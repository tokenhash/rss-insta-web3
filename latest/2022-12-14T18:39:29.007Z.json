[{"creator":"\n                     Dionysia Lemonaki \n                ","title":"\n                     How to Read a File Line by Line in Python \n                ","link":"https://www.freecodecamp.org/news/how-to-read-a-file-line-by-line-in-python/","pubDate":"Wed, 14 Dec 2022 12:58:48 -0500","content:encoded":"\n                     When coding in Python, there may be times when you need to open and read the contents of a text file. Luckily enough, there are several ways to do this in Python. The language has many built-in functions, methods, and keywords that you can use to create, write, read and \n                ","content:encodedSnippet":"When coding in Python, there may be times when you need to open and read the contents of a text file. Luckily enough, there are several ways to do this in Python. The language has many built-in functions, methods, and keywords that you can use to create, write, read and","dc:creator":"\n                     Dionysia Lemonaki \n                ","content":"\n                     When coding in Python, there may be times when you need to open and read the contents of a text file. Luckily enough, there are several ways to do this in Python. The language has many built-in functions, methods, and keywords that you can use to create, write, read and \n                ","contentSnippet":"When coding in Python, there may be times when you need to open and read the contents of a text file. Luckily enough, there are several ways to do this in Python. The language has many built-in functions, methods, and keywords that you can use to create, write, read and","guid":{"$":{"isPermaLink":"false"}},"categories":["\n                    \n                     Python \n                "],"isoDate":"2022-12-14T17:58:48.000Z","from":"https://medium.freecodecamp.org/feed","hashId":"0ec97d7c87d97c3ee70220aaea58ec74"},{"title":"Nouns DAO Debates Funding a Custom Governance Platform","link":"https://mirror.xyz/0xb1676B5Ab63F01F154bb9938F5e8999d9Da5444B/qq48PDxVWnNWfEGSgRYsvP1_GzJZY-KrXThRKKjeij0","pubDate":"Wed, 14 Dec 2022 18:04:15 GMT","content:encoded":"<blockquote>\n<p><em>TLDR: Nouns DAO is debating whether to extend funding for a custom governance client that enables context and discussion building for its ever popular decision-making process. The team behind the platform have withdrawn the proposal to incorporate changes and further align with the community.</em></p>\n</blockquote>\n<p>Nouns DAO has been successful in deploying thousands of ETH towards various projects and builders in an effort to proliferate the <a href=\"https://twitter.com/1fortytwo/status/1503351817270407170\">“Noggles meme”</a>. Over the course of Nouns DAO’s history, more than <a href=\"https://boardroom.io/nounsdao/proposals\">180 on-chain proposals</a> have been submitted, with an additional 100+ Prop House proposals considered. (<a href=\"https://prop.house/faq\">Prop House</a>, supported by Nouns DAO, creates funding rounds to “auction off fixed amounts of capital to builders with the best ideas.”) The DAO has frequently turned to its community to build bespoke solutions to improve its decision-making process. This has led to the development of a robust ecosystem of builders and believers who are committed to strengthening the DAO.</p>\n<p>In the case of governance solutions, teams such as House of Nouns (HoN), <a href=\"https://nounsagora.com/\">Nouns Agora</a>, and <a href=\"https://www.federation.wtf/\">Federation</a> (all Prop House alumni) have all stepped up to improve the Nouns DAO governance experience in different ways. In August, House of Nouns participated in a <a href=\"https://prop.house/\">Prop House</a> funding round focused on sourcing teams and ideas that could build custom governance solutions for the DAO and its ecosystem. The HON team <a href=\"https://prop.house/nouns/nouns-governance-clients\">was awarded</a> a 20 ETH grant (along with other projects) to build a “supercharged client for governance” with a focus on discussion and context building. Fast forward to today and the team has shipped the initial phase of the client, built a user base, and next looks to the future of the platform with their recent submission for a budget extension from Nouns DAO.</p>\n<h2 id=\"the-proposal-house-of-nouns\">The Proposal: House of Nouns</h2>\n<p>On December 5th, the HoN team <a href=\"https://boardroom.io/nounsdao/discussions/3166\">submitted a proposal</a> to the Nouns forum requesting additional funding to continue building their governance platform. In their proposal, the team highlights the progress they have made and the user adoption they have garnered in the months following their initial grant win. The proposal also provides community metrics, user activity metrics, and community testimonials to illustrate the project&#39;s early success with users.</p>\n<p>The HoN team has highlighted a handful of key areas within the product that they aim to improve over the next six months. These areas include the context layer, forum communications, and deeper integrations with existing Nounish communities.</p>\n<p>A total of 340 ETH is being requested by the four-person team. The team claims the budget is based on comparable funding requests from teams that are working on similar projects such as <a href=\"https://www.nounsagora.com/\">Nouns Agora</a> (an increasingly common trend among DAO service providers). Payment of the grant budget will be structured so that half is paid upfront with the remainder being streamed over the course of six months. Deliverables outlined in the proposal include the proposed improvements and enhancements to the House of Nouns client along with a House of Nouns Framework. This framework includes a GraphQL API, an open-source SDK, and a component library that all helps builders “create custom governance and discussion experiences”. In addition, the HON team defines key success metrics as having 30% or more of the Nounish ecosystem using the House of Nouns every week and 10 or more clients integrated into the House of Nouns framework and SDK by July 2023.</p>\n<p><img src=\"https://images.mirror-media.xyz/publication-images/LcTVCKTAagjmDk7-DqSWA.png?height=1356&width=1019\" alt=\"House of Nouns\"></p>\n<p>Nouns DAO governance is a fork of the widely adopted <a href=\"https://docs.compound.finance/v2/governance/\">Compound Governor Bravo</a> contract. This contract affords DAOs who use it on-chain governance with review and voting periods as well as a timelock. But Nouns DAO has taken a unique approach by giving holders of the Nouns NFT governance rights within the protocol (as opposed to, say, COMP governance token holders in Compound). In addition, the <a href=\"https://nouns.wtf/\">daily auction model</a> at Nouns DAO means its governance base grows daily.</p>\n<p>Proposals at Nouns DAO follow a process that is prevalent across DAOs. The lifecycle of a proposal begins in the idea stage as a forum post before it can be upgraded to a formal proposal. A minimum of two Nouns must be held to submit a proposal on-chain. Once a proposal goes live it enters what is called a ‘Voting Timeline’ that lasts seven days. In this timeline, a proposal kicks off a two-day window which is followed by an on-chain vote that lasts 3 days. This concludes with a two-day timelock before it can be executed.</p>\n<p>Voter sentiment surrounding this proposal was somewhat apprehensive, which is in part attributable to the proposal’s large price tag. After 57 <a href=\"https://boardroom.io/nounsdao/proposal/cHJvcG9zYWw6bm91bnNkYW86b25jaGFpbjoxODY=\">votes were cast</a> “against” and only 7 “for” and noting the supportive but reluctant responses in the forums, Discord, and on <a href=\"https://houseofnouns.wtf/proposals/186\">their own interface</a>, House of Nouns decided to cancel their proposal, a decision which they explain in a tweet-thread:</p>\n<p><a href=\"https://twitter.com/houseofnouns/status/1602845489975635968?s=20&amp;t=eYPHHAlzDM_2vjHjMgj-EA\">https://twitter.com/houseofnouns/status/1602845489975635968?s=20&amp;t=eYPHHAlzDM_2vjHjMgj-EA</a></p>\n<h2 id=\"big-picture\">Big Picture</h2>\n<p>Governance can vary radically from one web3 organization to the next, not just because of different systems (i.e. on-chain versus off-chain) but because the tooling is still evolving. Most active participants in the governance space track proposal activity (and their associated discussions) across multiple DAOs and often need to negotiate very different communities, processes, and governance interfaces. (This is a problem we at Boardroom are attempting to solve.) House of Nouns hopes to continue developing a governance interface that is integrative and highly engaging — which, as they argue, can only improve governance participation rates and attract more users to the space. This isn’t just about Nouns DAO, but about models that can be successfully adopted in other, similar organizations.</p>\n<p>More than this, while we have seen protocol governance succeed through direct resource allocation, this has been most prevalent in DeFi — when a protocol hires a treasury manager, for example. The type of initiative under consideration here has usually been funded by foundations or core protocol teams — but Nouns DAO is outsourcing that process. With Nouns DAO weighing the funding of governance tooling, we can see the possibility of such funding expanding to any web3 vertical across many different types of organizations. That the House of Nouns proposal has been cancelled in order to be revised — to “<a href=\"https://twitter.com/houseofnouns/status/1602845497672310784?s=20&amp;t=x-6T02cjPMsqMrg_Tf1rNA\">lower the budget</a>, clarify the roadmap and open source plans,” among other things — is not a sign of failure but rather of a healthy governance process.</p>\n<hr>\n<h2 id=\"well-be-tracking-this-proposal-activity-closely-at-boardroom-follow-our-newsletter-to-stay-up-to-date--if-youre-a-voter-in-a-protocol-make-sure-to-check-out-boardroom-portal\"><em>We’ll be tracking this proposal activity closely at Boardroom, follow our <a href=\"https://governance.substack.com/\">newsletter</a> to stay up to date.</em>  <em>If you’re a voter in a protocol, make sure to check out <a href=\"https://boardroom.io/portal\">Boardroom Portal</a>.</em></h2>\n<p><em>If you find submirror valuable, please consider donate to wong2.eth to help cover server cost.</em></p>\n","content:encodedSnippet":"TLDR: Nouns DAO is debating whether to extend funding for a custom governance client that enables context and discussion building for its ever popular decision-making process. The team behind the platform have withdrawn the proposal to incorporate changes and further align with the community.\nNouns DAO has been successful in deploying thousands of ETH towards various projects and builders in an effort to proliferate the “Noggles meme”. Over the course of Nouns DAO’s history, more than 180 on-chain proposals have been submitted, with an additional 100+ Prop House proposals considered. (Prop House, supported by Nouns DAO, creates funding rounds to “auction off fixed amounts of capital to builders with the best ideas.”) The DAO has frequently turned to its community to build bespoke solutions to improve its decision-making process. This has led to the development of a robust ecosystem of builders and believers who are committed to strengthening the DAO.\nIn the case of governance solutions, teams such as House of Nouns (HoN), Nouns Agora, and Federation (all Prop House alumni) have all stepped up to improve the Nouns DAO governance experience in different ways. In August, House of Nouns participated in a Prop House funding round focused on sourcing teams and ideas that could build custom governance solutions for the DAO and its ecosystem. The HON team was awarded a 20 ETH grant (along with other projects) to build a “supercharged client for governance” with a focus on discussion and context building. Fast forward to today and the team has shipped the initial phase of the client, built a user base, and next looks to the future of the platform with their recent submission for a budget extension from Nouns DAO.\nThe Proposal: House of Nouns\nOn December 5th, the HoN team submitted a proposal to the Nouns forum requesting additional funding to continue building their governance platform. In their proposal, the team highlights the progress they have made and the user adoption they have garnered in the months following their initial grant win. The proposal also provides community metrics, user activity metrics, and community testimonials to illustrate the project's early success with users.\nThe HoN team has highlighted a handful of key areas within the product that they aim to improve over the next six months. These areas include the context layer, forum communications, and deeper integrations with existing Nounish communities.\nA total of 340 ETH is being requested by the four-person team. The team claims the budget is based on comparable funding requests from teams that are working on similar projects such as Nouns Agora (an increasingly common trend among DAO service providers). Payment of the grant budget will be structured so that half is paid upfront with the remainder being streamed over the course of six months. Deliverables outlined in the proposal include the proposed improvements and enhancements to the House of Nouns client along with a House of Nouns Framework. This framework includes a GraphQL API, an open-source SDK, and a component library that all helps builders “create custom governance and discussion experiences”. In addition, the HON team defines key success metrics as having 30% or more of the Nounish ecosystem using the House of Nouns every week and 10 or more clients integrated into the House of Nouns framework and SDK by July 2023.\n\nNouns DAO governance is a fork of the widely adopted Compound Governor Bravo contract. This contract affords DAOs who use it on-chain governance with review and voting periods as well as a timelock. But Nouns DAO has taken a unique approach by giving holders of the Nouns NFT governance rights within the protocol (as opposed to, say, COMP governance token holders in Compound). In addition, the daily auction model at Nouns DAO means its governance base grows daily.\nProposals at Nouns DAO follow a process that is prevalent across DAOs. The lifecycle of a proposal begins in the idea stage as a forum post before it can be upgraded to a formal proposal. A minimum of two Nouns must be held to submit a proposal on-chain. Once a proposal goes live it enters what is called a ‘Voting Timeline’ that lasts seven days. In this timeline, a proposal kicks off a two-day window which is followed by an on-chain vote that lasts 3 days. This concludes with a two-day timelock before it can be executed.\nVoter sentiment surrounding this proposal was somewhat apprehensive, which is in part attributable to the proposal’s large price tag. After 57 votes were cast “against” and only 7 “for” and noting the supportive but reluctant responses in the forums, Discord, and on their own interface, House of Nouns decided to cancel their proposal, a decision which they explain in a tweet-thread:\nhttps://twitter.com/houseofnouns/status/1602845489975635968?s=20&t=eYPHHAlzDM_2vjHjMgj-EA\nBig Picture\nGovernance can vary radically from one web3 organization to the next, not just because of different systems (i.e. on-chain versus off-chain) but because the tooling is still evolving. Most active participants in the governance space track proposal activity (and their associated discussions) across multiple DAOs and often need to negotiate very different communities, processes, and governance interfaces. (This is a problem we at Boardroom are attempting to solve.) House of Nouns hopes to continue developing a governance interface that is integrative and highly engaging — which, as they argue, can only improve governance participation rates and attract more users to the space. This isn’t just about Nouns DAO, but about models that can be successfully adopted in other, similar organizations.\nMore than this, while we have seen protocol governance succeed through direct resource allocation, this has been most prevalent in DeFi — when a protocol hires a treasury manager, for example. The type of initiative under consideration here has usually been funded by foundations or core protocol teams — but Nouns DAO is outsourcing that process. With Nouns DAO weighing the funding of governance tooling, we can see the possibility of such funding expanding to any web3 vertical across many different types of organizations. That the House of Nouns proposal has been cancelled in order to be revised — to “lower the budget, clarify the roadmap and open source plans,” among other things — is not a sign of failure but rather of a healthy governance process.\nWe’ll be tracking this proposal activity closely at Boardroom, follow our newsletter to stay up to date.  If you’re a voter in a protocol, make sure to check out Boardroom Portal.\nIf you find submirror valuable, please consider donate to wong2.eth to help cover server cost.","guid":"https://mirror.xyz/0xb1676B5Ab63F01F154bb9938F5e8999d9Da5444B/qq48PDxVWnNWfEGSgRYsvP1_GzJZY-KrXThRKKjeij0","isoDate":"2022-12-14T18:04:15.000Z","from":"https://submirror.xyz/0xb1676B5Ab63F01F154bb9938F5e8999d9Da5444B","hashId":"964e26ea9dfb578b4c1d72e53aa576fe"},{"creator":"InfoSec Write-ups","title":"Recon Skills and Tips — Learn All About Them at IWCON 2022","link":"https://infosecwriteups.com/recon-skills-and-tips-learn-all-about-them-at-iwcon-2022-43e6564b7a96?source=rss----7b722bfd1b8d---4","pubDate":"Wed, 14 Dec 2022 18:04:21 GMT","content:encoded":"<h3>Recon Skills and Tips — Learn All About Them at IWCON 2022</h3><h4>Less than 2 days left for 2022’s much-awaited virtual cybersecurity conference.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*s42t0OQd2FgWr5iA1ihUdA.png\" /></figure><p>Happy to introduce <a href=\"https://twitter.com/GodfatherOrwa\">@GodfatherOrwa</a> as one of our speakers at IWCON2022.</p><p>Watch the video as he conveys in his own words about his journey and his topics-</p><h3>IWCON 2022 | InfoSec Community on Twitter: &quot;Happy to introduce @GodfatherOrwa as one of our speakers at #IWCON2022.Catch his talk on &quot;Recon skills and tips&quot; on 17th December 2022, 08:30 PM IST.Registered for the conference yet?Book your seat here: https://t.co/CYKu8AB1NG#conference #infosec #bugbounty #hacking pic.twitter.com/ZCUsSiYqFp / Twitter&quot;</h3><p>Happy to introduce @GodfatherOrwa as one of our speakers at #IWCON2022.Catch his talk on &quot;Recon skills and tips&quot; on 17th December 2022, 08:30 PM IST.Registered for the conference yet?Book your seat here: https://t.co/CYKu8AB1NG#conference #infosec #bugbounty #hacking pic.twitter.com/ZCUsSiYqFp</p><p>Catch his talk on <strong><em>Recon skills and tips</em></strong> on 17th December 2022, 08:30 PM IST.</p><p>Registered for the conference yet? <a href=\"https://iwcon.live\"><strong><em>Book your seat here.</em></strong></a></p><p>See you at the event.</p><p>Best,<br>Editorial team, <br>Infosec Writeups.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=43e6564b7a96\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://infosecwriteups.com/recon-skills-and-tips-learn-all-about-them-at-iwcon-2022-43e6564b7a96\">Recon Skills and Tips — Learn All About Them at IWCON 2022</a> was originally published in <a href=\"https://infosecwriteups.com\">InfoSec Write-ups</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","content:encodedSnippet":"Recon Skills and Tips — Learn All About Them at IWCON 2022\nLess than 2 days left for 2022’s much-awaited virtual cybersecurity conference.\n\nHappy to introduce @GodfatherOrwa as one of our speakers at IWCON2022.\nWatch the video as he conveys in his own words about his journey and his topics-\nIWCON 2022 | InfoSec Community on Twitter: \"Happy to introduce @GodfatherOrwa as one of our speakers at #IWCON2022.Catch his talk on \"Recon skills and tips\" on 17th December 2022, 08:30 PM IST.Registered for the conference yet?Book your seat here: https://t.co/CYKu8AB1NG#conference #infosec #bugbounty #hacking pic.twitter.com/ZCUsSiYqFp / Twitter\"\nHappy to introduce @GodfatherOrwa as one of our speakers at #IWCON2022.Catch his talk on \"Recon skills and tips\" on 17th December 2022, 08:30 PM IST.Registered for the conference yet?Book your seat here: https://t.co/CYKu8AB1NG#conference #infosec #bugbounty #hacking pic.twitter.com/ZCUsSiYqFp\nCatch his talk on Recon skills and tips on 17th December 2022, 08:30 PM IST.\nRegistered for the conference yet? Book your seat here.\nSee you at the event.\nBest,\nEditorial team, \nInfosec Writeups.\n\nRecon Skills and Tips — Learn All About Them at IWCON 2022 was originally published in InfoSec Write-ups on Medium, where people are continuing the conversation by highlighting and responding to this story.","dc:creator":"InfoSec Write-ups","guid":"https://medium.com/p/43e6564b7a96","categories":["security","conference","hacking","information-security","cybersecurity"],"isoDate":"2022-12-14T18:04:21.000Z","from":"https://medium.com/feed/bugbountywriteup","hashId":"0b4f2496c29ceb4f5ba9c77c346b3448"},{"creator":"Zohar Zilberman","title":"Implementing cascading merges in GitHub Actions (Part 3)","link":"https://blog.joshuins.com/implementing-cascading-merges-in-github-actions-part-3-46ae584ce094?source=rss------devops-5","pubDate":"Wed, 14 Dec 2022 18:07:38 GMT","dc:creator":"Zohar Zilberman","content":"<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://blog.joshuins.com/implementing-cascading-merges-in-github-actions-part-3-46ae584ce094?source=rss------devops-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/1*wGd55jZLPoyBdHIij73N4Q.png\" width=\"2880\"></a></p><p class=\"medium-feed-snippet\">In Part 1 and Part 2 we implemented cascading merges using GitHub Actions.</p><p class=\"medium-feed-link\"><a href=\"https://blog.joshuins.com/implementing-cascading-merges-in-github-actions-part-3-46ae584ce094?source=rss------devops-5\">Continue reading on Joshu Blog »</a></p></div>","contentSnippet":"In Part 1 and Part 2 we implemented cascading merges using GitHub Actions.\nContinue reading on Joshu Blog »","guid":"https://medium.com/p/46ae584ce094","categories":["ci","github-actions","devops"],"isoDate":"2022-12-14T18:07:38.000Z","from":"https://medium.com/feed/tag/devops","hashId":"cea927e463c8805e214b8e4942e0153e"},{"creator":"Allen Helton","title":"I Built a Serverless App To Cross-Post My Blogs","link":"https://betterprogramming.pub/i-built-a-serverless-app-to-cross-post-my-blogs-aa4c6979ff9b?source=rss----d0b105d10f0a---4","pubDate":"Wed, 14 Dec 2022 18:15:38 GMT","content:encoded":"<h4>Publishing my blogs on several platforms takes up a lot of time every week. There had to be a better way</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Yr_e8u3xMFeQQKs_.jpg\" /><figcaption><em>Image by </em><a href=\"https://www.freepik.com/author/macrovector\"><em>Macrovector</em></a><em> on Freepik</em></figcaption></figure><p>I do a lot of writing.</p><p>I’ve written and published a blog post <a href=\"https://twitter.com/AllenHeltonDev/status/1600875349037920256\">every week for the last 50 weeks</a>. It’s something that I do because I have a passion for writing and <a href=\"https://betterprogramming.pub/how-i-became-an-aws-serverless-hero-f89f718a3b4d\">sharing the things I learn with others</a>.</p><p>Writing not only provides me with a great way to help others, but it also <a href=\"https://betterprogramming.pub/three-reasons-why-blogging-makes-you-a-better-developer-4ca42336a84b\">helps me learn</a> by ensuring I know a topic from top to bottom. It has highly benefited my writing ability, comprehension, and self-awareness. I could go on and on about it, but we’re here to talk about something else.</p><p>The hardest part about blogging is cross-posting. Cross-posting is where I take the content from my articles and post it on other websites with a link to my blog. I republish my content on <a href=\"https://allenheltondev.medium.com/\">Medium</a>, <a href=\"https://dev.to/allenheltondev\">Dev.to</a>, and <a href=\"https://allenheltondev.hashnode.dev/\">Hashnode</a>.</p><p>By cross-posting on these different platforms, I am able to reach a wider audience than if I only published content on my blog.</p><p>Unfortunately, it’s not just a simple copy/paste on these platforms. I have to do a couple of modifications to the content that vary based on the site I’m publishing on.</p><ul><li>Update links — my articles often reference other articles I’ve written. I update these links on each platform to point to the cross-posted version. So all my Medium articles link to my other Medium articles, all the Dev articles point to other Dev articles, etc. This provides a nice, unified experience for my readers.</li><li>Update embeds — I regularly embed code or tweets in my posts. Each platform uses a different mechanism to embed content into a post.</li><li>Set canonical URL — Each post needs to point back to the original article hosted <a href=\"https://readysetcloud.io\">on my blog</a>. If they do not, <a href=\"https://www.seoclarity.net/resources/knowledgebase/what-is-a-site-crawler\">SEO crawlers</a> will detect duplicate content and lower search engine rankings.</li></ul><p>As you can imagine, this takes a lot of time every week. Parsing through links and updating them with the right references, replacing embedded content, and setting canonical URLs for three different sites adds up quickly.</p><p>So I decided to fix that. I built a serverless app that will update and cross-post my content every time I publish something new.</p><p>Let’s take a look.</p><h3>How It Works</h3><p>My blog is built with the <a href=\"https://gohugo.io/\">static site generator Hugo</a> and hosted in <a href=\"https://aws.amazon.com/amplify/\">AWS Amplify</a>. If you’re interested in how I built it, <a href=\"https://allenheltondev.medium.com/take-the-leap-10-steps-to-building-your-personal-blog-with-aws-hugo-ready-set-cloud-ccc466443123\">I wrote a blog post about it</a>.</p><p>I write articles in markdown and push them to the main branch in my repository. An Amplify build is triggered, which runs Hugo to compile the markdown into HTML, then it publishes the content to S3, which CloudFront fronts.</p><p>For my app, I wanted to trigger an async process to run whenever the build finished successfully. This process would fetch the file from GitHub, transform the markdown to the appropriate format, and publish it to all the different platforms.</p><figure><img alt=\"Automation flow on a successful build\" src=\"https://cdn-images-1.medium.com/max/1024/0*jWBMz9yd1zl8OuZH.png\" /><figcaption><em>Automation flow on a successful build</em></figcaption></figure><p>Triggering a process after a successful Amplify build was something I looked for in the docs but couldn’t find. I was about to trigger a Lambda function directly from my build when I decided to ask <a href=\"https://twitter.com/focusotter\">Michael Liendo</a> if he knew any tricks.</p><p>Luckily, I piqued his interest. He dug deep and discovered a neat undocumented feature.</p><h3>Allen Helton on Twitter: &quot;Coolness of the day - I was able to trigger a #lambda function when my @AWSAmplify build finished successfully. Shoutout to @focusotter for discovering this little tidbit. Here&#39;s the event configuration in SAM: pic.twitter.com/Ev3V4LeBop / Twitter&quot;</h3><p>Coolness of the day - I was able to trigger a #lambda function when my @AWSAmplify build finished successfully. Shoutout to @focusotter for discovering this little tidbit. Here&#39;s the event configuration in SAM: pic.twitter.com/Ev3V4LeBop</p><p>So I was able to trigger a Lambda function with an EventBridge rule on a successful build!</p><p>This Lambda function calls into GitHub and looks for commits in the last five minutes [new post] in the commit message. It then grabs all the new files in my blog directory from the commit and starts a state machine execution that transforms and publishes the content to the various platforms.</p><p>If there are no commits with [new post] in the message or no new files in the blog directory of my repository, the Lambda function execution stops without triggering the state machine.</p><p>The state machine workflow looks like this:</p><figure><img alt=\"Transform and publish state machine\" src=\"https://cdn-images-1.medium.com/max/1024/0*3i4my-8ou75kLWjX.png\" /><figcaption><em>Transform and publish state machine</em></figcaption></figure><p>To prevent the articles from accidentally being published more than once, it starts with an <a href=\"https://betterprogramming.pub/serverless-api-essentials-idempotency-e753b7b49680\">idempotency check</a>, keyed off the file name, and commit sha. If multiple executions are triggered with the same file name/commit combination and the original execution is in progress or was successful, the execution aborts. If the original execution failed, it safely retries to process the article.</p><p>After the idempotency check, it uses a direct integration to DynamoDB to load all the existing articles and their mappings (more on this in a minute). Once the articles are loaded, it transforms and publishes them to all three platforms in parallel.</p><p>On success, it saves the cross-post URLs and updates the idempotency record. Then it’s live!</p><p>Let’s take a closer look at the transform and publish components.</p><h3>Updating Links</h3><p>When I manually update links to point to my cross-posted versions, I have to scroll through my story list page on the platform I’m cross-posting on. I find the link to the article I referenced, then update the content accordingly.</p><p>But I can’t do that with a backend process. I can’t “click and scroll” and find the right article.</p><p>So, I built a catalog of all my articles in DynamoDB.</p><figure><img alt=\"Article catalog in DynamoDB\" src=\"https://cdn-images-1.medium.com/max/1024/0*nadDpjxmYtJeKBSR.png\" /><figcaption><em>Article catalog in DynamoDB</em></figcaption></figure><p>Each article gets a record in DynamoDB that uniquely identifies it by the <a href=\"https://redclaycreative.com/glossary/what-is-post-slug/\">post slug</a>. The record contains a links object that contains the URL to the cross-posted version on Medium, Dev, and Hashnode.</p><pre>{<br> &quot;pk&quot;: &quot;/blog/allen.helton/infrastructure-from-code-benchmark&quot;,<br> &quot;sk&quot;: &quot;article&quot;,<br> &quot;GSI1PK&quot;: &quot;article&quot;,<br> &quot;GSI1SK&quot;: &quot;The Current State of Infrastructure From Code&quot;,<br> &quot;links&quot;: {<br>  &quot;devUrl&quot;: &quot;https://dev.to/aws-heroes/the-current-state-of-infrastructure-from-code-1fjc&quot;,<br>  &quot;mediumUrl&quot;: &quot;https://betterprogramming.pub/the-current-state-of-infrastructure-from-code-cbd3469ecdc5&quot;,<br>  &quot;url&quot;: &quot;/blog/allen.helton/infrastructure-from-code-benchmark&quot;,<br>  &quot;hashnodeUrl&quot;: &quot;https://allenheltondev.hashnode.dev/the-current-state-of-infrastructure-from-code&quot;<br> },<br> &quot;title&quot;: &quot;The Current State of Infrastructure From Code&quot;<br>}</pre><p>To identify links in my post, I used a regular expression to match the markdown link format. All internal links (meaning references to other posts I’ve written) start with /blog/allen.helton/, so I included that to identify the links that needed to be updated quickly.</p><p>Once I was able to grab all internal links, I had to iterate over them, replacing the value of my URL with the mapped value in the links object of the article record.</p><h3>Updating Embeds</h3><p>When you see rich content in a post, that is typically the result of an embed. It’s a special piece of content presented in a way that looks more natural to readers.</p><p>The most common embedding I use in my posts is for Twitter. It puts a tweet directly into the content, so the reader gets the view exactly as if they were on the site. But the format of an embed differs on all the platforms I post on. For example, here are the different structures to embed a tweet.</p><pre>My Blog: {&lt;tweet user=&quot;&lt;username&gt;&quot; id=&quot;&lt;tweet id&gt;&quot;&gt;}<br>Dev: {% twitter &lt;url to tweet&gt; %}<br>Medium: &lt;url to tweet&gt;<br>Hashnode: %[&lt;url to tweet&gt;]</pre><p>As you can see, the structure is very different, so I had to use another regex to match the tweet format in my blog, compose the full Twitter URL, then transform it to the specific platform.</p><p>Overall not a terribly difficult part of the project, but the inconsistency was killing me!</p><h3>Publishing the Articles</h3><p>After the data is transformed appropriately, I use the API of the respective platform to post. This part was unexpectedly difficult. It’s also an appropriate time to talk about <a href=\"https://betterprogramming.pub/are-you-really-api-first-or-do-you-just-think-it-24ffc47ec7ea\">API-first development</a>.</p><p>Having a strong, intuitive set of API docs is critical if you expect people to integrate with your software. If you don’t, only the persistent integrators will stick with it to get their automation going. I might have abandoned this project if it wasn’t for this article.</p><p>Of the three platforms I integrated with, only Dev had decent documentation — and even that one was iffy. The documentation states their original API version is deprecated, but the new version only has two endpoints implemented. I was wary of building an integration with a deprecated version but decided to go with it. Luckily their API works very well, and I had it going in just a few minutes.</p><p>Medium and Hashnode were completely different stories.</p><p>Medium had what felt like long-form writing for their documentation and hosted it in GitHub in a README. All the information I needed was there, but I had to hunt for it.</p><p>Hashnode uses GraphQL for its API and provides a testing tool with object definitions and no explanations. I had to rely on blog posts to figure out what was going on there.</p><p>But with trial and error, I successfully found the right endpoints and requested bodies to publish my content.</p><p>I did stray off the beaten path slightly for Medium and Dev. When I post on Dev, I always link my content to the <a href=\"https://dev.to/aws-heroes\">AWS Heroes collection</a>. Similarly, on Medium, I add my content to the <a href=\"https://betterprogramming.pub/\">Better Programming publication</a>. So I had to figure out how to submit the content directly to them to optimize the flow.</p><p>In the end, I was able to get them all working, and the content linked correctly and presented in the right format.</p><p>The final part of publishing the articles is to get the post slug of the new article for each platform and create the DynamoDB entry for the story so it can be referenced in future articles.</p><p>Luckily, the full URL is returned in the success response message of each post, so I could grab them and save the data back to DynamoDB.</p><h3>Final Thoughts</h3><p>This was a fun little app to build that was way more involved than I originally expected. Now that it’s done, I will spend some time polishing and parameterizing the IaC so it can be open sourced.</p><p>This will take a huge amount of time going forward. Not only that, but it should also make my posts less prone to error. Humans make mistakes all the time. There have been plenty of times when I missed a link or forgot to update an embed. With automation, it will never be missed.</p><blockquote>Take any chance you have to remove the human element out of a process.</blockquote><p>If you’re reading this on Dev, Medium, or Hashnode, hopefully, all the links worked for you. This post was my first production test.</p><p>I hope this post inspires you to go and build something to make your life easier. What repetitive tasks do you do that could be automated? Nowadays, there’s an API for pretty much everything we interact with — almost nothing is off the table.</p><p>If you do build something, tell me about it! I’d love to see what you made!</p><p>Happy coding!</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=aa4c6979ff9b\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://betterprogramming.pub/i-built-a-serverless-app-to-cross-post-my-blogs-aa4c6979ff9b\">I Built a Serverless App To Cross-Post My Blogs</a> was originally published in <a href=\"https://betterprogramming.pub\">Better Programming</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","content:encodedSnippet":"Publishing my blogs on several platforms takes up a lot of time every week. There had to be a better way\nImage by Macrovector on Freepik\nI do a lot of writing.\nI’ve written and published a blog post every week for the last 50 weeks. It’s something that I do because I have a passion for writing and sharing the things I learn with others.\nWriting not only provides me with a great way to help others, but it also helps me learn by ensuring I know a topic from top to bottom. It has highly benefited my writing ability, comprehension, and self-awareness. I could go on and on about it, but we’re here to talk about something else.\nThe hardest part about blogging is cross-posting. Cross-posting is where I take the content from my articles and post it on other websites with a link to my blog. I republish my content on Medium, Dev.to, and Hashnode.\nBy cross-posting on these different platforms, I am able to reach a wider audience than if I only published content on my blog.\nUnfortunately, it’s not just a simple copy/paste on these platforms. I have to do a couple of modifications to the content that vary based on the site I’m publishing on.\n\nUpdate links — my articles often reference other articles I’ve written. I update these links on each platform to point to the cross-posted version. So all my Medium articles link to my other Medium articles, all the Dev articles point to other Dev articles, etc. This provides a nice, unified experience for my readers.\nUpdate embeds — I regularly embed code or tweets in my posts. Each platform uses a different mechanism to embed content into a post.\nSet canonical URL — Each post needs to point back to the original article hosted on my blog. If they do not, SEO crawlers will detect duplicate content and lower search engine rankings.\n\nAs you can imagine, this takes a lot of time every week. Parsing through links and updating them with the right references, replacing embedded content, and setting canonical URLs for three different sites adds up quickly.\nSo I decided to fix that. I built a serverless app that will update and cross-post my content every time I publish something new.\nLet’s take a look.\nHow It Works\nMy blog is built with the static site generator Hugo and hosted in AWS Amplify. If you’re interested in how I built it, I wrote a blog post about it.\nI write articles in markdown and push them to the main branch in my repository. An Amplify build is triggered, which runs Hugo to compile the markdown into HTML, then it publishes the content to S3, which CloudFront fronts.\nFor my app, I wanted to trigger an async process to run whenever the build finished successfully. This process would fetch the file from GitHub, transform the markdown to the appropriate format, and publish it to all the different platforms.\nAutomation flow on a successful build\nTriggering a process after a successful Amplify build was something I looked for in the docs but couldn’t find. I was about to trigger a Lambda function directly from my build when I decided to ask Michael Liendo if he knew any tricks.\nLuckily, I piqued his interest. He dug deep and discovered a neat undocumented feature.\nAllen Helton on Twitter: \"Coolness of the day - I was able to trigger a #lambda function when my @AWSAmplify build finished successfully. Shoutout to @focusotter for discovering this little tidbit. Here's the event configuration in SAM: pic.twitter.com/Ev3V4LeBop / Twitter\"\nCoolness of the day - I was able to trigger a #lambda function when my @AWSAmplify build finished successfully. Shoutout to @focusotter for discovering this little tidbit. Here's the event configuration in SAM: pic.twitter.com/Ev3V4LeBop\nSo I was able to trigger a Lambda function with an EventBridge rule on a successful build!\nThis Lambda function calls into GitHub and looks for commits in the last five minutes [new post] in the commit message. It then grabs all the new files in my blog directory from the commit and starts a state machine execution that transforms and publishes the content to the various platforms.\nIf there are no commits with [new post] in the message or no new files in the blog directory of my repository, the Lambda function execution stops without triggering the state machine.\nThe state machine workflow looks like this:\nTransform and publish state machine\nTo prevent the articles from accidentally being published more than once, it starts with an idempotency check, keyed off the file name, and commit sha. If multiple executions are triggered with the same file name/commit combination and the original execution is in progress or was successful, the execution aborts. If the original execution failed, it safely retries to process the article.\nAfter the idempotency check, it uses a direct integration to DynamoDB to load all the existing articles and their mappings (more on this in a minute). Once the articles are loaded, it transforms and publishes them to all three platforms in parallel.\nOn success, it saves the cross-post URLs and updates the idempotency record. Then it’s live!\nLet’s take a closer look at the transform and publish components.\nUpdating Links\nWhen I manually update links to point to my cross-posted versions, I have to scroll through my story list page on the platform I’m cross-posting on. I find the link to the article I referenced, then update the content accordingly.\nBut I can’t do that with a backend process. I can’t “click and scroll” and find the right article.\nSo, I built a catalog of all my articles in DynamoDB.\nArticle catalog in DynamoDB\nEach article gets a record in DynamoDB that uniquely identifies it by the post slug. The record contains a links object that contains the URL to the cross-posted version on Medium, Dev, and Hashnode.\n{\n \"pk\": \"/blog/allen.helton/infrastructure-from-code-benchmark\",\n \"sk\": \"article\",\n \"GSI1PK\": \"article\",\n \"GSI1SK\": \"The Current State of Infrastructure From Code\",\n \"links\": {\n  \"devUrl\": \"https://dev.to/aws-heroes/the-current-state-of-infrastructure-from-code-1fjc\",\n  \"mediumUrl\": \"https://betterprogramming.pub/the-current-state-of-infrastructure-from-code-cbd3469ecdc5\",\n  \"url\": \"/blog/allen.helton/infrastructure-from-code-benchmark\",\n  \"hashnodeUrl\": \"https://allenheltondev.hashnode.dev/the-current-state-of-infrastructure-from-code\"\n },\n \"title\": \"The Current State of Infrastructure From Code\"\n}\nTo identify links in my post, I used a regular expression to match the markdown link format. All internal links (meaning references to other posts I’ve written) start with /blog/allen.helton/, so I included that to identify the links that needed to be updated quickly.\nOnce I was able to grab all internal links, I had to iterate over them, replacing the value of my URL with the mapped value in the links object of the article record.\nUpdating Embeds\nWhen you see rich content in a post, that is typically the result of an embed. It’s a special piece of content presented in a way that looks more natural to readers.\nThe most common embedding I use in my posts is for Twitter. It puts a tweet directly into the content, so the reader gets the view exactly as if they were on the site. But the format of an embed differs on all the platforms I post on. For example, here are the different structures to embed a tweet.\nMy Blog: {<tweet user=\"<username>\" id=\"<tweet id>\">}\nDev: {% twitter <url to tweet> %}\nMedium: <url to tweet>\nHashnode: %[<url to tweet>]\nAs you can see, the structure is very different, so I had to use another regex to match the tweet format in my blog, compose the full Twitter URL, then transform it to the specific platform.\nOverall not a terribly difficult part of the project, but the inconsistency was killing me!\nPublishing the Articles\nAfter the data is transformed appropriately, I use the API of the respective platform to post. This part was unexpectedly difficult. It’s also an appropriate time to talk about API-first development.\nHaving a strong, intuitive set of API docs is critical if you expect people to integrate with your software. If you don’t, only the persistent integrators will stick with it to get their automation going. I might have abandoned this project if it wasn’t for this article.\nOf the three platforms I integrated with, only Dev had decent documentation — and even that one was iffy. The documentation states their original API version is deprecated, but the new version only has two endpoints implemented. I was wary of building an integration with a deprecated version but decided to go with it. Luckily their API works very well, and I had it going in just a few minutes.\nMedium and Hashnode were completely different stories.\nMedium had what felt like long-form writing for their documentation and hosted it in GitHub in a README. All the information I needed was there, but I had to hunt for it.\nHashnode uses GraphQL for its API and provides a testing tool with object definitions and no explanations. I had to rely on blog posts to figure out what was going on there.\nBut with trial and error, I successfully found the right endpoints and requested bodies to publish my content.\nI did stray off the beaten path slightly for Medium and Dev. When I post on Dev, I always link my content to the AWS Heroes collection. Similarly, on Medium, I add my content to the Better Programming publication. So I had to figure out how to submit the content directly to them to optimize the flow.\nIn the end, I was able to get them all working, and the content linked correctly and presented in the right format.\nThe final part of publishing the articles is to get the post slug of the new article for each platform and create the DynamoDB entry for the story so it can be referenced in future articles.\nLuckily, the full URL is returned in the success response message of each post, so I could grab them and save the data back to DynamoDB.\nFinal Thoughts\nThis was a fun little app to build that was way more involved than I originally expected. Now that it’s done, I will spend some time polishing and parameterizing the IaC so it can be open sourced.\nThis will take a huge amount of time going forward. Not only that, but it should also make my posts less prone to error. Humans make mistakes all the time. There have been plenty of times when I missed a link or forgot to update an embed. With automation, it will never be missed.\nTake any chance you have to remove the human element out of a process.\nIf you’re reading this on Dev, Medium, or Hashnode, hopefully, all the links worked for you. This post was my first production test.\nI hope this post inspires you to go and build something to make your life easier. What repetitive tasks do you do that could be automated? Nowadays, there’s an API for pretty much everything we interact with — almost nothing is off the table.\nIf you do build something, tell me about it! I’d love to see what you made!\nHappy coding!\n\nI Built a Serverless App To Cross-Post My Blogs was originally published in Better Programming on Medium, where people are continuing the conversation by highlighting and responding to this story.","dc:creator":"Allen Helton","guid":"https://medium.com/p/aa4c6979ff9b","categories":["cloud-computing","aws","serverless","programming","software-development"],"isoDate":"2022-12-14T18:15:38.000Z","from":"https://medium.com/feed/better-programming","hashId":"a8fd43534ae2f8a721769b42389d51cf"},{"creator":"Anton Klimenko","title":"To Throw or Not to Throw? Error Propagation in JavaScript and TypeScript","link":"https://betterprogramming.pub/to-throw-or-not-to-throw-error-propagation-in-js-and-ts-68aaabe30e30?source=rss----d0b105d10f0a---4","pubDate":"Wed, 14 Dec 2022 18:26:17 GMT","content:encoded":"<h4>Exploring Error propagation principles</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*ZdBz_Rz9lU6Jbyt0\" /><figcaption>Photo by <a href=\"https://unsplash.com/@rojekilian?utm_source=medium&amp;utm_medium=referral\">Sarah Kilian</a> on <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>One of the most questionable concepts in JavaScript and TypeScript is error propagation. Part of the problem is the misunderstanding of the difference between an exception and an error.</p><p>The post aims to discover exception types and define error propagation principles. Even though the article emphasizes JavaScript and TypeScript, the same error propagation principles apply to many other languages.</p><h3>Exceptions and errors</h3><p>An error is an object containing information about what went wrong and where in code it happened. Exceptions are not errors; <a href=\"https://en.wikipedia.org/wiki/Exception_handling\"><em>exceptions</em></a><em> </em>are anomalous or exceptional conditions requiring special processing. There are two types of such conditions: <em>operational </em>and<em> non-operational</em>.</p><p>The input validation errors are <em>operational </em>errors<em>. </em>A failed login attempt is an <em>operational</em> situation. These use cases are expected and handled accordingly. The application continues operating as usual whenever such scenarios happen.</p><p><em>A non-operational</em> condition is when an application cannot automatically resolve an error and should be terminated. For example, an application should store data in a DB. Some of the application&#39;s functionality is lost when the connection to a DB is impossible. If this functionality is critical, the application is in a <em>non-operational </em>state. If it cannot automatically recover, it should be terminated.</p><h3>Errors propagation</h3><p>Everything starts from error propagation. The method with which an error is returned determines whether the application can continue functioning or it&#39;s better to stop. The error propagation method also defines how the error should be handled.</p><p>There are two ways to propagate an error in JavaScript and TypeScript:</p><ul><li><a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/throw\">Throw</a> an exception. It terminates the process if not handled. It should be used when the intention is to stop an application when something goes wrong.</li><li>Return an error. It denotes an expected error case scenario and does not require an application termination.</li></ul><p>The danger of using the <em>throw </em>mechanism to return an error is that it can terminate an application if not handled properly. Just returning errors will not stop an application. But ignoring such errors can bring an application into an unexpected and disordered state.</p><p>Another essential aspect when choosing an error propagation mechanism is documentation. When working with TypeScript, the language service infers types of input and output parameters of the functions. If a function returns a parameter of error type, it is visible in the code editor and reduces the risk of missing error handling. The situation differs when a function throws an exception — the language service cannot identify it. There&#39;s the <a href=\"https://tsdoc.org/pages/tags/throws/\"><em>throws</em></a><em> </em>tag defined in <a href=\"https://tsdoc.org/\">TSDoc</a>, but it&#39;s not widely used. The only way to find out that the function throws an exception is to read its source code.</p><h3>Exception Handling</h3><p>Exception handling depends on how an error is returned and the type of function that returns an error. It&#39;s relatively easy for synchronous functions. Error checked with <em>if </em>clause in the case when it is returned by a function. If a function throws an exception, its call is usually guarded with <em>try/catch</em>.</p><p>Exception handling is more complex in the case of asynchronous functions. There are a few ways to handle asynchronous operations:</p><ul><li>Use callback functions</li><li>Use promises with .then and .catch</li><li>Use await to resolve promises</li></ul><p>There are also generators, but I&#39;ll omit them.</p><p>Exception handling in callbacks is quite simple. Whenever an asynchronous operation is finished, the operation handler invokes a callback function and returns errors if there are some. By convention, the first parameter of the callback function is an error. If an error is not null, the callback function invocation stops. It makes the control flow easy to understand.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/fd628a2551aa35c320206b977713d052/href\">https://medium.com/media/fd628a2551aa35c320206b977713d052/href</a></iframe><p>There are a few challenges here. It is unclear whether the error results from an <em>operational</em> or <em>non-operational</em> exception. Another challenge is processing results propagation. The need to pass one function&#39;s output to another&#39;s input created lots of code with nested callbacks, which is hard to read and maintain.</p><p>Promises solved the problem of orchestrating sequential invocations of functions (synchronous and asynchronous). A sequence of promises can be joined in one call with <em>.then, </em>and data can flow between calls. But promises use callbacks and inherit the same exception handling challenges.</p><p><em>Async/await </em>removed the need to use callbacks and solved the orchestration issue. The result of the asynchronous function can now be awaited. It makes code cleaner and easier to read, a <em>happy path </em>at least. <em>Try/catch</em> replaced the callback error handling technique. It felt like a win at the beginning. In reality, new issues replaced old issues:</p><ul><li>When guarding an asynchronous function call with<em> try/catch, </em>it is still unclear whether the error results from an <em>operational</em> or <em>non-operational</em> exception.</li><li>It is not rare to see multiple asynchronous function calls within one <em>try/catch</em> block. In this case, the <em>catch</em> clause handles exceptions from all functions. It is also not rare to see an intricate error processing logic in the <em>catch</em> block in an attempt to understand what function call is the source of error.</li><li>Nested <em>try/catch</em> blocks. It looks even worse than nested callbacks.</li></ul><p>So, how can we use the advantage of <em>async/await</em> in asynchronous call orchestration and minimise exception handling issues?</p><h3>Error propagation and handling principles</h3><ul><li>Return error for <em>operational </em>exceptions.</li><li>Always check returned errors.</li><li>Throw an error for <em>non-operational </em>exceptions.</li><li><em>Try </em>statement block should guard a single logical unit or a call.</li><li>Avoid complex logic in a <em>catch</em> clause.</li><li>Don&#39;t nest <em>try/catch</em> blocks.</li><li>Wrap errors.</li></ul><p>Wrapping errors means taking one error value and putting another error value inside it. It allows extending an error with additional information about where it came from or how it happened without losing the original value. There are a few <a href=\"https://2ality.com/2021/06/error-cause.html#a-library\">libraries</a> supporting error wrapping in JavaScript. Alternatively, you can adopt ECMAScript2022 which has built-in support of <a href=\"https://2ality.com/2022/06/ecmascript-2022.html#error.cause\">error.cause</a><em>.</em></p><p>The following sections show examples of error propagation and handling:</p><h4>Try catch approach</h4><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/bead3e691e75ae89a319b5dc1d69e450/href\">https://medium.com/media/bead3e691e75ae89a319b5dc1d69e450/href</a></iframe><p>It&#39;s easy to reason about the code when <em>try/catch</em> guards a single statement. Things get worse quickly when it&#39;s necessary to handle multiple asynchronous calls.</p><h4>Wrapping try/catch approach</h4><p>This approach hides <em>try/catch</em> within the function. The function declaration states that it can return an error or a value. It allows using an <em>if </em>statement to control logic flow.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/854916a7d5685d7ab15489298729ee77/href\">https://medium.com/media/854916a7d5685d7ab15489298729ee77/href</a></iframe><p>The following example is the next step to generalise error handling. It uses TypeScript utility types to infer function parameters and output types.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/6f3eb3febe9505b2c07c448ba553a1f0/href\">https://medium.com/media/6f3eb3febe9505b2c07c448ba553a1f0/href</a></iframe><p>The examples above use <a href=\"https://deno.land/\">Deno</a> read file API. To run them, use the following command:</p><pre>$ FILE=hello.txt deno run --allow-env=FILE --allow-read main.ts</pre><p>Thanks for reading.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=68aaabe30e30\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://betterprogramming.pub/to-throw-or-not-to-throw-error-propagation-in-js-and-ts-68aaabe30e30\">To Throw or Not to Throw? Error Propagation in JavaScript and TypeScript</a> was originally published in <a href=\"https://betterprogramming.pub\">Better Programming</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","content:encodedSnippet":"Exploring Error propagation principles\nPhoto by Sarah Kilian on Unsplash\nOne of the most questionable concepts in JavaScript and TypeScript is error propagation. Part of the problem is the misunderstanding of the difference between an exception and an error.\nThe post aims to discover exception types and define error propagation principles. Even though the article emphasizes JavaScript and TypeScript, the same error propagation principles apply to many other languages.\nExceptions and errors\nAn error is an object containing information about what went wrong and where in code it happened. Exceptions are not errors; exceptions are anomalous or exceptional conditions requiring special processing. There are two types of such conditions: operational and non-operational.\nThe input validation errors are operational errors. A failed login attempt is an operational situation. These use cases are expected and handled accordingly. The application continues operating as usual whenever such scenarios happen.\nA non-operational condition is when an application cannot automatically resolve an error and should be terminated. For example, an application should store data in a DB. Some of the application's functionality is lost when the connection to a DB is impossible. If this functionality is critical, the application is in a non-operational state. If it cannot automatically recover, it should be terminated.\nErrors propagation\nEverything starts from error propagation. The method with which an error is returned determines whether the application can continue functioning or it's better to stop. The error propagation method also defines how the error should be handled.\nThere are two ways to propagate an error in JavaScript and TypeScript:\n\nThrow an exception. It terminates the process if not handled. It should be used when the intention is to stop an application when something goes wrong.\nReturn an error. It denotes an expected error case scenario and does not require an application termination.\n\nThe danger of using the throw mechanism to return an error is that it can terminate an application if not handled properly. Just returning errors will not stop an application. But ignoring such errors can bring an application into an unexpected and disordered state.\nAnother essential aspect when choosing an error propagation mechanism is documentation. When working with TypeScript, the language service infers types of input and output parameters of the functions. If a function returns a parameter of error type, it is visible in the code editor and reduces the risk of missing error handling. The situation differs when a function throws an exception — the language service cannot identify it. There's the throws tag defined in TSDoc, but it's not widely used. The only way to find out that the function throws an exception is to read its source code.\nException Handling\nException handling depends on how an error is returned and the type of function that returns an error. It's relatively easy for synchronous functions. Error checked with if clause in the case when it is returned by a function. If a function throws an exception, its call is usually guarded with try/catch.\nException handling is more complex in the case of asynchronous functions. There are a few ways to handle asynchronous operations:\n\nUse callback functions\nUse promises with .then and .catch\nUse await to resolve promises\n\nThere are also generators, but I'll omit them.\nException handling in callbacks is quite simple. Whenever an asynchronous operation is finished, the operation handler invokes a callback function and returns errors if there are some. By convention, the first parameter of the callback function is an error. If an error is not null, the callback function invocation stops. It makes the control flow easy to understand.\nhttps://medium.com/media/fd628a2551aa35c320206b977713d052/href\nThere are a few challenges here. It is unclear whether the error results from an operational or non-operational exception. Another challenge is processing results propagation. The need to pass one function's output to another's input created lots of code with nested callbacks, which is hard to read and maintain.\nPromises solved the problem of orchestrating sequential invocations of functions (synchronous and asynchronous). A sequence of promises can be joined in one call with .then, and data can flow between calls. But promises use callbacks and inherit the same exception handling challenges.\nAsync/await removed the need to use callbacks and solved the orchestration issue. The result of the asynchronous function can now be awaited. It makes code cleaner and easier to read, a happy path at least. Try/catch replaced the callback error handling technique. It felt like a win at the beginning. In reality, new issues replaced old issues:\n\nWhen guarding an asynchronous function call with try/catch, it is still unclear whether the error results from an operational or non-operational exception.\nIt is not rare to see multiple asynchronous function calls within one try/catch block. In this case, the catch clause handles exceptions from all functions. It is also not rare to see an intricate error processing logic in the catch block in an attempt to understand what function call is the source of error.\nNested try/catch blocks. It looks even worse than nested callbacks.\n\nSo, how can we use the advantage of async/await in asynchronous call orchestration and minimise exception handling issues?\nError propagation and handling principles\n\nReturn error for operational exceptions.\nAlways check returned errors.\nThrow an error for non-operational exceptions.\nTry statement block should guard a single logical unit or a call.\nAvoid complex logic in a catch clause.\nDon't nest try/catch blocks.\nWrap errors.\n\nWrapping errors means taking one error value and putting another error value inside it. It allows extending an error with additional information about where it came from or how it happened without losing the original value. There are a few libraries supporting error wrapping in JavaScript. Alternatively, you can adopt ECMAScript2022 which has built-in support of error.cause.\nThe following sections show examples of error propagation and handling:\nTry catch approach\nhttps://medium.com/media/bead3e691e75ae89a319b5dc1d69e450/href\nIt's easy to reason about the code when try/catch guards a single statement. Things get worse quickly when it's necessary to handle multiple asynchronous calls.\nWrapping try/catch approach\nThis approach hides try/catch within the function. The function declaration states that it can return an error or a value. It allows using an if statement to control logic flow.\nhttps://medium.com/media/854916a7d5685d7ab15489298729ee77/href\nThe following example is the next step to generalise error handling. It uses TypeScript utility types to infer function parameters and output types.\nhttps://medium.com/media/6f3eb3febe9505b2c07c448ba553a1f0/href\nThe examples above use Deno read file API. To run them, use the following command:\n$ FILE=hello.txt deno run --allow-env=FILE --allow-read main.ts\nThanks for reading.\n\nTo Throw or Not to Throw? Error Propagation in JavaScript and TypeScript was originally published in Better Programming on Medium, where people are continuing the conversation by highlighting and responding to this story.","dc:creator":"Anton Klimenko","guid":"https://medium.com/p/68aaabe30e30","categories":["software-development","typescript","javascript","programming","error-handling"],"isoDate":"2022-12-14T18:26:17.000Z","from":"https://medium.com/feed/better-programming","hashId":"3b23010b34e001ed2d85aad45e1497b0"}]