[{"creator":"Stefan Avram ","title":"The Simplicity of tRPC with the Power of GraphQL ","link":"https://hackernoon.com/the-simplicity-of-trpc-with-the-power-of-graphql?source=rss","pubDate":"Wed, 14 Dec 2022 17:14:41 GMT","content:encoded":"<p>\\\nI'm a big fan of tRPC. The idea of exporting types from the server and importing them in the client to have a type-safe contract between both, even without a compile-time step, is simply brilliant. To all the people who are involved in tRPC, you're doing amazing work.</p>\n<p>\\\nThat said, when I'm looking at comparisons between tRPC and GraphQL, it seems like we're comparing apples and oranges.</p>\n<p>\\\nThis becomes especially apparent when you look at the public discourse around GraphQL and tRPC. Look at this diagram by <a href=\"https://twitter.com/t3dotgg?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598100163528052736%7Ctwgr%5E915a23463607e397f201c8e09ea80e12c1afa3e4%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwundergraph.com%2Fblog%2Ftrpc_vs_graphql\">theo</a> for example:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/-9b93prc.png\" alt=\"\" /></p>\n<p><a href=\"https://twitter.com/t3dotgg?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598100163528052736%7Ctwgr%5E915a23463607e397f201c8e09ea80e12c1afa3e4%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwundergraph.com%2Fblog%2Ftrpc_vs_graphql\">Theo</a> explained this diagram in depth and at first glance, it makes a lot of sense. tRPC doesn't require a compile-time step, the developer experience is incredible, and it's a lot simpler than GraphQL.</p>\n<p>\\\nBut is that really the full picture, or is this simplicity achieved at the cost of something else? Let's find out by building a simple app with both tRPC and GraphQL.</p>\n<h2 id=\"letsbuildafacebookclonewithtrpc\">Let's build a Facebook clone with tRPC</h2>\n<p>Let's imagine a file tree with a page for the news feed, a component for the feed list and a component for the feed item.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">src/pages/news-feed\n├── NewsFeed.tsx\n├── NewsFeedList.tsx\n└── NewsFeedItem.tsx\n</code></pre>\n<p>\\\nAt the very top of the feed page, we need some information about the user, notifications, unread messages, etc.</p>\n<p>\\\nWhen rendering the feed list, we need to know the number of feed items, if there's another page, and how to fetch it.</p>\n<p>\\\nFor the feed item, we need to know the author, the content, the number of likes, and if the user has liked it.</p>\n<p>\\\nIf we were to use tRPC, we would create a \"procedure\" to load all this data in one go. We'd call this procedure at the top of the page and then propagate the data down to the components.</p>\n<p>\\\nOur feed component would look something like this:</p>\n<pre><code class=\"typescript language-typescript\">import { trpc } from '../utils/trpc'\n\nexport function NewsFeed() {\n  const feed = trpc.newsFeed.useQuery()\n  return (\n    &lt;div&gt;\n      &lt;Avatar&gt;{feed.user}&lt;/Avatar&gt;\n      &lt;UnreadMessages&gt; {feed.unreadMessages} unread messages &lt;/UnreadMessages&gt;\n      &lt;Notifications&gt; {feed.notifications} notifications &lt;/Notifications&gt;\n      &lt;NewsFeedList feed={feed} /&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nNext, let's look at the feed list component:</p>\n<pre><code class=\"typescript language-typescript\">export function NewsFeedList({ feed }) {\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;News Feed&lt;/h1&gt;\n      &lt;p&gt;There are {feed.items.length} items&lt;/p&gt;\n      {feed.items.map((item) =&gt; (\n        &lt;NewsFeedItem item={item} /&gt;\n      ))}\n      {feed.hasNextPage &amp;&amp; (\n        &lt;button onClick={feed.fetchNextPage}&gt;Load more&lt;/button&gt;\n      )}\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nAnd finally, the feed item component:</p>\n<pre><code class=\"typescript language-typescript\">export function NewsFeedItem({ item }) {\n  return (\n    &lt;div&gt;\n      &lt;h2&gt;{item.author.name}&lt;/h2&gt;\n      &lt;p&gt;{item.content}&lt;/p&gt;\n      &lt;button onClick={item.like}&gt;Like&lt;/button&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nKeep in mind, we're still a single team, it's all TypeScript, one single codebase, and we're still using tRPC.</p>\n<p>\\\nLet's figure out what data we actually need to render the page. We need the user, the unread messages, the notifications, the feed items, the number of feed items, the next page, the author, the content, the number of likes, and if the user has liked it.</p>\n<p>\\\nWhere can we find detailed information about all of this? To understand the data requirements for the avatar, we need to look at the <code>Avatar</code> component. There are components for unread messages and notifications, so we need to look at those as well. The feed list component needs the number of items, the next page, and the feed items. The feed item component contains the requirements for each list item.</p>\n<p>\\\nIn total, if we want to understand the data requirements for this page, we need to look at 6 different components. At the same time, we don't really know what data is actually needed for each component. There's no way for each component to declare what data it needs as tRPC has no such concept.</p>\n<p>\\\nKeep in mind that this is just one single page. What happens if we add similar but slightly different pages?</p>\n<p>\\\nLet's say we're building a variant of the news feed, but instead of showing the latest posts, we're showing the most popular posts.</p>\n<p>\\\nWe could more or less use the same components, with just a few changes. Let's say that popular posts have special badges which require extra data.</p>\n<p>\\\nShould we create a new procedure for this? Or maybe we could just add a few more fields to the existing procedure?</p>\n<p>\\\nDoes this approach scale well if we're adding more and more pages? Does this not sound like the problem we've had with REST APIs? We've even got famous names for these problems, like Overfetching and Underfetching, and we haven't even gotten to the point where we're talking about the N+1 problem.</p>\n<p>\\\nAt some point we might decide to split the procedure into one root procedure and multiple sub-procedures. What if we're fetching an array at the root level, and then for each item in the array, we have to call another procedure to fetch more data?</p>\n<p>\\\nAnother open could be to introduce arguments to the initial version of our procedure, e.g. <code>trpc.newsFeed.useQuery({withPopularBadges: true})</code>.</p>\n<p>\\\nThis would work, but it feels like we're starting to re-invent the features of GraphQL.</p>\n<h2 id=\"letsbuildafacebookclonewithgraphql\">Let's build a Facebook clone with GraphQL</h2>\n<p>Now, let's contrast this with GraphQL. GraphQL has the concept of Fragments, which allows us to declare the data requirements for each component. Clients like Relay allow you to declare a single GraphQL query at the top of the page, and include fragments from the child components into the query.</p>\n<p>\\\nThis way, we're still making a single fetch at the top of the page, but the framework actually supports us in declaring and gathering the data requirements for each component.</p>\n<p>Let's look at the same example using GraphQL, Fragments, and Relay. For laziness reasons, the code is not 100% correct because I'm using Copilot to write it, but it should be very close to what it would look like in a real app.</p>\n<p>\\</p>\n<pre><code class=\"typescript language-typescript\">import { graphql } from 'react-relay'\n\nexport function NewsFeed() {\n  const feed = useQuery(graphql`\n    query NewsFeedQuery {\n      user {\n        ...Avatar_user\n      }\n      unreadMessages {\n        ...UnreadMessages_unreadMessages\n      }\n      notifications {\n        ...Notifications_notifications\n      }\n      ...NewsFeedList_feed\n    }\n  `)\n  return (\n    &lt;div&gt;\n      &lt;Avatar user={feed.user} /&gt;\n      &lt;UnreadMessages unreadMessages={feed.unreadMessages} /&gt;\n      &lt;Notifications notifications={feed.notifications} /&gt;\n      &lt;NewsFeedList feed={feed} /&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nNext, let's look at the feed list component. The feed list component declares a fragment for itself, and includes the fragment for the feed item component.</p>\n<p>\\</p>\n<pre><code class=\"typescript language-typescript\">import { graphql } from 'react-relay'\n\nexport function NewsFeedList({ feed }) {\n  const list = useFragment(\n    graphql`\n      fragment NewsFeedList_feed on NewsFeed {\n        items {\n          ...NewsFeedItem_item\n        }\n        hasNextPage\n      }\n    `,\n    feed\n  )\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;News Feed&lt;/h1&gt;\n      &lt;p&gt;There are {feed.items.length} items&lt;/p&gt;\n      {feed.items.map((item) =&gt; (\n        &lt;NewsFeedItem item={item} /&gt;\n      ))}\n      {feed.hasNextPage &amp;&amp; (\n        &lt;button onClick={feed.fetchNextPage}&gt;Load more&lt;/button&gt;\n      )}\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nAnd finally, the feed item component:</p>\n<pre><code class=\"typescript language-typescript\">import { graphql } from 'react-relay'\n\nexport function NewsFeedItem({ item }) {\n  const item = useFragment(\n    graphql`\n      fragment NewsFeedItem_item on NewsFeedItem {\n        author {\n          name\n        }\n        content\n        likes\n        hasLiked\n      }\n    `,\n    item\n  )\n  return (\n    &lt;div&gt;\n      &lt;h2&gt;{item.author.name}&lt;/h2&gt;\n      &lt;p&gt;{item.content}&lt;/p&gt;\n      &lt;button onClick={item.like}&gt;Like&lt;/button&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nNext, let's create a variation of the news feed with popular badges on feed items. We can reuse the same components, as we're able to use the <code>@include</code> directive to conditionally include the popular badge fragment.</p>\n<pre><code class=\"typescript language-typescript\">import { graphql } from 'react-relay'\n\nexport function PopularNewsFeed() {\n  const feed = useQuery(graphql`\n    query PopularNewsFeedQuery($withPopularBadges: Boolean!) {\n      user {\n        ...Avatar_user\n      }\n      unreadMessages {\n        ...UnreadMessages_unreadMessages\n      }\n      notifications {\n        ...Notifications_notifications\n      }\n      ...NewsFeedList_feed\n    }\n  `)\n  return (\n    &lt;div&gt;\n      &lt;Avatar user={feed.user} /&gt;\n      &lt;UnreadMessages unreadMessages={feed.unreadMessages} /&gt;\n      &lt;Notifications notifications={feed.notifications} /&gt;\n      &lt;NewsFeedList feed={feed} /&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nNext, let's look at how the updated feed list item could look like:</p>\n<pre><code class=\"typescript language-typescript\">import { graphql } from 'react-relay'\n\nexport function NewsFeedItem({ item }) {\n  const item = useFragment(\n    graphql`\n      fragment NewsFeedItem_item on NewsFeedItem {\n        author {\n          name\n        }\n        content\n        likes\n        hasLiked\n        ...PopularBadge_item @include(if: $withPopularBadges)\n      }\n    `,\n    item\n  )\n  return (\n    &lt;div&gt;\n      &lt;h2&gt;{item.author.name}&lt;/h2&gt;\n      &lt;p&gt;{item.content}&lt;/p&gt;\n      &lt;button onClick={item.like}&gt;Like&lt;/button&gt;\n      {item.popularBadge &amp;&amp; &lt;PopularBadge badge={item.popularBadge} /&gt;}\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nAs you can see, GraphQL is quite flexible and allows us to build complex web applications, including variations of the same page, without having to duplicate too much code.</p>\n<h2 id=\"graphqlfragmentsallowustodeclaredatarequirementsatthecomponentlevel\">GraphQL Fragments allow us to declare data requirements at the component level</h2>\n<p>Moreover, GraphQL Fragments allow us to explicitly declare the data requirements for each component, which get then hoisted up to the top of the page, and then fetched in a single request.</p>\n<p>\\</p>\n<h2 id=\"graphqlseparatesapiimplementationfromdatafetching\">GraphQL separates API implementation from data fetching</h2>\n<p>The great developer experience of tRPC is achieved by merging two very different concerns into one concept, API implementation and data consumption.</p>\n<p>\\\nIt's important to understand that this is a trade-off. There's no free lunch. The simplicity of tRPC comes at the cost of flexibility.</p>\n<p>\\\nWith GraphQL, you have to invest a lot more into schema design, but this investment pays off the moment you have to scale your application to many but related pages.</p>\n<p>\\\nBy separating API implementation from data fetching it becomes much easier to re-use the same API implementation for different use cases.</p>\n<h2 id=\"thepurposeofapisistoseparatetheinternalimplementationfromtheexternalinterface\">The purpose of APIs is to separate the internal implementation from the external interface</h2>\n<p>There's another important aspect to consider when building APIs. You might be starting with an internal API that's exclusively used by your own frontend, and tRPC might be a great fit for this use case.</p>\n<p>\\\nBut what about the future of your endeavor? What's the likelihood that you'll be growing your team? Is it possible that other teams, or even 3rd parties will want to consume your APIs?</p>\n<p>Both REST and GraphQL are built with collaboration in mind. Not all teams will be using TypeScript, and if you're crossing company boundaries, you'll want to expose APIs in a way that's easy to understand and consume.</p>\n<p>\\\nThere's a lot of tooling to expose and document REST and GraphQL APIs, while tRPC is clearly not designed for this use case.</p>\n<p>\\\nSo, while it's great to start with tRPC, you're very likely to outgrow it at some point, which I think theo also mentioned in one of his videos.</p>\n<p>\\\nIt's certainly possible to generate an OpenAPI specification from a tRPC API, the tooling exists, but if you're building a business that will eventually rely on exposing APIs to 3rd parties, your RPCs will not be able to compete against well-designed REST and GraphQL APIs.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>As stated in the beginning, I'm a big fan of the ideas behind tRPC. It's a great step into the right direction, making data fetching simpler and more developer friendly.</p>\n<p>\\\nGraphQL, Fragments, and Relay on the other hand are powerful tools that help you build complex web applications. At the same time, the setup is quite complex and there are many concepts to learn until you're getting the hang of it.</p>\n<p>\\\nWhile tRPC gets you started quickly, it's very likely that you'll outgrow its architecture at some point.If you're making a decision today to bet on either GraphQL or tRPC, you should take into account where you see your project going in the future. How complex will the data fetching requirements be? Will there be multiple teams consuming your APIs? Will you be exposing your APIs to 3rd parties?</p>\n<p>\\</p>\n<h2 id=\"outlook\">Outlook</h2>\n<p>With all that said, what if we could combine the best of both worlds? How would an API client look like that combines the simplicity of tRPC with the power of GraphQL? Could we build a pure TypeScript API client that gives us the power of Fragments and Relay, combined with the simplicity of tRPC?</p>\n<p>\\\nImagine we take the ideas of tRPC and combine them with what we've learned from GraphQL and Relay.</p>\n<p>\\\nHere's a little preview:</p>\n<p>\\</p>\n<pre><code class=\"typescript language-typescript\">// src/pages/index.tsx\nimport { useQuery } from '../../.wundergraph/generated/client'\nimport { Avatar_user } from '../components/Avatar'\nimport { UnreadMessages_unreadMessages } from '../components/UnreadMessages'\nimport { Notifications_notifications } from '../components/Notifications'\nimport { NewsFeedList_feed } from '../components/NewsFeedList'\nexport function NewsFeed() {\n  const feed = useQuery({\n    operationName: 'NewsFeed',\n    query: (q) =&gt; ({\n      user: q.user({\n        ...Avatar_user.fragment,\n      }),\n      unreadMessages: q.unreadMessages({\n        ...UnreadMessages_unreadMessages.fragment,\n      }),\n      notifications: q.notifications({\n        ...Notifications_notifications.fragment,\n      }),\n      ...NewsFeedList_feed.fragment,\n    }),\n  })\n  return (\n    &lt;div&gt;\n      &lt;Avatar /&gt;\n      &lt;UnreadMessages /&gt;\n      &lt;Notifications /&gt;\n      &lt;NewsFeedList /&gt;\n    &lt;/div&gt;\n  )\n}\n\n// src/components/Avatar.tsx\nimport { useFragment, Fragment } from '../../.wundergraph/generated/client'\nexport const Avatar_user = Fragment({\n  on: 'User',\n  fragment: ({ name, avatar }) =&gt; ({\n    name,\n    avatar,\n  }),\n})\nexport function Avatar() {\n  const data = useFragment(Avatar_user)\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;{data.name}&lt;/h1&gt;\n      &lt;img src={data.avatar} /&gt;\n    &lt;/div&gt;\n  )\n}\n\n// src/components/NewsFeedList.tsx\nimport { useFragment, Fragment } from '../../.wundergraph/generated/client'\nimport { NewsFeedItem_item } from './NewsFeedItem'\nexport const NewsFeedList_feed = Fragment({\n  on: 'NewsFeed',\n  fragment: ({ items }) =&gt; ({\n    items: items({\n      ...NewsFeedItem_item.fragment,\n    }),\n  }),\n})\nexport function NewsFeedList() {\n  const data = useFragment(NewsFeedList_feed)\n  return (\n    &lt;div&gt;\n      {data.items.map((item) =&gt; (\n        &lt;NewsFeedItem item={item} /&gt;\n      ))}\n    &lt;/div&gt;\n  )\n}\n\n// src/components/NewsFeedItem.tsx\nimport { useFragment, Fragment } from '../../.wundergraph/generated/client'\nexport const NewsFeedItem_item = Fragment({\n  on: 'NewsFeedItem',\n  fragment: ({ id, author, content }) =&gt; ({\n    id,\n    author,\n    content,\n  }),\n})\nexport function NewsFeedItem() {\n  const data = useFragment(NewsFeedItem_item)\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;{data.title}&lt;/h1&gt;\n      &lt;p&gt;{data.content}&lt;/p&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>\n<p>\\\nWhat do you think? Would you use something like this? Do you see the value in defining data dependencies at the component level, or do you prefer to stick with defining remote procedures at the page level? I'd love to hear your thoughts…</p>\n<p>\\\nWe're currently in the design phase to build the best data fetching experience for React, NextJS and all other frameworks. If you're interested in this topic, follow me on <a href=\"https://twitter.com/jensneuse_de\">Twitter</a> to stay up to date.</p>\n<p>\\\nIf you'd like to join the discussion and discuss RFCs with us, feel free to join our <a href=\"https://wundergraph.com/discord\">Discord</a> server.</p>\n<p>Next</p>","content:encodedSnippet":"\\\nI'm a big fan of tRPC. The idea of exporting types from the server and importing them in the client to have a type-safe contract between both, even without a compile-time step, is simply brilliant. To all the people who are involved in tRPC, you're doing amazing work.\n\\\nThat said, when I'm looking at comparisons between tRPC and GraphQL, it seems like we're comparing apples and oranges.\n\\\nThis becomes especially apparent when you look at the public discourse around GraphQL and tRPC. Look at this diagram by theo for example:\n\nTheo explained this diagram in depth and at first glance, it makes a lot of sense. tRPC doesn't require a compile-time step, the developer experience is incredible, and it's a lot simpler than GraphQL.\n\\\nBut is that really the full picture, or is this simplicity achieved at the cost of something else? Let's find out by building a simple app with both tRPC and GraphQL.\nLet's build a Facebook clone with tRPC\nLet's imagine a file tree with a page for the news feed, a component for the feed list and a component for the feed item.\n\\\nsrc/pages/news-feed\n├── NewsFeed.tsx\n├── NewsFeedList.tsx\n└── NewsFeedItem.tsx\n\n\\\nAt the very top of the feed page, we need some information about the user, notifications, unread messages, etc.\n\\\nWhen rendering the feed list, we need to know the number of feed items, if there's another page, and how to fetch it.\n\\\nFor the feed item, we need to know the author, the content, the number of likes, and if the user has liked it.\n\\\nIf we were to use tRPC, we would create a \"procedure\" to load all this data in one go. We'd call this procedure at the top of the page and then propagate the data down to the components.\n\\\nOur feed component would look something like this:\nimport { trpc } from '../utils/trpc'\n\nexport function NewsFeed() {\n  const feed = trpc.newsFeed.useQuery()\n  return (\n    <div>\n      <Avatar>{feed.user}</Avatar>\n      <UnreadMessages> {feed.unreadMessages} unread messages </UnreadMessages>\n      <Notifications> {feed.notifications} notifications </Notifications>\n      <NewsFeedList feed={feed} />\n    </div>\n  )\n}\n\n\\\nNext, let's look at the feed list component:\nexport function NewsFeedList({ feed }) {\n  return (\n    <div>\n      <h1>News Feed</h1>\n      <p>There are {feed.items.length} items</p>\n      {feed.items.map((item) => (\n        <NewsFeedItem item={item} />\n      ))}\n      {feed.hasNextPage && (\n        <button onClick={feed.fetchNextPage}>Load more</button>\n      )}\n    </div>\n  )\n}\n\n\\\nAnd finally, the feed item component:\nexport function NewsFeedItem({ item }) {\n  return (\n    <div>\n      <h2>{item.author.name}</h2>\n      <p>{item.content}</p>\n      <button onClick={item.like}>Like</button>\n    </div>\n  )\n}\n\n\\\nKeep in mind, we're still a single team, it's all TypeScript, one single codebase, and we're still using tRPC.\n\\\nLet's figure out what data we actually need to render the page. We need the user, the unread messages, the notifications, the feed items, the number of feed items, the next page, the author, the content, the number of likes, and if the user has liked it.\n\\\nWhere can we find detailed information about all of this? To understand the data requirements for the avatar, we need to look at the Avatar component. There are components for unread messages and notifications, so we need to look at those as well. The feed list component needs the number of items, the next page, and the feed items. The feed item component contains the requirements for each list item.\n\\\nIn total, if we want to understand the data requirements for this page, we need to look at 6 different components. At the same time, we don't really know what data is actually needed for each component. There's no way for each component to declare what data it needs as tRPC has no such concept.\n\\\nKeep in mind that this is just one single page. What happens if we add similar but slightly different pages?\n\\\nLet's say we're building a variant of the news feed, but instead of showing the latest posts, we're showing the most popular posts.\n\\\nWe could more or less use the same components, with just a few changes. Let's say that popular posts have special badges which require extra data.\n\\\nShould we create a new procedure for this? Or maybe we could just add a few more fields to the existing procedure?\n\\\nDoes this approach scale well if we're adding more and more pages? Does this not sound like the problem we've had with REST APIs? We've even got famous names for these problems, like Overfetching and Underfetching, and we haven't even gotten to the point where we're talking about the N+1 problem.\n\\\nAt some point we might decide to split the procedure into one root procedure and multiple sub-procedures. What if we're fetching an array at the root level, and then for each item in the array, we have to call another procedure to fetch more data?\n\\\nAnother open could be to introduce arguments to the initial version of our procedure, e.g. trpc.newsFeed.useQuery({withPopularBadges: true}).\n\\\nThis would work, but it feels like we're starting to re-invent the features of GraphQL.\nLet's build a Facebook clone with GraphQL\nNow, let's contrast this with GraphQL. GraphQL has the concept of Fragments, which allows us to declare the data requirements for each component. Clients like Relay allow you to declare a single GraphQL query at the top of the page, and include fragments from the child components into the query.\n\\\nThis way, we're still making a single fetch at the top of the page, but the framework actually supports us in declaring and gathering the data requirements for each component.\nLet's look at the same example using GraphQL, Fragments, and Relay. For laziness reasons, the code is not 100% correct because I'm using Copilot to write it, but it should be very close to what it would look like in a real app.\n\\\nimport { graphql } from 'react-relay'\n\nexport function NewsFeed() {\n  const feed = useQuery(graphql`\n    query NewsFeedQuery {\n      user {\n        ...Avatar_user\n      }\n      unreadMessages {\n        ...UnreadMessages_unreadMessages\n      }\n      notifications {\n        ...Notifications_notifications\n      }\n      ...NewsFeedList_feed\n    }\n  `)\n  return (\n    <div>\n      <Avatar user={feed.user} />\n      <UnreadMessages unreadMessages={feed.unreadMessages} />\n      <Notifications notifications={feed.notifications} />\n      <NewsFeedList feed={feed} />\n    </div>\n  )\n}\n\n\\\nNext, let's look at the feed list component. The feed list component declares a fragment for itself, and includes the fragment for the feed item component.\n\\\nimport { graphql } from 'react-relay'\n\nexport function NewsFeedList({ feed }) {\n  const list = useFragment(\n    graphql`\n      fragment NewsFeedList_feed on NewsFeed {\n        items {\n          ...NewsFeedItem_item\n        }\n        hasNextPage\n      }\n    `,\n    feed\n  )\n  return (\n    <div>\n      <h1>News Feed</h1>\n      <p>There are {feed.items.length} items</p>\n      {feed.items.map((item) => (\n        <NewsFeedItem item={item} />\n      ))}\n      {feed.hasNextPage && (\n        <button onClick={feed.fetchNextPage}>Load more</button>\n      )}\n    </div>\n  )\n}\n\n\\\nAnd finally, the feed item component:\nimport { graphql } from 'react-relay'\n\nexport function NewsFeedItem({ item }) {\n  const item = useFragment(\n    graphql`\n      fragment NewsFeedItem_item on NewsFeedItem {\n        author {\n          name\n        }\n        content\n        likes\n        hasLiked\n      }\n    `,\n    item\n  )\n  return (\n    <div>\n      <h2>{item.author.name}</h2>\n      <p>{item.content}</p>\n      <button onClick={item.like}>Like</button>\n    </div>\n  )\n}\n\n\\\nNext, let's create a variation of the news feed with popular badges on feed items. We can reuse the same components, as we're able to use the @include directive to conditionally include the popular badge fragment.\nimport { graphql } from 'react-relay'\n\nexport function PopularNewsFeed() {\n  const feed = useQuery(graphql`\n    query PopularNewsFeedQuery($withPopularBadges: Boolean!) {\n      user {\n        ...Avatar_user\n      }\n      unreadMessages {\n        ...UnreadMessages_unreadMessages\n      }\n      notifications {\n        ...Notifications_notifications\n      }\n      ...NewsFeedList_feed\n    }\n  `)\n  return (\n    <div>\n      <Avatar user={feed.user} />\n      <UnreadMessages unreadMessages={feed.unreadMessages} />\n      <Notifications notifications={feed.notifications} />\n      <NewsFeedList feed={feed} />\n    </div>\n  )\n}\n\n\\\nNext, let's look at how the updated feed list item could look like:\nimport { graphql } from 'react-relay'\n\nexport function NewsFeedItem({ item }) {\n  const item = useFragment(\n    graphql`\n      fragment NewsFeedItem_item on NewsFeedItem {\n        author {\n          name\n        }\n        content\n        likes\n        hasLiked\n        ...PopularBadge_item @include(if: $withPopularBadges)\n      }\n    `,\n    item\n  )\n  return (\n    <div>\n      <h2>{item.author.name}</h2>\n      <p>{item.content}</p>\n      <button onClick={item.like}>Like</button>\n      {item.popularBadge && <PopularBadge badge={item.popularBadge} />}\n    </div>\n  )\n}\n\n\\\nAs you can see, GraphQL is quite flexible and allows us to build complex web applications, including variations of the same page, without having to duplicate too much code.\nGraphQL Fragments allow us to declare data requirements at the component level\nMoreover, GraphQL Fragments allow us to explicitly declare the data requirements for each component, which get then hoisted up to the top of the page, and then fetched in a single request.\n\\\nGraphQL separates API implementation from data fetching\nThe great developer experience of tRPC is achieved by merging two very different concerns into one concept, API implementation and data consumption.\n\\\nIt's important to understand that this is a trade-off. There's no free lunch. The simplicity of tRPC comes at the cost of flexibility.\n\\\nWith GraphQL, you have to invest a lot more into schema design, but this investment pays off the moment you have to scale your application to many but related pages.\n\\\nBy separating API implementation from data fetching it becomes much easier to re-use the same API implementation for different use cases.\nThe purpose of APIs is to separate the internal implementation from the external interface\nThere's another important aspect to consider when building APIs. You might be starting with an internal API that's exclusively used by your own frontend, and tRPC might be a great fit for this use case.\n\\\nBut what about the future of your endeavor? What's the likelihood that you'll be growing your team? Is it possible that other teams, or even 3rd parties will want to consume your APIs?\nBoth REST and GraphQL are built with collaboration in mind. Not all teams will be using TypeScript, and if you're crossing company boundaries, you'll want to expose APIs in a way that's easy to understand and consume.\n\\\nThere's a lot of tooling to expose and document REST and GraphQL APIs, while tRPC is clearly not designed for this use case.\n\\\nSo, while it's great to start with tRPC, you're very likely to outgrow it at some point, which I think theo also mentioned in one of his videos.\n\\\nIt's certainly possible to generate an OpenAPI specification from a tRPC API, the tooling exists, but if you're building a business that will eventually rely on exposing APIs to 3rd parties, your RPCs will not be able to compete against well-designed REST and GraphQL APIs.\nConclusion\nAs stated in the beginning, I'm a big fan of the ideas behind tRPC. It's a great step into the right direction, making data fetching simpler and more developer friendly.\n\\\nGraphQL, Fragments, and Relay on the other hand are powerful tools that help you build complex web applications. At the same time, the setup is quite complex and there are many concepts to learn until you're getting the hang of it.\n\\\nWhile tRPC gets you started quickly, it's very likely that you'll outgrow its architecture at some point.If you're making a decision today to bet on either GraphQL or tRPC, you should take into account where you see your project going in the future. How complex will the data fetching requirements be? Will there be multiple teams consuming your APIs? Will you be exposing your APIs to 3rd parties?\n\\\nOutlook\nWith all that said, what if we could combine the best of both worlds? How would an API client look like that combines the simplicity of tRPC with the power of GraphQL? Could we build a pure TypeScript API client that gives us the power of Fragments and Relay, combined with the simplicity of tRPC?\n\\\nImagine we take the ideas of tRPC and combine them with what we've learned from GraphQL and Relay.\n\\\nHere's a little preview:\n\\\n// src/pages/index.tsx\nimport { useQuery } from '../../.wundergraph/generated/client'\nimport { Avatar_user } from '../components/Avatar'\nimport { UnreadMessages_unreadMessages } from '../components/UnreadMessages'\nimport { Notifications_notifications } from '../components/Notifications'\nimport { NewsFeedList_feed } from '../components/NewsFeedList'\nexport function NewsFeed() {\n  const feed = useQuery({\n    operationName: 'NewsFeed',\n    query: (q) => ({\n      user: q.user({\n        ...Avatar_user.fragment,\n      }),\n      unreadMessages: q.unreadMessages({\n        ...UnreadMessages_unreadMessages.fragment,\n      }),\n      notifications: q.notifications({\n        ...Notifications_notifications.fragment,\n      }),\n      ...NewsFeedList_feed.fragment,\n    }),\n  })\n  return (\n    <div>\n      <Avatar />\n      <UnreadMessages />\n      <Notifications />\n      <NewsFeedList />\n    </div>\n  )\n}\n\n// src/components/Avatar.tsx\nimport { useFragment, Fragment } from '../../.wundergraph/generated/client'\nexport const Avatar_user = Fragment({\n  on: 'User',\n  fragment: ({ name, avatar }) => ({\n    name,\n    avatar,\n  }),\n})\nexport function Avatar() {\n  const data = useFragment(Avatar_user)\n  return (\n    <div>\n      <h1>{data.name}</h1>\n      <img src={data.avatar} />\n    </div>\n  )\n}\n\n// src/components/NewsFeedList.tsx\nimport { useFragment, Fragment } from '../../.wundergraph/generated/client'\nimport { NewsFeedItem_item } from './NewsFeedItem'\nexport const NewsFeedList_feed = Fragment({\n  on: 'NewsFeed',\n  fragment: ({ items }) => ({\n    items: items({\n      ...NewsFeedItem_item.fragment,\n    }),\n  }),\n})\nexport function NewsFeedList() {\n  const data = useFragment(NewsFeedList_feed)\n  return (\n    <div>\n      {data.items.map((item) => (\n        <NewsFeedItem item={item} />\n      ))}\n    </div>\n  )\n}\n\n// src/components/NewsFeedItem.tsx\nimport { useFragment, Fragment } from '../../.wundergraph/generated/client'\nexport const NewsFeedItem_item = Fragment({\n  on: 'NewsFeedItem',\n  fragment: ({ id, author, content }) => ({\n    id,\n    author,\n    content,\n  }),\n})\nexport function NewsFeedItem() {\n  const data = useFragment(NewsFeedItem_item)\n  return (\n    <div>\n      <h1>{data.title}</h1>\n      <p>{data.content}</p>\n    </div>\n  )\n}\n\n\\\nWhat do you think? Would you use something like this? Do you see the value in defining data dependencies at the component level, or do you prefer to stick with defining remote procedures at the page level? I'd love to hear your thoughts…\n\\\nWe're currently in the design phase to build the best data fetching experience for React, NextJS and all other frameworks. If you're interested in this topic, follow me on Twitter to stay up to date.\n\\\nIf you'd like to join the discussion and discuss RFCs with us, feel free to join our Discord server.\nNext","dc:creator":"Stefan Avram ","guid":"https://hackernoon.com/the-simplicity-of-trpc-with-the-power-of-graphql?source=rss","categories":["graphql","trpc","typescript","facebook","web-development","react","programming","webdev","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja"],"isoDate":"2022-12-14T17:14:41.000Z","from":"https://hackernoon.com/feed","hashId":"b421fd2f76af4ce2af6c970e9a530da7"},{"creator":"kevin","title":"Which Framework Must You Implement for Your Next Project? (Next Js VS React)","link":"https://hackernoon.com/which-framework-must-you-implement-for-your-next-project-next-js-vs-react?source=rss","pubDate":"Wed, 14 Dec 2022 18:03:38 GMT","content:encoded":"<div class=\"paragraph\">React and Next JS are effective JavaScript frameworks for developing web applications and websites. These frameworks are used by a large community of developers all over the world. Both are open-source projects for developing powerful and interactive web applications, but which should you use? If you are perplexed by the question of <a href=\"https://dorustree.com/hire-reactjs-developers/\">Next JS vs React</a>, this blog will be of assistance.</div><div class=\"paragraph\">Let&#x27;s compare and contrast these two powerful frameworks to see which one you should use for your next project!</div><div class=\"paragraph\">Finding the right framework can be difficult due to the abundance of available Java script (JS) libraries and frameworks. Despite the numerous options, two frameworks are widely used by developers and businesses alike: Next JS to React.</div><h2>What is React?</h2><div class=\"paragraph\">React is a JavaScript library for creating user interfaces that are declarative, efficient, and flexible. It enables you to create complex user interfaces by assembling small, isolated pieces of code known as components. React is unique because it works with a virtual DOM rather than the Document Object Model (DOM). This means that when you make changes to your UI, React only updates the parts of the DOM that are necessary, making your app more performant.</div><h2>What is Next.js?</h2><div class=\"paragraph\"><a href=\"https://hackernoon.com/what-is-nextjs-and-how-to-debug-it-82523t65\">Next.js</a> is one of the most lightweight frameworks for React applications on the market. Web app development companies use Next.js to create a ready-to-use application with its server-side rendering and static site features. It allows developers to create a React app that uses server-side rendering to save the app&#x27;s data in advance on the server. As a result, search bots and visitors can interact with a fully interactive website as well as a pre-rendered HTML page. This ensures that visitors to the app will see an interactive web app in less than three seconds.</div><h2>The pros and cons of React</h2><div class=\"paragraph\">For a variety of reasons, React is popular among developers. Here&#x27;s a rundown of the advantages and disadvantages of using React for your next front-end project.</div><h2>The Advantages of Using React</h2><div class=\"paragraph\">1. <strong>Performance Improvement</strong></div><div class=\"paragraph\">Its performance is one of the reasons for its success. To manage user interface updates, React employs a virtual DOM. As a result, React apps are quick and responsive. Only the relevant parts of the DOM are updated when a user interacts with a React app. This eliminates the need to redraw the entire page. As a result, React apps are significantly faster than traditional JavaScript frameworks.</div><div class=\"paragraph\">React can also be combined with other libraries and frameworks to create even more powerful applications. React is an excellent choice for creating high-performance user interfaces for these reasons.</div><div class=\"paragraph\">2. <strong>Components that are reusable</strong></div><div class=\"paragraph\">Web applications built with React are made up of reusable components, each with its own logic and controls. This reusability enables developers to recycle components and reuse them on different pages while retaining their properties. Furthermore, you can change the code of the components, and the change will be reflected across all pages.</div><div class=\"paragraph\">3. <strong>Easy to Learn</strong></div><div class=\"paragraph\">Because React JS is an open-source tool, any developer can create tutorials, training tools, and other documentation to help new and experienced developers alike learn. Developers with a JavaScript background will find that they can learn the ins and outs of React in a matter of days.</div><div class=\"paragraph\">Furthermore, because the tool is open-source and simple to learn, business owners and hiring managers will have an easier time finding web developers with React JS experience and knowledge. The ease of learning React also benefits developers with prior experience with React JS. Because React is an open-source tool, development improvements are constantly being made, so developers must stay up to date on the latest improvements.</div><div class=\"paragraph\">4. <strong>Dynamic web applications are simple to create</strong></div><div class=\"paragraph\">In general, dynamic web applications require HTML strings, which makes them more complex. However, because it is built on JavaScript, React allows developers to easily build dynamic web applications with less coding.</div><h2>The Disadvantages of Using React</h2><div class=\"paragraph\">1. <strong>Documentation is too frequently updated</strong></div><div class=\"paragraph\">Another disadvantage of constantly updated technologies is this. React technologies are updated and accelerated at such a rapid pace that there is insufficient time to create proper documentation. To address this, developers write their own instructions as new releases and tools become available in their current projects.</div><div class=\"paragraph\">2. <strong>Fast-Developing</strong></div><div class=\"paragraph\">React.js has grown in popularity in recent years due to its rapid development. However, this has resulted in some disadvantages for developers.</div><div class=\"paragraph\">One of the most serious issues is that React.js is constantly evolving, making it difficult to keep up with the latest enhancements. This means that developers must devote a significant amount of time to staying current with the React ecosystem, which may be a turnoff for some.</div><div class=\"paragraph\">Furthermore, the rapid pace of development can lead to bugs and instability in React applications.</div><div class=\"paragraph\">3. <strong>Inattention to User Interface</strong></div><div class=\"paragraph\">React includes a plethora of tools for developing and creating user interfaces. React JS, unlike frameworks, is not an &quot;all-in-one&quot; app development tool. As a result, if you use a model-view-controller (MVC), React development is only responsible for the user interface. Other tools must be used by the developers to create the model and controller. To create a functional application, you will need to use additional tools that will cover other critical components such as the backend and data storage.</div><div class=\"paragraph\">Additional tools will be required for app programming interfaces (APIs), routing, and other components.</div><h2>The pros and cons of Next Js</h2><div class=\"paragraph\">These pros and cons will help you gain a better understanding of what Next.js can do based on your goal, length of usage, and production requirements.</div><h2>The Advantages of Using Next Js</h2><div class=\"paragraph\">1. <strong>Speed</strong></div><div class=\"paragraph\">Next.js applications run quickly because of Server-side Rendering and Dynamic Synthesis, which provide a more intelligent way of handling data. The response time of the server to queries determines the speed of server-side rendering. It is quick because static material can be delivered over a CDN. Additionally, native image optimization tools improve efficiency.</div><div class=\"paragraph\">2. <strong>It is simple to code</strong></div><div class=\"paragraph\">Next.js requires less code than React and other frameworks that work with React. Developers only need to create the page and include a link to the component in the header, resulting in less code, better readability, and better project management.</div><div class=\"paragraph\">3. <strong>Simple customization</strong></div><div class=\"paragraph\">Next JS is highly customizable because it makes use of plugins like babel. Its deployment is also simple, and it allows it to launch applications quickly.</div><div class=\"paragraph\">4. <strong>Fast rendering</strong></div><div class=\"paragraph\">Every change to the content is immediately visible by reloading the website. Because the component is immediately displayed, it is easier to track changes as they occur.</div><div class=\"paragraph\">5. <strong>CSS support</strong></div><div class=\"paragraph\">The built-in CSS support in Next.js is a key feature. This means that developers can incorporate CSS Stylesheets into their Next.js projects without requiring the use of any additional libraries or tooling. This is especially useful for small projects where adding a CSS preprocessor would be overkill.</div><div class=\"paragraph\">Furthermore, because CSS support is built-in, developers can use features like server-side rendering and code splitting without worrying about whether their CSS will be properly processed.</div><h2>The Disadvantages of Using Next Js</h2><div class=\"paragraph\">1. <strong>Routing﻿</strong></div><div class=\"paragraph\">It&#x27;s a file-based router, which means it&#x27;s a file system that handles responses and requests via files. These file projects are sometimes insufficient for some projects. To create or use dynamic routes, you&#x27;ll need NodeJS, which requires skilled developers.</div><div class=\"paragraph\">2. <strong>Community</strong></div><div class=\"paragraph\">It is still small, but it is growing by the day as Next.js becomes one of the most popular web building blocks. There are fewer Next.js experts than there are React or other frameworks, but it is not a new framework. The talent pool and demand for Next.js developers are growing, creating opportunities for those looking to make a name for themselves in modern application development.</div><h2>Is Next.js a better framework than React?</h2><div class=\"paragraph\">&quot;Is Next JS Better Than <a href=\"https://reactjs.org/\">React</a>?&quot; appears to be an inappropriate question in my opinion. However, the best technology or library to use is determined by your project&#x27;s requirements and business objectives.</div><div class=\"paragraph\">React and Next.js is rapidly becoming the most important components of the overall digital experience. They provide a more seamless and faster project experience at a lower development cost.</div><h2>Which is better, Next JS or React JS?</h2><div class=\"paragraph\">There is no correct answer to this question. As previously stated, choosing a framework or library is entirely dependent on the requirements of your project. React and Next.js are new and useful tools for your project, but they are only useful for certain tasks.</div><div class=\"paragraph\">Next.js provides the most effective server-side rendering and static website development solutions. It also allows you to easily manage projects by providing a variety of tools and features.</div><div class=\"paragraph\">React, on the other hand, is the best choice for creating user interfaces for single-page apps. It enables you to create more appealing and intuitive applications because it works with the layer of mobile and web apps.</div><h2>Conclusion</h2><div class=\"paragraph\">In a nutshell, Next.js provides a variety of tools and features to streamline the development process, whereas React.js has more resources for the front-end development of your mobile and web applications.</div><div class=\"paragraph\">In my opinion, both React and Next.js are fantastic, powerful tools for building beautiful, snappy web apps, and there is no clear winner. They perform different functions.</div>","content:encodedSnippet":"React and Next JS are effective JavaScript frameworks for developing web applications and websites. These frameworks are used by a large community of developers all over the world. Both are open-source projects for developing powerful and interactive web applications, but which should you use? If you are perplexed by the question of Next JS vs React, this blog will be of assistance.\nLet's compare and contrast these two powerful frameworks to see which one you should use for your next project!\nFinding the right framework can be difficult due to the abundance of available Java script (JS) libraries and frameworks. Despite the numerous options, two frameworks are widely used by developers and businesses alike: Next JS to React.\nWhat is React?\nReact is a JavaScript library for creating user interfaces that are declarative, efficient, and flexible. It enables you to create complex user interfaces by assembling small, isolated pieces of code known as components. React is unique because it works with a virtual DOM rather than the Document Object Model (DOM). This means that when you make changes to your UI, React only updates the parts of the DOM that are necessary, making your app more performant.\nWhat is Next.js?\nNext.js is one of the most lightweight frameworks for React applications on the market. Web app development companies use Next.js to create a ready-to-use application with its server-side rendering and static site features. It allows developers to create a React app that uses server-side rendering to save the app's data in advance on the server. As a result, search bots and visitors can interact with a fully interactive website as well as a pre-rendered HTML page. This ensures that visitors to the app will see an interactive web app in less than three seconds.\nThe pros and cons of React\nFor a variety of reasons, React is popular among developers. Here's a rundown of the advantages and disadvantages of using React for your next front-end project.\nThe Advantages of Using React\n1. Performance Improvement\nIts performance is one of the reasons for its success. To manage user interface updates, React employs a virtual DOM. As a result, React apps are quick and responsive. Only the relevant parts of the DOM are updated when a user interacts with a React app. This eliminates the need to redraw the entire page. As a result, React apps are significantly faster than traditional JavaScript frameworks.\nReact can also be combined with other libraries and frameworks to create even more powerful applications. React is an excellent choice for creating high-performance user interfaces for these reasons.\n2. Components that are reusable\nWeb applications built with React are made up of reusable components, each with its own logic and controls. This reusability enables developers to recycle components and reuse them on different pages while retaining their properties. Furthermore, you can change the code of the components, and the change will be reflected across all pages.\n3. Easy to Learn\nBecause React JS is an open-source tool, any developer can create tutorials, training tools, and other documentation to help new and experienced developers alike learn. Developers with a JavaScript background will find that they can learn the ins and outs of React in a matter of days.\nFurthermore, because the tool is open-source and simple to learn, business owners and hiring managers will have an easier time finding web developers with React JS experience and knowledge. The ease of learning React also benefits developers with prior experience with React JS. Because React is an open-source tool, development improvements are constantly being made, so developers must stay up to date on the latest improvements.\n4. Dynamic web applications are simple to create\nIn general, dynamic web applications require HTML strings, which makes them more complex. However, because it is built on JavaScript, React allows developers to easily build dynamic web applications with less coding.\nThe Disadvantages of Using React\n1. Documentation is too frequently updated\nAnother disadvantage of constantly updated technologies is this. React technologies are updated and accelerated at such a rapid pace that there is insufficient time to create proper documentation. To address this, developers write their own instructions as new releases and tools become available in their current projects.\n2. Fast-Developing\nReact.js has grown in popularity in recent years due to its rapid development. However, this has resulted in some disadvantages for developers.\nOne of the most serious issues is that React.js is constantly evolving, making it difficult to keep up with the latest enhancements. This means that developers must devote a significant amount of time to staying current with the React ecosystem, which may be a turnoff for some.\nFurthermore, the rapid pace of development can lead to bugs and instability in React applications.\n3. Inattention to User Interface\nReact includes a plethora of tools for developing and creating user interfaces. React JS, unlike frameworks, is not an \"all-in-one\" app development tool. As a result, if you use a model-view-controller (MVC), React development is only responsible for the user interface. Other tools must be used by the developers to create the model and controller. To create a functional application, you will need to use additional tools that will cover other critical components such as the backend and data storage.\nAdditional tools will be required for app programming interfaces (APIs), routing, and other components.\nThe pros and cons of Next Js\nThese pros and cons will help you gain a better understanding of what Next.js can do based on your goal, length of usage, and production requirements.\nThe Advantages of Using Next Js\n1. Speed\nNext.js applications run quickly because of Server-side Rendering and Dynamic Synthesis, which provide a more intelligent way of handling data. The response time of the server to queries determines the speed of server-side rendering. It is quick because static material can be delivered over a CDN. Additionally, native image optimization tools improve efficiency.\n2. It is simple to code\nNext.js requires less code than React and other frameworks that work with React. Developers only need to create the page and include a link to the component in the header, resulting in less code, better readability, and better project management.\n3. Simple customization\nNext JS is highly customizable because it makes use of plugins like babel. Its deployment is also simple, and it allows it to launch applications quickly.\n4. Fast rendering\nEvery change to the content is immediately visible by reloading the website. Because the component is immediately displayed, it is easier to track changes as they occur.\n5. CSS support\nThe built-in CSS support in Next.js is a key feature. This means that developers can incorporate CSS Stylesheets into their Next.js projects without requiring the use of any additional libraries or tooling. This is especially useful for small projects where adding a CSS preprocessor would be overkill.\nFurthermore, because CSS support is built-in, developers can use features like server-side rendering and code splitting without worrying about whether their CSS will be properly processed.\nThe Disadvantages of Using Next Js\n1. Routing﻿\nIt's a file-based router, which means it's a file system that handles responses and requests via files. These file projects are sometimes insufficient for some projects. To create or use dynamic routes, you'll need NodeJS, which requires skilled developers.\n2. Community\nIt is still small, but it is growing by the day as Next.js becomes one of the most popular web building blocks. There are fewer Next.js experts than there are React or other frameworks, but it is not a new framework. The talent pool and demand for Next.js developers are growing, creating opportunities for those looking to make a name for themselves in modern application development.\nIs Next.js a better framework than React?\n\"Is Next JS Better Than React?\" appears to be an inappropriate question in my opinion. However, the best technology or library to use is determined by your project's requirements and business objectives.\nReact and Next.js is rapidly becoming the most important components of the overall digital experience. They provide a more seamless and faster project experience at a lower development cost.\nWhich is better, Next JS or React JS?\nThere is no correct answer to this question. As previously stated, choosing a framework or library is entirely dependent on the requirements of your project. React and Next.js are new and useful tools for your project, but they are only useful for certain tasks.\nNext.js provides the most effective server-side rendering and static website development solutions. It also allows you to easily manage projects by providing a variety of tools and features.\nReact, on the other hand, is the best choice for creating user interfaces for single-page apps. It enables you to create more appealing and intuitive applications because it works with the layer of mobile and web apps.\nConclusion\nIn a nutshell, Next.js provides a variety of tools and features to streamline the development process, whereas React.js has more resources for the front-end development of your mobile and web applications.\nIn my opinion, both React and Next.js are fantastic, powerful tools for building beautiful, snappy web apps, and there is no clear winner. They perform different functions.","dc:creator":"kevin","guid":"https://hackernoon.com/which-framework-must-you-implement-for-your-next-project-next-js-vs-react?source=rss","categories":["next-js-vs-react","hire-react-developers","react-js-development-services","react-js-development-company","react-development-service","programming","web-development","front-end-development","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja"],"isoDate":"2022-12-14T18:03:38.000Z","from":"https://hackernoon.com/feed","hashId":"e00a648aeeb0e69f28ee43f89912803d"},{"creator":"Nicolas Fränkel","title":"How to Move Away From Twitter","link":"https://hackernoon.com/how-to-move-away-from-twitter?source=rss","pubDate":"Wed, 14 Dec 2022 21:10:03 GMT","content:encoded":"<p>I opened my Twitter account more than 13 years ago, in August 2009. For 12 years, I kept focusing on professional-related content: Java, the JVM, programming, etc. I built my audience, trying to promote good technical content, either my own or stuff that I enjoyed reading.</p>\n<p>\\\nThen, on February 24th, Russia invaded Ukraine. My first visit to Ukraine was in 2014, just after the Maidan revolution. During eight years, I returned there often and made plenty of friends.</p>\n<p>\\\nOf course, I wanted to support them and started to use my Twitter account to fight Russian disinformation. I discovered how toxic Twitter could be after having stayed out of politics since the beginning: bad faith, logical fallacies, flat-out lies, reverse accusations, personal attacks, etc.</p>\n<p>\\\nWith the acquisition of Twitter by Elon Musk, I’m afraid it’s going to get much worse — case in point:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/ySK5UmEKUigi6gZlUx5UYDhUNhk1-q5a28lp.png\" alt=\"https://twitter.com/SarahKSilverman/status/1589418271308386304\" /></p>\n<p>\\\n\\\nSome (most?) people I know planned or already had moved away. The target seems to be Mastodon, an alternate decentralized Open Source using the <a href=\"https://en.wikipedia.org/wiki/ActivityPub\">ActivityPub</a> protocol:</p>\n<p>\\</p>\n<blockquote>\n  <p><em>Mastodon is free and open-source software for running self-hosted social networking services. It has microblogging features similar to the Twitter service, which are offered by a large number of independently run Mastodon nodes (technically known as instances), each with its own code of conduct, terms of service, privacy options, and moderation policies.</em></p>\n  <p>\\</p>\n  <p><em>Each user is a member of a specific Mastodon instance (also called a server), which can interoperate as a federated social network, allowing users on different nodes to interact with each other. This is intended to give users the flexibility to select a server whose policies they prefer, but keep access to a larger social network. Mastodon is also part of the Fediverse ensemble of server platforms, which use shared protocols allowing users to also interact with users on other compatible platforms, such as PeerTube and Friendica.</em></p>\n  <p>\\</p>\n  <p><em>—  <a href=\"https://en.wikipedia.org/wiki/Mastodon_%28software%29\">https://en.wikipedia.org/wiki/Mastodon_(software)</a></em></p>\n</blockquote>\n<p>\\\nForewarned is forearmed. I plan to stay on Twitter as long as possible while building up my Mastodon account with the same content. Then, if (when?) all hell breaks loose, I can just jump ship.</p>\n<h3 id=\"evaluatingthealternatives\">Evaluating the Alternatives</h3>\n<p>Let’s state things clearly: I believe I’m a good developer because I’m lazy. There’s no way I’m going to copy-paste content on both channels. Plus, I’m using Twitter’s scheduling feature, so I need something else.</p>\n<p>\\\nI’m one of many who want to keep a foot in each realm. For example, I found that Martin Fowler is also following <a href=\"https://martinfowler.com/articles/exploring-mastodon.html\">the same strategy</a>. However, his approach is “specific”:</p>\n<p>\\</p>\n<blockquote>\n  <p><em>One of the main things I wanted to do with Mastodon was to replicate my twitter feed there, so that folks who would rather follow me on Mastodon could get everything. To do this, I used moa.party. You have to give it credentials to access both your Twitter and Mastodon feeds, which is a little worrisome, but my Mastodon-aware colleagues have used it without problems.</em></p>\n</blockquote>\n<p>\\\nThere’s no way I’d give my credentials to a third party! I searched further and found this gem:</p>\n<p>\\</p>\n<blockquote>\n  <p><em>This tool synchronizes posts from Mastodon to Twitter and back. It does not matter where you post your stuff — it will get synchronized to the other!</em></p>\n  <p><em>— <a href=\"https://github.com/klausi/mastodon-twitter-sync\">Mastodon Twitter Sync</a></em></p>\n</blockquote>\n<p>\\\nIt looked exactly what I was searching for!</p>\n<h3 id=\"mastodontwitternbspsync\">Mastodon Twitter&nbsp;Sync</h3>\n<p>The tool provides two execution options:</p>\n<p>\\</p>\n<ul>\n<li>A Docker image</li>\n<li>Run from source — Rust</li>\n</ul>\n<p>\\\nThe <a href=\"https://hub.docker.com/r/klausi/mastodon-twitter-sync/tags\">Docker image</a> has no tags, save <code>latest</code>, and I had some issues mapping volumes.</p>\n<p>\\\nHence, I decided to run from source. Again, I'm lazy and don't want to run the tool manually. I've been using GitHub Actions for a couple of years to schedule my scripts.</p>\n<p>\\\nLet’s start with the following:</p>\n<p>\\</p>\n<pre><code class=\"yaml language-yaml\">name: Sync Twitter to and from Mastodon\non:\n  schedule:\n    - cron: \"24 */2 * * *\"                               #1\n  workflow_dispatch:\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the synchronization code         #2\n        uses: actions/checkout@v3\n        with:\n          repository: klausi/mastodon-twitter-sync\n      - name: Install Rust                               #3                            \n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: stable\n          profile: minimal                               #4\n      - name: Execute synchronization                    #5\n        uses: actions-rs/cargo@v1\n        with:\n          command: run\n          args: --release\n</code></pre>\n<ol>\n<li><p>Schedule every two hours, 24 minutes after the hour.</p>\n<p>\\</p></li>\n<li><p>Check out the sync project’s code.</p>\n<p>\\</p></li>\n<li><p>Install the Rust toolchain.</p>\n<p>\\</p></li>\n<li><p>The toolchain comes in different flavors called <a href=\"https://rust-lang.github.io/rustup/concepts/profiles.html\">profiles</a>. For scripting, <code>minimal</code> is enough, providing only <code>rustc</code>, <code>rust-std</code>, and <code>cargo.</code></p>\n<p>\\</p></li>\n<li><p>Run the code</p></li>\n</ol>\n<h3 id=\"managingcredentials\">Managing Credentials</h3>\n<p>Spoiler: the workflow doesn’t work. By default, the code runs interactively: it will ask for credentials to connect to both Twitter and Mastodon. Alternatively, the project accepts a configuration file containing all data — <code>mastodon-twitter-sync.toml</code>.</p>\n<p>\\\nMy advice is to run the project interactively locally once. If the TOML file doesn’t exist, the executable will ask for credentials and generate a new one containing them. But we shouldn’t add a file containing credential data in plain text on a Git repo. Instead, we shall:</p>\n<p>\\</p>\n<ol>\n<li><p>Encrypt the file.</p>\n<p>\\</p></li>\n<li><p>Add and commit the encrypted file.</p>\n<p>\\</p></li>\n<li><p>During workflow run, decrypt the file using a GitHub Action secret.</p></li>\n</ol>\n<p>\\</p>\n<pre><code class=\"yaml language-yaml\">jobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install GPG to decrypt the configuration file\n        run: sudo apt-get update &amp;&amp; sudo apt-get install -y gnupg\n      - name: Decrypt the configuration file\n        run: gpg --quiet --batch --yes --decrypt --passphrase=\"$GPG_PASSPHRASE\" --decrypt mastodon-twitter-sync.toml.gpg &gt; mastodon-twitter-sync.toml \n        env:\n          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}\n</code></pre>\n<p>\\\nAt this point, we have mixed the Rust source code with our configuration file in the same Git repository. Handling such a project involves a lot of <code>git rebase</code>, which I want to avoid. Let's keep the code separate with its dedicated lifecycle locally.</p>\n<p>\\</p>\n<pre><code class=\"javascript language-javascript\">mastodon-twitter-sync-job               #1\n|_ .github\n|  |_ workflows\n|    |_ sync.yml                        #2\n|_ mastodon-twitter-sync.toml.gpg       #3\n\nmastodon-twitter-sync                   #4\n|_ src\n|_ ...\n</code></pre>\n<ol>\n<li><p>My project</p>\n<p>\\</p></li>\n<li><p>GitHub action</p>\n<p>\\</p></li>\n<li><p>Encrypted credential file</p>\n<p>\\</p></li>\n<li><p>Independent sync project</p></li>\n</ol>\n<p>\\\nWe need to change how we check out the code:</p>\n<p>\\</p>\n<pre><code class=\"yaml language-yaml\">jobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repo itself\n        uses: actions/checkout@v3\n        with:\n          path: job\n      - name: Check out the synchronization code\n        uses: actions/checkout@v3\n        with:\n          repository: klausi/mastodon-twitter-sync\n          path: code\n</code></pre>\n<p>\\\nWhen we run the workflow, the layout is the following:</p>\n<p>\\</p>\n<pre><code>|_ job\n|  |_ .github\n|  |  |_ workflows\n|  |    |_ sync.yml\n|  |_ mastodon-twitter-sync.toml.gpg\n|\n|_ code\n|  |_ src\n|  |_ ...\n</code></pre>\n<p>\\\nHenceforth, we should update the decrypting and run the steps accordingly:</p>\n<p>\\</p>\n<pre><code class=\"yaml language-yaml\">jobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Decrypt the configuration file\n        run: |\n          gpg --quiet --batch --yes --decrypt --passphrase=\"$GPG_PASSPHRASE\"\n              --decrypt job/mastodon-twitter-sync.toml.gpg &gt; mastodon-twitter-sync.toml #1\n        env:\n          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}\n      - name: Execute synchronization\n        uses: actions-rs/cargo@v1\n        with:\n          command: run\n          args: --manifest-path=./code/Cargo.toml --release                             #2\n</code></pre>\n<ol>\n<li><p>Decrypt from the <code>job</code> subfolder in the current root folder.</p>\n<p>\\</p></li>\n<li><p>Run in the current folder using the <code>code</code> subfolder.</p></li>\n</ol>\n<h3 id=\"synconlynbsponce\">Sync Only&nbsp;Once</h3>\n<p>The project creates a <code>post_cache.json</code> file that contains all previously synced content to avoid duplicating the same content during each execution. We need to take it into account:</p>\n<p>\\</p>\n<pre><code class=\"yaml language-yaml\">jobs:\n  sync:\n    runs-on: ubuntu-latest\n      - name: Update post cache\n        run: &gt;\n          cp ./post_cache.json ./job/ 2&gt;/dev/null || :    #1\n      - name: Commit and push post cache\n        uses: EndBug/add-and-commit@v7                    #2\n        with:\n          cwd: './job'\n          add: post_cache.json\n          default_author: github_actions\n          message: Update post cache\n</code></pre>\n<ol>\n<li><p>Copy the <code>post_cache.json</code> in the <code>job</code> subfolder. Only succeed the step if the job synchronizes no content, and the file is generated.</p>\n<p>\\</p></li>\n<li><p>Commit back the file if it has changed.</p></li>\n</ol>\n<h3 id=\"workflowoptimization\">Workflow Optimization</h3>\n<p>In the current state, each run downloads the dependencies and compiles the project, even though the source code stays the code; it’s highly inefficient.</p>\n<p>\\\nThe platform provides a generic <a href=\"https://github.com/marketplace/actions/cache\">caching GitHub Action</a>. However, I found <a href=\"https://github.com/Swatinem/rust-cache\">rust-cache</a>, a Rust-specific one that provides appropriate defaults for Rust. Let’s use it to cache the dependencies and the executable across workflow executions (provided some parameters stay the same):</p>\n<p>\\</p>\n<pre><code class=\"yaml language-yaml\">jobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install Rust\n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: stable\n          profile: minimal\n      - name: Cache executable             #1\n        uses: Swatinem/rust-cache@v2\n        with:\n          workspaces: code                 #2\n</code></pre>\n<ol>\n<li><p>Must be installed after Rust install, as the cache key contains Rust-specific data</p>\n<p>\\</p></li>\n<li><p>Cache artifacts located in the <code>code</code> subfolder</p></li>\n</ol>\n<h3 id=\"finalnotes\">Final Notes</h3>\n<p>With this setup, I need to update the repo with the new JSON cache file before I commit any change to the workflow. I could create a dedicated repo for it to improve the situation, but it’s good enough for now.</p>\n<p>\\\nThe connection to Mastodon is fickle; a lot of actions fail with the following message:</p>\n<p>\\</p>\n<pre><code class=\"javascript language-javascript\">Error connecting to Mastodon: Http(\n    reqwest::Error {\n        kind: Request,\n        url: Url {\n            scheme: \"https\",\n            cannot_be_a_base: false,\n            username: \"\",\n            password: None,\n            host: Some(\n                Domain(\n                    \"mastodon.top\",\n                ),\n            ),\n            port: None,\n            path: \"//api/v1/accounts/verify_credentials\",\n            query: None,\n            fragment: None,\n        },\n        source: TimedOut,\n    },\n)\n</code></pre>\n<p>\\\nIt’s not an issue <em>per se</em>; it just means that synchronization lags. Should I move to a more reliable instance or even host my own?</p>\n<p>\\\nSo far, I’ve kept Twitter as my source of truth. I post content there, and it should appear on Mastodon. However, synchronization should happen both ways. Once I make Mastodon my main channel, I don’t need to change the above work.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>Twitter’s new owner claims to promote “comedy” but suspends accounts that make fun of him. At the same time, he claims to be a proponent of free speech but confuses opinion with information. The advertising market may curb his misguided views, but it’s still being determined.</p>\n<p>\\\nIn the meantime, I’m not willing to sit idly. Mastodon is gaining a lot of momentum. </p>\n<p>\\\nIn this post, I’ve explained how you can cross the chasm while still keeping your presence on Twitter until you don’t want to. Thanks to <a href=\"https://github.com/klausi/\">klausi</a> for their fantastic sync project and patience with my stumbling.</p>\n<p>\\\nThe source code is available on GitHub:</p>\n<p><a href=\"https://github.com/nfrankel/mastodon-twitter-sync-job?embedable=true\">https://github.com/nfrankel/mastodon-twitter-sync-job?embedable=true</a></p>\n<p><a href=\"https://github.com/nfrankel/mastodon-twitter-sync-job\"> \\n </a><strong>To go further:</strong></p>\n<p>\\</p>\n<ul>\n<li><a href=\"https://mastodon.top/web/@frankel\">Me on Mastodon</a></li>\n<li><a href=\"https://martinfowler.com/articles/exploring-mastodon.html\">Martin Fowler’s adventures in Mastodon</a></li>\n<li><a href=\"https://docs.joinmastodon.org/\">Mastodon documentation</a></li>\n<li><a href=\"https://moa.party/\">Moa bridge (be careful!)</a></li>\n<li><a href=\"https://github.com/klausi/mastodon-twitter-sync\">Mastodon Twitter Sync</a></li>\n</ul>\n<hr />\n<p><em>Originally published at <a href=\"https://blog.frankel.ch/move-away-twitter/\">A Java Geek</a> on December 11th, 2022</em></p>","content:encodedSnippet":"I opened my Twitter account more than 13 years ago, in August 2009. For 12 years, I kept focusing on professional-related content: Java, the JVM, programming, etc. I built my audience, trying to promote good technical content, either my own or stuff that I enjoyed reading.\n\\\nThen, on February 24th, Russia invaded Ukraine. My first visit to Ukraine was in 2014, just after the Maidan revolution. During eight years, I returned there often and made plenty of friends.\n\\\nOf course, I wanted to support them and started to use my Twitter account to fight Russian disinformation. I discovered how toxic Twitter could be after having stayed out of politics since the beginning: bad faith, logical fallacies, flat-out lies, reverse accusations, personal attacks, etc.\n\\\nWith the acquisition of Twitter by Elon Musk, I’m afraid it’s going to get much worse — case in point:\n\\\n \n\\\n\\\nSome (most?) people I know planned or already had moved away. The target seems to be Mastodon, an alternate decentralized Open Source using the ActivityPub protocol:\n\\\n\n  \nMastodon is free and open-source software for running self-hosted social networking services. It has microblogging features similar to the Twitter service, which are offered by a large number of independently run Mastodon nodes (technically known as instances), each with its own code of conduct, terms of service, privacy options, and moderation policies.\n\\\n  \nEach user is a member of a specific Mastodon instance (also called a server), which can interoperate as a federated social network, allowing users on different nodes to interact with each other. This is intended to give users the flexibility to select a server whose policies they prefer, but keep access to a larger social network. Mastodon is also part of the Fediverse ensemble of server platforms, which use shared protocols allowing users to also interact with users on other compatible platforms, such as PeerTube and Friendica.\n\\\n  \n—  https://en.wikipedia.org/wiki/Mastodon_(software)\n\\\nForewarned is forearmed. I plan to stay on Twitter as long as possible while building up my Mastodon account with the same content. Then, if (when?) all hell breaks loose, I can just jump ship.\nEvaluating the Alternatives\nLet’s state things clearly: I believe I’m a good developer because I’m lazy. There’s no way I’m going to copy-paste content on both channels. Plus, I’m using Twitter’s scheduling feature, so I need something else.\n\\\nI’m one of many who want to keep a foot in each realm. For example, I found that Martin Fowler is also following the same strategy. However, his approach is “specific”:\n\\\n\n  \nOne of the main things I wanted to do with Mastodon was to replicate my twitter feed there, so that folks who would rather follow me on Mastodon could get everything. To do this, I used moa.party. You have to give it credentials to access both your Twitter and Mastodon feeds, which is a little worrisome, but my Mastodon-aware colleagues have used it without problems.\n\\\nThere’s no way I’d give my credentials to a third party! I searched further and found this gem:\n\\\n\n  \nThis tool synchronizes posts from Mastodon to Twitter and back. It does not matter where you post your stuff — it will get synchronized to the other!\n— Mastodon Twitter Sync\n\\\nIt looked exactly what I was searching for!\nMastodon Twitter Sync\nThe tool provides two execution options:\n\\\n\nA Docker image\nRun from source — Rust\n\\\nThe Docker image has no tags, save latest, and I had some issues mapping volumes.\n\\\nHence, I decided to run from source. Again, I'm lazy and don't want to run the tool manually. I've been using GitHub Actions for a couple of years to schedule my scripts.\n\\\nLet’s start with the following:\n\\\nname: Sync Twitter to and from Mastodon\non:\n  schedule:\n    - cron: \"24 */2 * * *\"                               #1\n  workflow_dispatch:\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the synchronization code         #2\n        uses: actions/checkout@v3\n        with:\n          repository: klausi/mastodon-twitter-sync\n      - name: Install Rust                               #3                            \n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: stable\n          profile: minimal                               #4\n      - name: Execute synchronization                    #5\n        uses: actions-rs/cargo@v1\n        with:\n          command: run\n          args: --release\n\nSchedule every two hours, 24 minutes after the hour.\n\\\nCheck out the sync project’s code.\n\\\nInstall the Rust toolchain.\n\\\nThe toolchain comes in different flavors called profiles. For scripting, minimal is enough, providing only rustc, rust-std, and cargo.\n\\\nRun the code\n\n\nManaging Credentials\nSpoiler: the workflow doesn’t work. By default, the code runs interactively: it will ask for credentials to connect to both Twitter and Mastodon. Alternatively, the project accepts a configuration file containing all data — mastodon-twitter-sync.toml.\n\\\nMy advice is to run the project interactively locally once. If the TOML file doesn’t exist, the executable will ask for credentials and generate a new one containing them. But we shouldn’t add a file containing credential data in plain text on a Git repo. Instead, we shall:\n\\\n\n\nEncrypt the file.\n\\\nAdd and commit the encrypted file.\n\\\nDuring workflow run, decrypt the file using a GitHub Action secret.\n\n\n\\\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install GPG to decrypt the configuration file\n        run: sudo apt-get update && sudo apt-get install -y gnupg\n      - name: Decrypt the configuration file\n        run: gpg --quiet --batch --yes --decrypt --passphrase=\"$GPG_PASSPHRASE\" --decrypt mastodon-twitter-sync.toml.gpg > mastodon-twitter-sync.toml \n        env:\n          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}\n\n\\\nAt this point, we have mixed the Rust source code with our configuration file in the same Git repository. Handling such a project involves a lot of git rebase, which I want to avoid. Let's keep the code separate with its dedicated lifecycle locally.\n\\\nmastodon-twitter-sync-job               #1\n|_ .github\n|  |_ workflows\n|    |_ sync.yml                        #2\n|_ mastodon-twitter-sync.toml.gpg       #3\n\nmastodon-twitter-sync                   #4\n|_ src\n|_ ...\n\nMy project\n\\\nGitHub action\n\\\nEncrypted credential file\n\\\nIndependent sync project\n\n\n\\\nWe need to change how we check out the code:\n\\\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repo itself\n        uses: actions/checkout@v3\n        with:\n          path: job\n      - name: Check out the synchronization code\n        uses: actions/checkout@v3\n        with:\n          repository: klausi/mastodon-twitter-sync\n          path: code\n\n\\\nWhen we run the workflow, the layout is the following:\n\\\n|_ job\n|  |_ .github\n|  |  |_ workflows\n|  |    |_ sync.yml\n|  |_ mastodon-twitter-sync.toml.gpg\n|\n|_ code\n|  |_ src\n|  |_ ...\n\n\\\nHenceforth, we should update the decrypting and run the steps accordingly:\n\\\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Decrypt the configuration file\n        run: |\n          gpg --quiet --batch --yes --decrypt --passphrase=\"$GPG_PASSPHRASE\"\n              --decrypt job/mastodon-twitter-sync.toml.gpg > mastodon-twitter-sync.toml #1\n        env:\n          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}\n      - name: Execute synchronization\n        uses: actions-rs/cargo@v1\n        with:\n          command: run\n          args: --manifest-path=./code/Cargo.toml --release                             #2\n\nDecrypt from the job subfolder in the current root folder.\n\\\nRun in the current folder using the code subfolder.\n\n\nSync Only Once\nThe project creates a post_cache.json file that contains all previously synced content to avoid duplicating the same content during each execution. We need to take it into account:\n\\\njobs:\n  sync:\n    runs-on: ubuntu-latest\n      - name: Update post cache\n        run: >\n          cp ./post_cache.json ./job/ 2>/dev/null || :    #1\n      - name: Commit and push post cache\n        uses: EndBug/add-and-commit@v7                    #2\n        with:\n          cwd: './job'\n          add: post_cache.json\n          default_author: github_actions\n          message: Update post cache\n\nCopy the post_cache.json in the job subfolder. Only succeed the step if the job synchronizes no content, and the file is generated.\n\\\nCommit back the file if it has changed.\n\n\nWorkflow Optimization\nIn the current state, each run downloads the dependencies and compiles the project, even though the source code stays the code; it’s highly inefficient.\n\\\nThe platform provides a generic caching GitHub Action. However, I found rust-cache, a Rust-specific one that provides appropriate defaults for Rust. Let’s use it to cache the dependencies and the executable across workflow executions (provided some parameters stay the same):\n\\\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install Rust\n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: stable\n          profile: minimal\n      - name: Cache executable             #1\n        uses: Swatinem/rust-cache@v2\n        with:\n          workspaces: code                 #2\n\nMust be installed after Rust install, as the cache key contains Rust-specific data\n\\\nCache artifacts located in the code subfolder\n\n\nFinal Notes\nWith this setup, I need to update the repo with the new JSON cache file before I commit any change to the workflow. I could create a dedicated repo for it to improve the situation, but it’s good enough for now.\n\\\nThe connection to Mastodon is fickle; a lot of actions fail with the following message:\n\\\nError connecting to Mastodon: Http(\n    reqwest::Error {\n        kind: Request,\n        url: Url {\n            scheme: \"https\",\n            cannot_be_a_base: false,\n            username: \"\",\n            password: None,\n            host: Some(\n                Domain(\n                    \"mastodon.top\",\n                ),\n            ),\n            port: None,\n            path: \"//api/v1/accounts/verify_credentials\",\n            query: None,\n            fragment: None,\n        },\n        source: TimedOut,\n    },\n)\n\n\\\nIt’s not an issue per se; it just means that synchronization lags. Should I move to a more reliable instance or even host my own?\n\\\nSo far, I’ve kept Twitter as my source of truth. I post content there, and it should appear on Mastodon. However, synchronization should happen both ways. Once I make Mastodon my main channel, I don’t need to change the above work.\nConclusion\nTwitter’s new owner claims to promote “comedy” but suspends accounts that make fun of him. At the same time, he claims to be a proponent of free speech but confuses opinion with information. The advertising market may curb his misguided views, but it’s still being determined.\n\\\nIn the meantime, I’m not willing to sit idly. Mastodon is gaining a lot of momentum. \n\\\nIn this post, I’ve explained how you can cross the chasm while still keeping your presence on Twitter until you don’t want to. Thanks to klausi for their fantastic sync project and patience with my stumbling.\n\\\nThe source code is available on GitHub:\nhttps://github.com/nfrankel/mastodon-twitter-sync-job?embedable=true\n \\n To go further:\n\\\n\nMe on Mastodon\nMartin Fowler’s adventures in Mastodon\nMastodon documentation\nMoa bridge (be careful!)\nMastodon Twitter Sync\nOriginally published at A Java Geek on December 11th, 2022","dc:creator":"Nicolas Fränkel","content":"Hacker Kllausi used Twitter to fight Russian disinformation in Ukraine. Klusi wanted to stay on Twitter as long as possible while building up his Mastodon account with the same content. He wanted to replicate his Twitter feed there, so that folks who would rather follow him on Mastodon could get everything. Kluzi decided to run from source using Docker to synchronize posts from Twitter to Mastodon. Klussi is one of many who want to keep a foot in each realm.","contentSnippet":"Hacker Kllausi used Twitter to fight Russian disinformation in Ukraine. Klusi wanted to stay on Twitter as long as possible while building up his Mastodon account with the same content. He wanted to replicate his Twitter feed there, so that folks who would rather follow him on Mastodon could get everything. Kluzi decided to run from source using Docker to synchronize posts from Twitter to Mastodon. Klussi is one of many who want to keep a foot in each realm.","guid":"https://hackernoon.com/how-to-move-away-from-twitter?source=rss","categories":["rust","twitter","mastodon","github-actions","social-media","hackernoon-top-story","elon-musk","twitter-tools","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja"],"isoDate":"2022-12-14T21:10:03.000Z","from":"https://hackernoon.com/feed","hashId":"9b654c2f964af770101c0f75867e5e2e"},{"creator":"Alberto Cuesta Cañada ","title":"How To Review a Governance Action","link":"https://hackernoon.com/how-to-review-a-governance-action?source=rss","pubDate":"Wed, 14 Dec 2022 21:20:40 GMT","content:encoded":"<p>Good governance needs a clear understanding of consequences.</p>\n<p>\\\nWhen I worked for financial institutions, strict change management processes protected the technology from unintended harm during changes. </p>\n<p>\\\nSenior staff was responsible for implementing changes, but their busy schedules and the complexity of the changes often made this challenging. </p>\n<p>\\\nTo avoid rejection, one had to carefully describe the intended change and follow the rules and check the appropriate boxes.</p>\n<p>\\\nBlockchain technology is reinventing finance, including change management processes. </p>\n<p>\\\nWe have been successful in making senior staff responsible for changes through the use of multisigs and DAOs, but we have not been as successful in ensuring that these signers understand what they are signing off on. </p>\n<p>\\\nAs a result, it is necessary to implore them to sign. Despite the real risk of a governance attack, it has become somewhat of a joke to simply sign off on things without understanding their implications.</p>\n<p>\\\nEarly on at Yield, I focused on the problem of multisig members not understanding what they were signing off on. This was unacceptable to me, and I wanted to prevent myself from being able to rug the protocol before higher valuations might influence my judgment.</p>\n<p>\\\nIf your multisig members are unsure of what they are signing, there are ways to make the process easier for them. I’ll show you how.</p>\n<h2 id=\"howgovernorsseechange\">How Governors See Change</h2>\n<p>Some blockchain applications, such as Uniswap, are permissionless and require no further action after deployment. However, most other applications have adopted change-by-governance patterns, where changes can be made as long as they are signed off by a multisig or a DAO.</p>\n<p>\\\nSome changes are simple, such as transferring tokens or adjusting a parameter, while others are more complex and involve deploying contracts and orchestrating them. </p>\n<p>\\\nObtaining signatures for any change requires a significant amount of effort, so it is common to ask for a single signature for all elements included in a change. At Yield, the largest change I've seen included more than three hundred individual calls.</p>\n<p>\\\nFor simpler changes, multisig members may be willing to review the call data and may even have the ability to understand it. However, for more complex changes, this is not possible.</p>\n<p>\\\nGovernors approving a change should know which functions are being called, what parameters are being used, and what effects these will have. They should be able to find this information on their own, without help from others.</p>\n<p>\\\nIt is possible to achieve this, and it is easier than it may seem. However, first, we must understand how governance changes are executed by smart contracts.</p>\n<h2 id=\"governancetechnology\">Governance Technology</h2>\n<p>At Yield, we built our own Timelock, taking inspiration from Compound but making a crucial change. While the original Timelock can store and delay a single call, our Timelock can store a batch of calls with any number of calls included.</p>\n<p>\\\nOther protocols may use different contracts, but the basic process remains the same: a batch of function calls is recorded, approved, and then executed.</p>\n<p>\\\nIn our Timelock, a call is a target and call data representing a call on the target:</p>\n<pre><code class=\"javascript language-javascript\">struct Proposal {\n&amp;nbsp;&amp;nbsp;&amp;nbsp;    STATE state;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;    uint32 eta;\n    }\n</code></pre>\n<p>\\\nA proposal, or change, is simply an array of calls.</p>\n<pre><code class=\"javascript language-javascript\">function propose(Call[] calldata functionCalls)\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;external override auth returns (bytes32 txHash)\n&amp;nbsp;&amp;nbsp;&amp;nbsp;{\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;txHash = keccak256(abi.encode(functionCalls));\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;require(proposals[txHash].state == STATE.UNKNOWN, \"Already proposed.\");\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;proposals[txHash].state = STATE.PROPOSED;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;emit Proposed(txHash);\n&amp;nbsp;&amp;nbsp;&amp;nbsp;}\n</code></pre>\n<p>\\\nThe propose function is permissioned and, in our implementation, only allowed to our developers.</p>\n<p>\\\nThere is also an approve function that can only be called by the multisig. The approval time determines the earliest possible execution time.</p>\n<pre><code class=\"javascript language-javascript\">function approve(bytes32 txHash)\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;external override auth returns (uint32 eta)\n&amp;nbsp;&amp;nbsp;&amp;nbsp;{\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Proposal memory proposal = proposals[txHash];\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;require(proposal.state == STATE.PROPOSED, \"Not proposed.\");\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;eta = uint32(block.timestamp) + delay;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;proposal.state = STATE.APPROVED;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;proposal.eta = eta;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;proposals[txHash] = proposal;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;emit Approved(txHash, eta);\n&amp;nbsp;&amp;nbsp;&amp;nbsp;}\n</code></pre>\n<p>\\\nOnly developers are allowed to execute a change, and they must supply the same batch that was used in the propose function. If the batch is different or the change identifier is incorrect, the change will fail to find the approval and will not be executed.</p>\n<pre><code class=\"javascript language-javascript\">function execute(Call[] calldata functionCalls)\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;external override auth returns (bytes[] memory results)\n&amp;nbsp;&amp;nbsp;&amp;nbsp;{\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;bytes32 txHash = keccak256(abi.encode(functionCalls));\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Proposal memory proposal = proposals[txHash];\n&amp;nbsp;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;require(proposal.state == STATE.APPROVED, \"Not approved.\");\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;require(uint32(block.timestamp) &gt;= proposal.eta, \"ETA not reached.\");\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;require(uint32(block.timestamp) &lt;= proposal.eta + GRACE_PERIOD, \"Proposal is stale.\");\n\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;delete proposals[txHash];\n\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;results = new bytes[](functionCalls.length);\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for (uint256 i = 0; i &lt; functionCalls.length; i++){\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;require(functionCalls[i].target.isContract(), \"Call to a non-contract\");\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(bool success, bytes memory result) = functionCalls[i].target.call(functionCalls[i].data);\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if (!success) revert(RevertMsgExtractor.getRevertMsg(result));\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;results[i] = result;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;}\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;emit Executed(txHash);\n&amp;nbsp;&amp;nbsp;&amp;nbsp;}\n</code></pre>\n<p>\\\nIn any situation where a change is being considered, there will be someone who decides that the change should be made, and there will be developers who turn that idea into code. This code, in the form of a batch of function calls, is then fed to the Timelock using `propose`.</p>\n<p>\\\nThe next step is for responsible senior staff, a multisig, or a DAO to review the change and decide whether to approve it, calling `approve`.</p>\n<p>\\\nThis step is the one that is often difficult because understanding the proposed change from the Timelock is difficult. We can make this process easier for them by using existing development tools to provide them with detailed information about the nature of the change.</p>\n<h2 id=\"reviewingchangeindetail\">Reviewing Change in Detail</h2>\n<p>Once a change has been proposed in the Timelock, it becomes immutable thanks to its unique identifier. If a governor approves this identifier, only that exact batch of calls can be executed.</p>\n<p>\\\nWith this in mind, we can:</p>\n<ol>\n<li>`propose` on the real network.</li>\n<li>Fork that network.</li>\n<li>Impersonate the governor and `approve` the proposal in the fork.</li>\n<li>`execute` in the fork</li>\n</ol>\n<p>\\\nThe change being executed is the same as the one that was proposed because we forked the network after the proposal. Not only that, but anyone can analyze the execution with a transaction decoder. </p>\n<p>\\\nAt Yield, we use Tenderly, but there are other options available. I made public <strong><a href=\"https://dashboard.tenderly.co/public/Yield/v2-public/fork-simulation/749a3418-2b51-4a8e-ad33-550b809ac4fd\">one of our proposal executions in a fork</a></strong> for educational purposes.</p>\n<p>\\\nAs a multisig member at Yield, I review the execution of every proposal in a fork. I compare the change identifier for approval in the multisig against the change identifier in the fork, and then I know with total certainty that what is in the multisig is what would be executed.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/9nMyFjQNicRJ5HwksmBytJBySMi2-2022-12-14T21:20:39.642Z-clbo5pr7800000as692ts2awz\" alt=\"Verifying the execution identifier\" /></p>\n<p>\\\nAll changes must include <strong><a href=\"https://github.com/yieldprotocol/governance-v2/pull/86\">a text-based description</a></strong> of their purpose and the parameters being used. I use this to understand what the change does in a broad sense, and then use the transaction decoder to review the detail.</p>\n<p>\\\nI start by comparing the description against the contracts involved in the execution to ensure that they match. Conducting due diligence in this process includes verifying all new contracts and ensuring that their verified code is what is in the repository.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/9nMyFjQNicRJ5HwksmBytJBySMi2-2022-12-14T21:20:39.673Z-clbo5pr7e00010as6cs0r1hxz\" alt=\"Reviewing contracts involved\" /></p>\n<p>\\\nKnowing the contracts involved, the events of the transaction provide all the necessary information for reviewing the rest of the execution. </p>\n<p>\\\nI review the permissions granted and revoked, any changes to the oracles, and that the numerical parameters match what was discussed and agreed upon.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/9nMyFjQNicRJ5HwksmBytJBySMi2-2022-12-14T21:20:39.675Z-clbo5pr7f00020as606dq7jas\" alt=\"Reviewing al events\" /></p>\n<p>\\\n<strong><a href=\"https://nebulous-sprout-43a.notion.site/YPP-83-Replace-Witch-v1-with-Witch-v2-on-Mainnet-0bce6c53b83b46ac8e76dc1722fdd86d\">I document my review on Notion</a></strong> and make it publicly available for each change. Other governors can review my work or conduct their own due diligence in any other way they choose. In any case, I believe that the risk of being caught if I misrepresent a change is now sufficiently high.</p>\n<h2 id=\"gnosissafeasasimpleralternative\">Gnosis Safe as a Simpler Alternative</h2>\n<p>Gnosis Safe now offers a batch builder and automatically creates a simulation on Tenderly for all executions. This is the same functionality I described, with a friendlier interface. </p>\n<p>\\\nIf your governance proposals are simple enough to be created manually in a web interface, Gnosis Safe would be a simpler option. You can share the simulation report from Gnosis Safe and achieve the same result.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/9nMyFjQNicRJ5HwksmBytJBySMi2-2022-12-14T21:20:39.677Z-clbo5pr7h00030as6gucn8gsp\" alt=\"Gnosis Safe offers a neatly packaged solution\" /></p>\n<p>\\</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Governance of blockchain applications is difficult, and as a governor, you risk signing off on changes that could lead to the failure of the application, either by mistake or by design. Recent events have only emphasized the need to protect our users from harm.</p>\n<p>\\\nBy using developer tools and following simple processes at <a href=\"https://www.yieldprotocol.com\">Yield</a>, we have been able to provide governors with clear information about what they are signing off on. We have successfully executed over one hundred separate changes, totaling thousands of contract calls, have reduced the number of governance errors, and are able to catch more mistakes earlier than before.</p>\n<p>\\\nNothing we do is magic; it is simply common sense. Please make sure that you understand what you sign, and ask for the necessary tools if you must. We owe it to our users.</p>","content:encodedSnippet":"Good governance needs a clear understanding of consequences.\n\\\nWhen I worked for financial institutions, strict change management processes protected the technology from unintended harm during changes. \n\\\nSenior staff was responsible for implementing changes, but their busy schedules and the complexity of the changes often made this challenging. \n\\\nTo avoid rejection, one had to carefully describe the intended change and follow the rules and check the appropriate boxes.\n\\\nBlockchain technology is reinventing finance, including change management processes. \n\\\nWe have been successful in making senior staff responsible for changes through the use of multisigs and DAOs, but we have not been as successful in ensuring that these signers understand what they are signing off on. \n\\\nAs a result, it is necessary to implore them to sign. Despite the real risk of a governance attack, it has become somewhat of a joke to simply sign off on things without understanding their implications.\n\\\nEarly on at Yield, I focused on the problem of multisig members not understanding what they were signing off on. This was unacceptable to me, and I wanted to prevent myself from being able to rug the protocol before higher valuations might influence my judgment.\n\\\nIf your multisig members are unsure of what they are signing, there are ways to make the process easier for them. I’ll show you how.\nHow Governors See Change\nSome blockchain applications, such as Uniswap, are permissionless and require no further action after deployment. However, most other applications have adopted change-by-governance patterns, where changes can be made as long as they are signed off by a multisig or a DAO.\n\\\nSome changes are simple, such as transferring tokens or adjusting a parameter, while others are more complex and involve deploying contracts and orchestrating them. \n\\\nObtaining signatures for any change requires a significant amount of effort, so it is common to ask for a single signature for all elements included in a change. At Yield, the largest change I've seen included more than three hundred individual calls.\n\\\nFor simpler changes, multisig members may be willing to review the call data and may even have the ability to understand it. However, for more complex changes, this is not possible.\n\\\nGovernors approving a change should know which functions are being called, what parameters are being used, and what effects these will have. They should be able to find this information on their own, without help from others.\n\\\nIt is possible to achieve this, and it is easier than it may seem. However, first, we must understand how governance changes are executed by smart contracts.\nGovernance Technology\nAt Yield, we built our own Timelock, taking inspiration from Compound but making a crucial change. While the original Timelock can store and delay a single call, our Timelock can store a batch of calls with any number of calls included.\n\\\nOther protocols may use different contracts, but the basic process remains the same: a batch of function calls is recorded, approved, and then executed.\n\\\nIn our Timelock, a call is a target and call data representing a call on the target:\nstruct Proposal {\n&nbsp;&nbsp;&nbsp;    STATE state;\n&nbsp;&nbsp;&nbsp;    uint32 eta;\n    }\n\n\\\nA proposal, or change, is simply an array of calls.\nfunction propose(Call[] calldata functionCalls)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;external override auth returns (bytes32 txHash)\n&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;txHash = keccak256(abi.encode(functionCalls));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(proposals[txHash].state == STATE.UNKNOWN, \"Already proposed.\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proposals[txHash].state = STATE.PROPOSED;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;emit Proposed(txHash);\n&nbsp;&nbsp;&nbsp;}\n\n\\\nThe propose function is permissioned and, in our implementation, only allowed to our developers.\n\\\nThere is also an approve function that can only be called by the multisig. The approval time determines the earliest possible execution time.\nfunction approve(bytes32 txHash)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;external override auth returns (uint32 eta)\n&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Proposal memory proposal = proposals[txHash];\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(proposal.state == STATE.PROPOSED, \"Not proposed.\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;eta = uint32(block.timestamp) + delay;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proposal.state = STATE.APPROVED;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proposal.eta = eta;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proposals[txHash] = proposal;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;emit Approved(txHash, eta);\n&nbsp;&nbsp;&nbsp;}\n\n\\\nOnly developers are allowed to execute a change, and they must supply the same batch that was used in the propose function. If the batch is different or the change identifier is incorrect, the change will fail to find the approval and will not be executed.\nfunction execute(Call[] calldata functionCalls)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;external override auth returns (bytes[] memory results)\n&nbsp;&nbsp;&nbsp;{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes32 txHash = keccak256(abi.encode(functionCalls));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Proposal memory proposal = proposals[txHash];\n&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(proposal.state == STATE.APPROVED, \"Not approved.\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(uint32(block.timestamp) >= proposal.eta, \"ETA not reached.\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(uint32(block.timestamp) <= proposal.eta + GRACE_PERIOD, \"Proposal is stale.\");\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delete proposals[txHash];\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;results = new bytes[](functionCalls.length);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for (uint256 i = 0; i < functionCalls.length; i++){\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(functionCalls[i].target.isContract(), \"Call to a non-contract\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(bool success, bytes memory result) = functionCalls[i].target.call(functionCalls[i].data);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (!success) revert(RevertMsgExtractor.getRevertMsg(result));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;results[i] = result;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;emit Executed(txHash);\n&nbsp;&nbsp;&nbsp;}\n\n\\\nIn any situation where a change is being considered, there will be someone who decides that the change should be made, and there will be developers who turn that idea into code. This code, in the form of a batch of function calls, is then fed to the Timelock using `propose`.\n\\\nThe next step is for responsible senior staff, a multisig, or a DAO to review the change and decide whether to approve it, calling `approve`.\n\\\nThis step is the one that is often difficult because understanding the proposed change from the Timelock is difficult. We can make this process easier for them by using existing development tools to provide them with detailed information about the nature of the change.\nReviewing Change in Detail\nOnce a change has been proposed in the Timelock, it becomes immutable thanks to its unique identifier. If a governor approves this identifier, only that exact batch of calls can be executed.\n\\\nWith this in mind, we can:\n`propose` on the real network.\nFork that network.\nImpersonate the governor and `approve` the proposal in the fork.\n`execute` in the fork\n\\\nThe change being executed is the same as the one that was proposed because we forked the network after the proposal. Not only that, but anyone can analyze the execution with a transaction decoder. \n\\\nAt Yield, we use Tenderly, but there are other options available. I made public one of our proposal executions in a fork for educational purposes.\n\\\nAs a multisig member at Yield, I review the execution of every proposal in a fork. I compare the change identifier for approval in the multisig against the change identifier in the fork, and then I know with total certainty that what is in the multisig is what would be executed.\n\\\n \n\\\nAll changes must include a text-based description of their purpose and the parameters being used. I use this to understand what the change does in a broad sense, and then use the transaction decoder to review the detail.\n\\\nI start by comparing the description against the contracts involved in the execution to ensure that they match. Conducting due diligence in this process includes verifying all new contracts and ensuring that their verified code is what is in the repository.\n\\\n \n\\\nKnowing the contracts involved, the events of the transaction provide all the necessary information for reviewing the rest of the execution. \n\\\nI review the permissions granted and revoked, any changes to the oracles, and that the numerical parameters match what was discussed and agreed upon.\n\\\n \n\\\nI document my review on Notion and make it publicly available for each change. Other governors can review my work or conduct their own due diligence in any other way they choose. In any case, I believe that the risk of being caught if I misrepresent a change is now sufficiently high.\nGnosis Safe as a Simpler Alternative\nGnosis Safe now offers a batch builder and automatically creates a simulation on Tenderly for all executions. This is the same functionality I described, with a friendlier interface. \n\\\nIf your governance proposals are simple enough to be created manually in a web interface, Gnosis Safe would be a simpler option. You can share the simulation report from Gnosis Safe and achieve the same result.\n\n\\\nConclusion\nGovernance of blockchain applications is difficult, and as a governor, you risk signing off on changes that could lead to the failure of the application, either by mistake or by design. Recent events have only emphasized the need to protect our users from harm.\n\\\nBy using developer tools and following simple processes at Yield, we have been able to provide governors with clear information about what they are signing off on. We have successfully executed over one hundred separate changes, totaling thousands of contract calls, have reduced the number of governance errors, and are able to catch more mistakes earlier than before.\n\\\nNothing we do is magic; it is simply common sense. Please make sure that you understand what you sign, and ask for the necessary tools if you must. We owe it to our users.","dc:creator":"Alberto Cuesta Cañada ","content":"Governors approving a change should know which functions are being called, what parameters are being used, and what effects these will have. They should be able to find this information on their own, without help from others.\n\nBy forking the network after a governance proposal is recorded and using a transaction decoder it is easier for a multisig member to understand what it is that they are signing on.","contentSnippet":"Governors approving a change should know which functions are being called, what parameters are being used, and what effects these will have. They should be able to find this information on their own, without help from others.\n\nBy forking the network after a governance proposal is recorded and using a transaction decoder it is easier for a multisig member to understand what it is that they are signing on.","guid":"https://hackernoon.com/how-to-review-a-governance-action?source=rss","categories":["blockchain","governance","solidity","ethereum","smart-contracts","how-to","guide"],"isoDate":"2022-12-14T21:20:40.000Z","from":"https://hackernoon.com/feed","hashId":"bfa27a822878681140020f2bc68198ed"},{"creator":"Marcin Wosinek","title":"jquery: Is Still Relevant or Is It a Product of the Past?","link":"https://hackernoon.com/jquery-is-still-relevant-or-is-it-a-product-of-the-past?source=rss","pubDate":"Wed, 14 Dec 2022 21:28:19 GMT","content:encoded":"<p>If you are currently getting into front-end development, you might be confused with jQuery. It can be unclear what it does, why it’s used, and whether it’s something that is still worth learning. Let’s examine this question—starting with a bit of history.</p>\n<h2 id=\"howjquerywashelpingprogrammersin2008\">How Jquery Was Helping Programmers in 2008</h2>\n<p>My first programming job was in 2008. Back then, I was helping build websites, and the main concern at that time was this: will it work in Internet Explorer 6? </p>\n<p>\\\nMaking websites work and look the same in that browser was easily about 50% of the front-end job—and the least fun part.</p>\n<p>\\\njQuery was there to help with many issues related to the browser landscape at that time.</p>\n<h3 id=\"browsercompatibilityissues\">Browser Compatibility Issues</h3>\n<p>There were plenty of differences between browsers. If you tested your code in a modern browser—like Firefox or Chrome—it was not guaranteed to work in Internet Explorer. There were a lot of differences in the CSS, and a bit less in JS. </p>\n<p>\\\nThe best practice at the time was to make the website work first in the modern browser—so it’s <em>future-proof</em>—and then add all the hacks necessary for it to work in the older browser.</p>\n<p>\\\njQuery addressed part of those issues—the methods it was providing were working the same in all the supported browsers. All the workarounds were removed from the application codebase. </p>\n<p>\\\nThere were many libraries with user interface (UI) components built on top of jQuery—most notably jQuery UI—and using those libraries saved a lot of headaches with getting marketing interface elements looking correct and working across all the browsers.</p>\n<h3 id=\"selectors\">Selectors</h3>\n<p>CSS has a very reasonable model for picking the elements from a document: selectors. </p>\n<p>\\\nAt that time, JavaScript was used only on the browser: so, JS and CSS were used by the same people, and they wanted the CSS selectors on the JS side too. At that time, browsers had nothing like this available natively.</p>\n<p>\\\nThis was another feature provided with jQuery. With it, you could find DOM elements with something as simple as</p>\n<pre><code>var element = $(‘.some-class’);\n</code></pre>\n<h3 id=\"obscurebrowserapis\">Obscure Browser APIs</h3>\n<p>The first version of JavaScript was developed in 10 days—so there were many rough edges. </p>\n<p>\\\nIts ad hoc nature continued over the years. <code>XMLHttpRequest</code> was a key feature to turn JavaScript into a language that can be used to develop browser-side applications—it allowed for doing additional requests from the JS to the server. The way of using it isn’t nice to read:</p>\n<pre><code>const request = new XMLHttpRequest();\nrequest.addEventListener(\"load\", function () {\n    console.log(this.responseText);\n  }\n);\nrequest.open(\"GET\", \"http://www.example.org/example.txt\");\nrequest.send();\n</code></pre>\n<p>\\\nWith jQuery, the same goal could be achieved with much more readable:</p>\n<pre><code>$.ajax({\n method: \"GET\",\n url: \"http://www.example.org/example.txt\",\n})\n .done(function( msg ) {\n   // or however the result was read in jQuery 1.2\n   console.log(msg);\n });\n</code></pre>\n<h2 id=\"solutionsprovidedbymodernbrowsers\">Solutions Provided by Modern Browsers</h2>\n<p>If you started your frontend journey recently, it’s unlikely that you ever saw those issues in practice—unless you are maintaining an IE 6 interface to a legacy application that was fossilized in some corporate environment.</p>\n<p>\\\nThanks to evergreen browsers, we hardly hear about compatibility issues nowadays. If your everyday business application works, you can assume that all browsers work the same. And wait for bug reports in case that they don’t all work the same.</p>\n<p>\\\nAPI issues are addressed as well—we have <code>document.querySelectorAll</code> and <code>fetch</code> that provides a nice API to perform common operations with native functions.</p>\n<h2 id=\"stillaprettypopularpackage\">Still a Pretty Popular Package</h2>\n<p>Even though jQuery is not in the spotlight anymore, it’s still a very popular package:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/cPKBkmirofPe9l3sgbPBAqdKwGF3-2022-12-14T21:28:18.646Z-clbo5zlco00040as67dsn37ff\" alt=\"Image description\" /></p>\n<p>If you <a href=\"https://npmtrends.com/@angular/core-vs-jquery-vs-react-vs-vue\">compare it with React, Vue, and Angular</a>, only React has more downloads. You can expect to see it in many projects that are out there. Especially if you consider that plenty of jQuery usages will likely not come via NPM—many will use the deprecated package manager Bower or CDN links.</p>\n<h2 id=\"whyusejqueryin2022\">Why Use jQuery in 2022?</h2>\n<p>The main reason I see is that you have a team that is accustomed to it—maybe not necessarily frontend developers, but perhaps content authors, designers, or marketing specialists who learned to do things with jQuery and see no reason to change things.</p>\n<p>\\\nYou might also still do so for consistency’s sake. For example, if in the codebase there are 200 <code>$.ajax</code> calls, I would think twice before adding some <code>fetch</code> call. It would be the start of a big refactoring, and I’m not sure in what situation it would make sense to invest so much effort into it.</p>\n<h2 id=\"shouldyoulearnjquery\">Should You Learn jQuery?</h2>\n<p>Learning it will not hurt you, but <strong>introducing</strong> it into a project can raise a few eyebrows. For greenfield projects, it makes sense to default to vanilla JS. </p>\n<p>\\\nAnd if you join a project that uses jQuery heavily, you can most likely learn it on the job just fine by reading documentation (I wrote a <a href=\"https://how-to.dev/how-to-read-the-documentation\">guide</a> for it) and getting code examples from the rest of the codebase.</p>\n<h2 id=\"howaboutyou\">How About You?</h2>\n<p>Are you using jQuery yourself? Have you seen it often in projects or job offers? Share your jQuery story in the comments!</p>","content:encodedSnippet":"If you are currently getting into front-end development, you might be confused with jQuery. It can be unclear what it does, why it’s used, and whether it’s something that is still worth learning. Let’s examine this question—starting with a bit of history.\nHow Jquery Was Helping Programmers in 2008\nMy first programming job was in 2008. Back then, I was helping build websites, and the main concern at that time was this: will it work in Internet Explorer 6? \n\\\nMaking websites work and look the same in that browser was easily about 50% of the front-end job—and the least fun part.\n\\\njQuery was there to help with many issues related to the browser landscape at that time.\nBrowser Compatibility Issues\nThere were plenty of differences between browsers. If you tested your code in a modern browser—like Firefox or Chrome—it was not guaranteed to work in Internet Explorer. There were a lot of differences in the CSS, and a bit less in JS. \n\\\nThe best practice at the time was to make the website work first in the modern browser—so it’s future-proof—and then add all the hacks necessary for it to work in the older browser.\n\\\njQuery addressed part of those issues—the methods it was providing were working the same in all the supported browsers. All the workarounds were removed from the application codebase. \n\\\nThere were many libraries with user interface (UI) components built on top of jQuery—most notably jQuery UI—and using those libraries saved a lot of headaches with getting marketing interface elements looking correct and working across all the browsers.\nSelectors\nCSS has a very reasonable model for picking the elements from a document: selectors. \n\\\nAt that time, JavaScript was used only on the browser: so, JS and CSS were used by the same people, and they wanted the CSS selectors on the JS side too. At that time, browsers had nothing like this available natively.\n\\\nThis was another feature provided with jQuery. With it, you could find DOM elements with something as simple as\nvar element = $(‘.some-class’);\n\nObscure Browser APIs\nThe first version of JavaScript was developed in 10 days—so there were many rough edges. \n\\\nIts ad hoc nature continued over the years. XMLHttpRequest was a key feature to turn JavaScript into a language that can be used to develop browser-side applications—it allowed for doing additional requests from the JS to the server. The way of using it isn’t nice to read:\nconst request = new XMLHttpRequest();\nrequest.addEventListener(\"load\", function () {\n    console.log(this.responseText);\n  }\n);\nrequest.open(\"GET\", \"http://www.example.org/example.txt\");\nrequest.send();\n\n\\\nWith jQuery, the same goal could be achieved with much more readable:\n$.ajax({\n method: \"GET\",\n url: \"http://www.example.org/example.txt\",\n})\n .done(function( msg ) {\n   // or however the result was read in jQuery 1.2\n   console.log(msg);\n });\n\nSolutions Provided by Modern Browsers\nIf you started your frontend journey recently, it’s unlikely that you ever saw those issues in practice—unless you are maintaining an IE 6 interface to a legacy application that was fossilized in some corporate environment.\n\\\nThanks to evergreen browsers, we hardly hear about compatibility issues nowadays. If your everyday business application works, you can assume that all browsers work the same. And wait for bug reports in case that they don’t all work the same.\n\\\nAPI issues are addressed as well—we have document.querySelectorAll and fetch that provides a nice API to perform common operations with native functions.\nStill a Pretty Popular Package\nEven though jQuery is not in the spotlight anymore, it’s still a very popular package:\n\nIf you compare it with React, Vue, and Angular, only React has more downloads. You can expect to see it in many projects that are out there. Especially if you consider that plenty of jQuery usages will likely not come via NPM—many will use the deprecated package manager Bower or CDN links.\nWhy Use jQuery in 2022?\nThe main reason I see is that you have a team that is accustomed to it—maybe not necessarily frontend developers, but perhaps content authors, designers, or marketing specialists who learned to do things with jQuery and see no reason to change things.\n\\\nYou might also still do so for consistency’s sake. For example, if in the codebase there are 200 $.ajax calls, I would think twice before adding some fetch call. It would be the start of a big refactoring, and I’m not sure in what situation it would make sense to invest so much effort into it.\nShould You Learn jQuery?\nLearning it will not hurt you, but introducing it into a project can raise a few eyebrows. For greenfield projects, it makes sense to default to vanilla JS. \n\\\nAnd if you join a project that uses jQuery heavily, you can most likely learn it on the job just fine by reading documentation (I wrote a guide for it) and getting code examples from the rest of the codebase.\nHow About You?\nAre you using jQuery yourself? Have you seen it often in projects or job offers? Share your jQuery story in the comments!","dc:creator":"Marcin Wosinek","content":"If you are currently getting into frontend development, you might be confused with jQuery. It can be unclear what it does, why it’s used, and whether it's something that is still worth learning. The first version of JavaScript was developed in 10 days, so there were many rough edges. With it, you could find DOM elements with something as simple asvar element. With modern browsers, the same goal could be achieved with much more readable: request = new XMLHttpRequest; // request.open('GET', \"http://www.example.org/example.txt\") // request.open(function(msg)","contentSnippet":"If you are currently getting into frontend development, you might be confused with jQuery. It can be unclear what it does, why it’s used, and whether it's something that is still worth learning. The first version of JavaScript was developed in 10 days, so there were many rough edges. With it, you could find DOM elements with something as simple asvar element. With modern browsers, the same goal could be achieved with much more readable: request = new XMLHttpRequest; // request.open('GET', \"http://www.example.org/example.txt\") // request.open(function(msg)","guid":"https://hackernoon.com/jquery-is-still-relevant-or-is-it-a-product-of-the-past?source=rss","categories":["javascript","beginners","jquery","webdev","hackernoon-top-story","front-end-development","frontend","programming","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja"],"isoDate":"2022-12-14T21:28:19.000Z","from":"https://hackernoon.com/feed","hashId":"fe2bc4d98bee1f08e8821ef58fa14efd"},{"creator":"Dmitry Shishov","title":"How to Earn During a Bearish Market","link":"https://hackernoon.com/how-to-earn-during-a-bearish-market?source=rss","pubDate":"Wed, 14 Dec 2022 21:35:39 GMT","content:encoded":"<div class=\"paragraph\">The market is bearish when the asset price is falling or is low - this is a common belief. But how then is it possible to earn during the bearish market? </div><div class=\"paragraph\">Or is the best way to hold the asset in the hope that its price will grow sooner or later?</div><h2>Market Moves in Cycles</h2><div class=\"paragraph\">The thing is that no market goes in a straight line. Any asset price is affected by investor sentiment and business cycles. And on these fluctuations, investors tend to earn if they build their strategy correctly. </div><div class=\"paragraph\">The top strategies for earning in the bearish market are the following.</div><h2>Dollar-Cost Averaging (DCA)</h2><div class=\"paragraph\">Even though the name of this strategy sounds complicated, in reality, it is about investing small sums at regular intervals rather than investing all available funds at a single time. By doing this, you achieve two goals:</div><div class=\"paragraph\">you are building stronger positions.</div><div class=\"paragraph\">you are averaging the negative effects of short-time price fluctuations.</div><div class=\"paragraph\">The best way to go about dollar-cost averaging is to use crypto bots. You set them up to buy when specific conditions are met, and they do so. With it, you eliminate the emotional component and avoid making spontaneous investment decisions.</div><div class=\"paragraph\">This is the best strategy to use for beginners who don’t yet have the needed experience to judge when it is better to buy. It is also suitable for long-term investors who don’t have time to follow rapid price changes and are committed to a specific asset.</div><div class=\"paragraph\">However, this strategy isn’t suitable when the prices are trending steadily in one direction or the other. And it works only if we expect that the asset price will ultimately increase.</div><div class=\"paragraph\">Also, you shall consider that transaction costs will be higher if you choose to use the DCA strategy instead of buying an asset in bulk.</div><h2>Trading a Downtrend</h2><div class=\"paragraph\">It is one of the most common strategies used to earn in a bearish market. Every investment or trading activity has one rule: buy low, sell high (BLSH). When you are trading a downtrend, you first sell, and then, buy. </div><div class=\"paragraph\">For example, you have BTC, and its price is moving down. Your BTC is worth $20,000 now. You expect it to fall. So, you sell your BTC and get $20,000. </div><div class=\"paragraph\">The next day, the BTC price dropped to $19,500. You buy it. So, you have the same amount of BTC but you sold it for $20,000 and purchased it for $19,500. Your profit is $500.</div><div class=\"paragraph\"><a href=\"https://www.investopedia.com/terms/s/shortselling.asp\">Short-selling</a> is one of the most common ways to trade a downtrend. </div><div class=\"paragraph\">The principle of short-selling is the same, with the only difference being that traders borrow funds to trade them. </div><div class=\"paragraph\">So, instead of selling your own BTC, you borrow the crypto from a broker, sell it, and then, buy the same amount of coins when their price drops. You return the borrowed funds to the broker and stay with the profit. </div><div class=\"paragraph\">But this strategy comes with increased risks because if the asset price grows, you will have to buy it for more money than you’ve sold it for. </div><div class=\"paragraph\">For example, if BTC grows from $20,000 to $25,000, you will have to buy it for the new price to repay the loan. Your loss will be $25,000 - $20,000 = $5,000. </div><div class=\"paragraph\">On top of that, you will also have to pay the interest generated by the loan.</div><div class=\"paragraph\">Short-selling can generate practically unlimited returns if used correctly but the losses are also unlimited if you don’t calculate everything properly. That’s why this strategy is recommended for advanced traders only.</div><h2>Lending, Staking, and Yield Farming</h2><div class=\"paragraph\">Less experienced users can try lending, staking, and yield farming to get income from the funds they have.</div><div class=\"paragraph\">Lending is much more secure than trading. If you have free coins, you can lend them to other users via a<a href=\"https://academy.binance.com/en/articles/what-is-crypto-lending-and-how-does-it-work\"> lending platform</a>. Those who borrow your coins pay interest, and you get your share from it. </div><div class=\"paragraph\">Staking is when you lock coins on a platform and receive rewards. After the locking period is over, you can get your coins back. There are staking plans that don’t have any locking period. </div><div class=\"paragraph\">It means that you can withdraw your funds whenever you want. But normally, rewards there are lower, too. </div><div class=\"paragraph\">Some platforms pay their users for providing liquidity. You lock your coins in a platform’s liquidity pool and in return, the platform rewards you with its native tokens. This way to earn is called yield farming.</div><div class=\"paragraph\">It is important to remember that these activities are profitable only if rewards are higher than the losses caused by the token price decline and/or if the token price is expected to grow eventually.</div><div class=\"paragraph\">For example, you lend 1 ETH worth $1,000 with a 5% interest rate. By the time the loan has to be repaid, ETH dropped by 10% and costs $900. You receive your 1ETH (valued at $900) + $50 in interest. </div><div class=\"paragraph\">So, instead of generating income, you lose $50 (you lend an equivalent of $1,000, and get back $950). </div><div class=\"paragraph\">Therefore, lending, as well as staking and yield farming, are profitable only if the price drop doesn’t exceed the percentage paid to you for your coins. </div><h2>Scalping</h2><div class=\"paragraph\">Given the volatility of the crypto market,<a href=\"https://primexbt.com/for-traders/what-is-scalping-in-cryptocurrency/\"> scalping</a> can bring significant profit during the bearish market. Scalpers benefit from selling and buying crypto within very short periods thus earning on very small price fluctuations. </div><div class=\"paragraph\">Multiple trades are placed during a very short period, therefore, smaller gains from individual trades accumulate to significant sums.</div><div class=\"paragraph\">Scalping requires a deep understanding of the market and an underlying asset. That’s why this activity is not recommended for beginners.</div><h2>Conclusion</h2><div class=\"paragraph\">While nobody knows for sure when a bearish market is going to end, all the previous bear markets have consistently been followed by a bull market. </div><div class=\"paragraph\">While many traders create a portfolio and develop a long-term plan that isn’t influenced by short-term market drops, others rely on more active practices to get over unfavorable circumstances. </div><div class=\"paragraph\">Whatever option you choose, remember a saying that a quick buck can be made during a bullish market but the wealth is built in a bearish market when the asset price is low.</div>","content:encodedSnippet":"The market is bearish when the asset price is falling or is low - this is a common belief. But how then is it possible to earn during the bearish market? \nOr is the best way to hold the asset in the hope that its price will grow sooner or later?\nMarket Moves in Cycles\nThe thing is that no market goes in a straight line. Any asset price is affected by investor sentiment and business cycles. And on these fluctuations, investors tend to earn if they build their strategy correctly. \nThe top strategies for earning in the bearish market are the following.\nDollar-Cost Averaging (DCA)\nEven though the name of this strategy sounds complicated, in reality, it is about investing small sums at regular intervals rather than investing all available funds at a single time. By doing this, you achieve two goals:\nyou are building stronger positions.\nyou are averaging the negative effects of short-time price fluctuations.\nThe best way to go about dollar-cost averaging is to use crypto bots. You set them up to buy when specific conditions are met, and they do so. With it, you eliminate the emotional component and avoid making spontaneous investment decisions.\nThis is the best strategy to use for beginners who don’t yet have the needed experience to judge when it is better to buy. It is also suitable for long-term investors who don’t have time to follow rapid price changes and are committed to a specific asset.\nHowever, this strategy isn’t suitable when the prices are trending steadily in one direction or the other. And it works only if we expect that the asset price will ultimately increase.\nAlso, you shall consider that transaction costs will be higher if you choose to use the DCA strategy instead of buying an asset in bulk.\nTrading a Downtrend\nIt is one of the most common strategies used to earn in a bearish market. Every investment or trading activity has one rule: buy low, sell high (BLSH). When you are trading a downtrend, you first sell, and then, buy. \nFor example, you have BTC, and its price is moving down. Your BTC is worth $20,000 now. You expect it to fall. So, you sell your BTC and get $20,000. \nThe next day, the BTC price dropped to $19,500. You buy it. So, you have the same amount of BTC but you sold it for $20,000 and purchased it for $19,500. Your profit is $500.\nShort-selling is one of the most common ways to trade a downtrend. \nThe principle of short-selling is the same, with the only difference being that traders borrow funds to trade them. \nSo, instead of selling your own BTC, you borrow the crypto from a broker, sell it, and then, buy the same amount of coins when their price drops. You return the borrowed funds to the broker and stay with the profit. \nBut this strategy comes with increased risks because if the asset price grows, you will have to buy it for more money than you’ve sold it for. \nFor example, if BTC grows from $20,000 to $25,000, you will have to buy it for the new price to repay the loan. Your loss will be $25,000 - $20,000 = $5,000. \nOn top of that, you will also have to pay the interest generated by the loan.\nShort-selling can generate practically unlimited returns if used correctly but the losses are also unlimited if you don’t calculate everything properly. That’s why this strategy is recommended for advanced traders only.\nLending, Staking, and Yield Farming\nLess experienced users can try lending, staking, and yield farming to get income from the funds they have.\nLending is much more secure than trading. If you have free coins, you can lend them to other users via a lending platform. Those who borrow your coins pay interest, and you get your share from it. \nStaking is when you lock coins on a platform and receive rewards. After the locking period is over, you can get your coins back. There are staking plans that don’t have any locking period. \nIt means that you can withdraw your funds whenever you want. But normally, rewards there are lower, too. \nSome platforms pay their users for providing liquidity. You lock your coins in a platform’s liquidity pool and in return, the platform rewards you with its native tokens. This way to earn is called yield farming.\nIt is important to remember that these activities are profitable only if rewards are higher than the losses caused by the token price decline and/or if the token price is expected to grow eventually.\nFor example, you lend 1 ETH worth $1,000 with a 5% interest rate. By the time the loan has to be repaid, ETH dropped by 10% and costs $900. You receive your 1ETH (valued at $900) + $50 in interest. \nSo, instead of generating income, you lose $50 (you lend an equivalent of $1,000, and get back $950). \nTherefore, lending, as well as staking and yield farming, are profitable only if the price drop doesn’t exceed the percentage paid to you for your coins. \nScalping\nGiven the volatility of the crypto market, scalping can bring significant profit during the bearish market. Scalpers benefit from selling and buying crypto within very short periods thus earning on very small price fluctuations. \nMultiple trades are placed during a very short period, therefore, smaller gains from individual trades accumulate to significant sums.\nScalping requires a deep understanding of the market and an underlying asset. That’s why this activity is not recommended for beginners.\nConclusion\nWhile nobody knows for sure when a bearish market is going to end, all the previous bear markets have consistently been followed by a bull market. \nWhile many traders create a portfolio and develop a long-term plan that isn’t influenced by short-term market drops, others rely on more active practices to get over unfavorable circumstances. \nWhatever option you choose, remember a saying that a quick buck can be made during a bullish market but the wealth is built in a bearish market when the asset price is low.","dc:creator":"Dmitry Shishov","content":"Many investors are inactive during a bearish market that’s why it is believed that it is better to hold your coins rather than trying to earn profit. But the truth is that any market moves in cycles, and the bearish market is not an exception. That’s why it is possible to get some profit even when bears rule. Here, you can read about the top strategies to earn during a bearish market. \n","contentSnippet":"Many investors are inactive during a bearish market that’s why it is believed that it is better to hold your coins rather than trying to earn profit. But the truth is that any market moves in cycles, and the bearish market is not an exception. That’s why it is possible to get some profit even when bears rule. Here, you can read about the top strategies to earn during a bearish market.","guid":"https://hackernoon.com/how-to-earn-during-a-bearish-market?source=rss","categories":["bear-market-diaries","crypto-bear-market","bear-market","make-money-in-bear-market","crypto","cryptocurrency","hackernoon-top-story","stock-market","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja"],"isoDate":"2022-12-14T21:35:39.000Z","from":"https://hackernoon.com/feed","hashId":"d9106b12d9b75864cd711b2b023520a1"},{"creator":"Max Albert","title":"How A Solopreneur Used Influencer Marketing to Reach the iOS Top 100 List","link":"https://hackernoon.com/how-a-solopreneur-used-influencer-marketing-to-reach-the-ios-top-100-list?source=rss","pubDate":"Wed, 14 Dec 2022 22:03:48 GMT","content:encoded":"<h2 id=\"howtofindandleverageinfluencerstomarketyournbspapp\">How to Find, and Leverage Influencers To Market Your&nbsp;App</h2>\n<p>\\\nEver since iOS 14.5&nbsp;<a href=\"https://www.crimtan.com/news/has-ios-14-killed-off-facebook-ads-and-why-that-may-a-good-thing/\">handicapped programmatic marketing</a>&nbsp;in April of 2021,&nbsp;<strong>influencer marketing —</strong> the process of having an influencer promote your product <strong>—</strong> has become increasingly important.</p>\n<p>\\\nIn fact,&nbsp;<a href=\"https://influencermarketinghub.com/influencer-marketing-benchmark-report/\">i</a><a href=\"https://medium.com/r?url=https%3A%2F%2Finfluencermarketinghub.com%2Finfluencer-marketing-benchmark-report%2F\">nfluencer marketing campaigns grew a staggering 26% in 2021 and the trend appears to be continuing in 2022.</a></p>\n<p>\\\nMany bootstrapped startup founders &amp; indie entrepreneurs believe that influencer marketing is out of reach for them.</p>\n<p>\\\nOften I hear founders say:</p>\n<p>\\</p>\n<ul>\n<li><p>“Aren’t influencers&nbsp;<em>super</em>&nbsp;expensive?”</p></li>\n<li><p>“What would influencers want to do with me and my product?”</p></li>\n<li><p>“I can’t get in touch with influencers even if I tried.”</p>\n<p>\\</p></li>\n</ul>\n<p>I’m here to tell you that influencer marketing is more accessible than you think!</p>\n<p>\\\nWhy? Because I was able to partner with NFL wide receiver Donovan Peoples-Jones to market my mobile game&nbsp;<a href=\"http://deeppassjam.com/\">DeepPassJam.com</a>&nbsp;to the iOS top 100 free games list without paying a cent.</p>\n<p>\\\nHere’s how I did it, and how you can do it too!</p>\n<p>\\\n<em>Note: Even though our product was a mobile game, all these tips are applicable to mobile apps and “direct-to-consumer” products too!</em></p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/AA0S3G9weRM3biUfJZ9ilO0mpDx1-waa345d.jpeg\" alt=\"\" /></p>\n<p>\\</p>\n<h2 id=\"step1identifyandmakeanbsplist\">Step 1: Identify and Make A&nbsp;List</h2>\n<p>Start by creating a spreadsheet of your top 50 ideal influencers to work with.</p>\n<p>\\\nYou should separate your list into 4 columns: “Name” “Contact” “Passion” and “Status.”</p>\n<p>\\\nUnder the contact column, write down the most convenient way to contact the influencer. A warm intro is most preferred, followed by email, followed by text, followed by in-browser “contact me” page, followed by cold social media DM.</p>\n<p>\\\nQuite often, smaller creators will have their business email available publicly if you scan their social media and website site.</p>\n<p>\\\nIf you cannot find an avenue to contact them, then the influencer is likely too big — leave the contact column blank.</p>\n<p>\\\nUnder the passion column, rate on a scale from 1 to 5 how much passion you would have to work with them if they said “yes.”</p>\n<p>\\\nUnder the status column, write down the status of reaching out. All the influencers will start with a status of “have not contacted.” Once you reach out once, change to “Contacted x1”</p>\n<p>\\\nIf you follow up once, change to “Contacted x2”. If they respond, then change to “Negotiating.”</p>\n<p>\\\nIf they ultimately decide to pass, or you follow up 3 times without a response change this column to “Contact lost.” This column serves as a&nbsp;<strong>Client Relationship Manager</strong>&nbsp;tool to keep you organized.</p>\n<p>\\\nSort the list by contact method quality.</p>\n<p>\\\nFrom there, sort the list again by passion.</p>\n<p>\\\nYou should reach out to creators in this order. Eight creators at a time. You should follow up three times without a response before you give up on reaching that creator.</p>\n<p>\\\nA few tips to think about when creating your list:</p>\n<p>\\</p>\n<ul>\n<li><strong>Target Smaller Influencers —</strong> Big influencers cost big bucks. Smaller influencers are often very affordable or even “free” (more on this later). Target influencers with followings under 50k on YouTube/Instagram or 500k on Tik Tok to start.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p><strong>Ensure Your Influencer Has The Right Influence —</strong> Some influencers have astronomical follower counts but when you look at their content, it’s not engaged with or only being engaged by bots.</p>\n<p>\\\nBeware of influencers like this! Also, it’s critical that the influencer has an audience that matches&nbsp;<strong>the demographics</strong>&nbsp;of people who use your product.</p>\n<p>\\\nIt doesn’t matter how many followers Oprah Winfrey has, if she promotes a First Person Shooter game (something typically younger men enjoy), the campaign could perform catastrophically poorly since Oprah’s following tends to consist of older women!</p></li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p><strong>Have An “In” —</strong> Prioritize influencers you can actually get in touch with: either via warm intro or because they have their business email readily available. Golden rule: avoid their agent at all costs! Agents care about one thing only, money upfront.</p>\n<p>\\\nIf you’re a startup founder, you likely don’t have the budget to be shoveling out loads of cash on influencer marketing campaigns. Instead, you could try contacting someone in the influencer’s orbit first: someone in their “entourage.”</p>\n<p>\\\nIf you can convince them of a quality product, they’ll likely be willing to warm intro you to the influencer at that point.</p>\n<p>\\</p></li>\n<li><p><strong>If you’re really struggling to find an “in”</strong> — You can reach out to&nbsp;<em>small</em>&nbsp;marketing agencies such as&nbsp;<a href=\"https://www.homeplate.media/\">Homeplate</a>&nbsp;or&nbsp;<a href=\"https://courtsidegroup.com/\">Courtside</a>&nbsp;as these agencies are likely to have connections to influencers. Keep in mind, these agencies will likely require a fee for their services. But they might be affordable to you.</p></li>\n</ul>\n<p>\\</p>\n<ul>\n<li><strong>Don’t discount&nbsp;<em>your</em>&nbsp;passion —</strong> It’s important to identify which creators you’d most like to work with because your passion for their brand will come off in the pitch.</li>\n</ul>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/AA0S3G9weRM3biUfJZ9ilO0mpDx1-85b34yj.jpeg\" alt=\"\" /></p>\n<p>\\</p>\n<h2 id=\"step2thenbsppitch\">Step 2: The&nbsp;Pitch</h2>\n<p>It’s time to reach out and pitch influencers you’ve identified.</p>\n<p>\\\nInfluencer partnerships are&nbsp;<strong>relationship based</strong>. That is to say your reputation matters. Influencers only work with people they trust. Here are some items that can help give you credibility when you initially reach out:</p>\n<p>\\</p>\n<ul>\n<li>A strong portfolio of past products you’ve created that have good reviews.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>An active community — even if it’s small — of existing &amp; happy users.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>Strong concept art of the future product — the more personalized to the influencer the better.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>A mutual acquaintance that can speak to your talents.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p>A strong “why” or mission to illuminate why you’re doing what you’re doing.</p>\n<p>\\</p></li>\n</ul>\n<p>For instance, my initial text to Donovan read:</p>\n<p>\\</p>\n<blockquote>\n  <p>Hey Donovan! I own a game studio called AppStop.io — we make sports games starring pro athletes. Our last moible game “QB Chase” starred Chase Winovich and is rated 4.9 stars on the iOS store. I’d love to build you a mobile game, completely free of charge. Curious if you have 30 minutes to discuss details next week?</p>\n</blockquote>\n<p>\\\nFull disclosure, I did have a warm intro to Donovan, but if I didn’t, I don’t believe I would’ve changed much about the initial text. I would’ve only included concept art in the initial message to grab attention, make the pitch more exciting, and make the pitch more personalized.</p>\n<p>\\\nIn our next meeting, I showed off a short slide deck highlighting my game studio, what I envisioned for Donovan’s game, how AppStop.io partners with philanthropies to donate money (this turned out to be critical), and concept art for how the game would look with Donovan in it.</p>\n<p>\\\nA few pro tips to keep in mind when entering the final pitch:</p>\n<p>\\</p>\n<ul>\n<li><strong>Keep it Short —</strong> What is your product? What makes your product the next big thing? What is your “ask” for the influencer? Keep it lean.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p><strong>Content is King — (IMPORTANT):</strong>&nbsp;There’s a common misconception that influencers only care about money. In my experience, influencers do care about money but what they care even more about is&nbsp;<em>content</em>.</p>\n<p>\\\nIf you can convince the influencer that your product will inspire content that will thrill their community and that your company can actually&nbsp;<em>create</em>&nbsp;that content on the influencer’s behalf, then they’re very likely to want to do business with you — perhaps even for free.</p>\n<p>\\\nThis could be a giveaway, custom digital art, or a cool video or Tik Tok. In our case, we let Donovan know that we would create Instagram content on his behalf and that this Instagram content would perform great (more on this in step 3)</p></li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p><strong>Do You Need to Pay? —</strong> You don’t always need to pay the influencer an&nbsp;<strong>upfront guarantee.</strong>&nbsp;This is especially true if your product is remarkable, your intro is particularly warm, and the marketing activation is very easy for them to implement.</p>\n<p>\\</p></li>\n<li><p>You&nbsp;<em>do</em>&nbsp;need to offer them&nbsp;<em>something</em>&nbsp;such as revenue share, content creation services, or philanthropic donations.</p>\n<p>\\\nSmaller influencers may also be fine with accepting an upfront guarantee as small as ~$500 simply so they can develop their own portfolio of successful marketing campaigns for when larger businesses reach out.</p>\n<p>\\</p></li>\n<li><p><strong>Have Thick Skin —</strong> If you reach out to 100 influencers cold and even three respond, then that’s a huge success. Influencers are flooded with entrepreneurs such as yourself (now more than ever), and they can’t get to every pitch.</p>\n<p>\\\nHave patience, and don’t take rejection personally. Every influencer you work with gives you more credibility. The first deal is the hardest.</p>\n<p>\\</p></li>\n</ul>\n<p>After the pitch is over, be sure to sign a licensing agreement with the influencer(s) so that you have the ability to use their Name, Image, and Likeness (NIL) in app and on promotional content.</p>\n<p>\\\nEven though it’s a hassle, it’s important to sign these contracts so that each party is committed to following through on their end of the deal.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/AA0S3G9weRM3biUfJZ9ilO0mpDx1-p1c343z.jpeg\" alt=\"\" /></p>\n<h2 id=\"chapter3implementingtheinfluencermarketingcampaign\">Chapter 3: Implementing the Influencer Marketing Campaign</h2>\n<p>The first thing to note is that the influencer’s fans are not the end all be all of your app’s users. Ideally speaking, you should think of influencers as a&nbsp;<strong>marketing catalyst</strong>&nbsp;that can increase two important stats:</p>\n<p>\\</p>\n<ul>\n<li>Get your app on the top charts of various AppStores — thereby increasing “<strong>organic</strong>&nbsp;**growth” (**i.e., users naturally finding you online)</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p>Provide a solid foundation of users that will naturally share the app with their friends. Often, this is called the “<strong>K-Factor.”</strong></p>\n<p>\\</p></li>\n</ul>\n<p>The right marketing strategy should always have your organic growth and K-Factor be the primary source of users. For instance, our game, Deep Pass Jam, grew 213% from users naturally finding us on the top iOS charts.</p>\n<p>\\\nThat means that all the marketing we did with the influencer accounted for less than half of our final total users! But, we still needed the influencer as a catalyst to get onto the top 100 charts to reap those benefits.</p>\n<hr />\n<p>The next thing to keep in mind is content delivery. Sometimes the influencers will want to create the content for the marketing campaign. Often, they will want you to create the content and then they will approve the content with edits.</p>\n<p>\\\nIt is very critical to express&nbsp;<em>who</em>&nbsp;is responsible for creating&nbsp;<em>what</em>&nbsp;content and&nbsp;<em>when</em>&nbsp;you plan to have the influencer post it. If you don’t express this in plain language, it will not be posted, or worse; the content could be posted incorrectly — having catastrophic consequences.</p>\n<p>\\\nIn our case, we expressed to Donovan that AppStop.io would be creating the content. We had a trick up our sleeve. We knew semi-realistic video game content performs&nbsp;<em>unbelievably well</em> on social media.</p>\n<p>\\\nIt’s jarring and fun for the viewer to see the digital version of your favorite character inside a video game. This type of content increased Kim Kardashian, Connor McGregor, and Gordon Ramsay’s social media engagement.</p>\n<p>\\\nSo, we had our animators get to work. In the end, Donovan got to relax for a week while his Instagram engagement increased a tremendous 300% because of the content we created on his behalf:</p>\n<p><a href=\"https://www.instagram.com/p/CZU0aFQJfI_/?embedable=true\">https://www.instagram.com/p/CZU0aFQJfI_/?embedable=true</a></p>\n<p>\\\nRegardless, a few tips and tricks with any content you plan to have the influencer post:</p>\n<p>\\</p>\n<ul>\n<li><strong>Include a Call-To-Action —</strong> Ensure there’s an easy off-ramp from the content to have consumers download your app</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><strong>Provide Value —</strong> The best social media content is content that can provide value to the viewer. Make the viewer laugh, give them valuable information, and show them something emotional. It’s important to study other apps’ high-performing content to see what worked for them and copy that format!</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><strong>Create a Network Effect —</strong> Influencers often have strong ties to other influencers with followings. Make it easy for them to engage and re-share the content by having the art be high-quality, tying the product to a larger mission (possibly a philanthropic partnership), and highlighting ownership of the original influencer.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p>Balance the Influencer’s Presence —While having the influencer star in promotional content and in-app can help drive traffic from fans who know the influencer, it can also be off-putting to those who aren’t familiar with the influencer. </p>\n<p>\\\nThat’s why it’s important for the influencer to have a “muted” presence. They shouldn’t be plastered on the front page of every piece of content, but they should be visible in&nbsp;<em>some</em>&nbsp;of the content.</p>\n<p>\\</p></li>\n</ul>\n<p>In addition to posting content, it’s important to know the data behind what you’re posting. Have a plan on exactly how many downloads you hope to gain from the influencer’s promotion. Stats matter because they can help advise content strategy.</p>\n<p>\\\nHere are some of the most important statistics every startup founder should know about the AppStore:</p>\n<p>\\</p>\n<ul>\n<li><p><a href=\"https://techcrunch.com/2022/06/02/new-report-examines-the-number-of-downloads-it-takes-to-hit-the-top-of-the-app-store/\">According to Tech Crunch, it requires roughly 8,000 downloads in a 24-hour period to get on the U.S. top 100 iOS free games list. 26,000 downloads to get into the top 10. Business apps are double those numbers. 16,000 for the top 100 and 52,000 for the top 10 of any business category.</a>&nbsp;Of course, these numbers can vary from day to day.</p>\n<p>\\</p></li>\n<li><p><a href=\"https://appfollow.io/benchmark?store=as&channel=%20appStoreBrowse&country=us&date=2022-07-11\">Certain app genres have different AppStore conversion rates.</a>&nbsp;Know what your genre’s average conversion rate is. If your app’s conversion rate is below average that means that you are missing out on important organic growth and need to improve your AppStore’s promotional content. </p>\n<p>\\\nSometimes this process is called “AppStore Optimization” or “ASO.” The most important promotional content is the photo previews of your app. Ensure these are very high quality prior to launching an influencer campaign.</p>\n<p>\\</p></li>\n</ul>\n<p>In conclusion, influencer marketing can be a powerful tool for bootstrapped startups looking to scale their apps. By partnering with influential individuals within their target market, startups can tap into their existing audience and gain valuable exposure for their apps. </p>\n<p>\\\nThis can help drive downloads and increase user engagement, ultimately helping the startup to grow and succeed.</p>\n<p>\\\nTo get started with influencer marketing, startups should identify potential influencers within their target market, offer them incentives to promote their app, and track the results to see if the strategy is effective.</p>\n<p>\\\nBy implementing influencer marketing as part of their growth strategy, bootstrapped startups can take their app to new heights.</p>","content:encodedSnippet":"How to Find, and Leverage Influencers To Market Your App\n\\\nEver since iOS 14.5 handicapped programmatic marketing in April of 2021, influencer marketing — the process of having an influencer promote your product — has become increasingly important.\n\\\nIn fact, influencer marketing campaigns grew a staggering 26% in 2021 and the trend appears to be continuing in 2022.\n\\\nMany bootstrapped startup founders & indie entrepreneurs believe that influencer marketing is out of reach for them.\n\\\nOften I hear founders say:\n\\\n\n\n“Aren’t influencers super expensive?”\n\n\n“What would influencers want to do with me and my product?”\n\n\n“I can’t get in touch with influencers even if I tried.”\n\\\nI’m here to tell you that influencer marketing is more accessible than you think!\n\\\nWhy? Because I was able to partner with NFL wide receiver Donovan Peoples-Jones to market my mobile game DeepPassJam.com to the iOS top 100 free games list without paying a cent.\n\\\nHere’s how I did it, and how you can do it too!\n\\\nNote: Even though our product was a mobile game, all these tips are applicable to mobile apps and “direct-to-consumer” products too!\n\\\n \n\\\nStep 1: Identify and Make A List\nStart by creating a spreadsheet of your top 50 ideal influencers to work with.\n\\\nYou should separate your list into 4 columns: “Name” “Contact” “Passion” and “Status.”\n\\\nUnder the contact column, write down the most convenient way to contact the influencer. A warm intro is most preferred, followed by email, followed by text, followed by in-browser “contact me” page, followed by cold social media DM.\n\\\nQuite often, smaller creators will have their business email available publicly if you scan their social media and website site.\n\\\nIf you cannot find an avenue to contact them, then the influencer is likely too big — leave the contact column blank.\n\\\nUnder the passion column, rate on a scale from 1 to 5 how much passion you would have to work with them if they said “yes.”\n\\\nUnder the status column, write down the status of reaching out. All the influencers will start with a status of “have not contacted.” Once you reach out once, change to “Contacted x1”\n\\\nIf you follow up once, change to “Contacted x2”. If they respond, then change to “Negotiating.”\n\\\nIf they ultimately decide to pass, or you follow up 3 times without a response change this column to “Contact lost.” This column serves as a Client Relationship Manager tool to keep you organized.\n\\\nSort the list by contact method quality.\n\\\nFrom there, sort the list again by passion.\n\\\nYou should reach out to creators in this order. Eight creators at a time. You should follow up three times without a response before you give up on reaching that creator.\n\\\nA few tips to think about when creating your list:\n\\\n\nTarget Smaller Influencers — Big influencers cost big bucks. Smaller influencers are often very affordable or even “free” (more on this later). Target influencers with followings under 50k on YouTube/Instagram or 500k on Tik Tok to start.\n\\\n\n\nEnsure Your Influencer Has The Right Influence — Some influencers have astronomical follower counts but when you look at their content, it’s not engaged with or only being engaged by bots.\n\\\nBeware of influencers like this! Also, it’s critical that the influencer has an audience that matches the demographics of people who use your product.\n\\\nIt doesn’t matter how many followers Oprah Winfrey has, if she promotes a First Person Shooter game (something typically younger men enjoy), the campaign could perform catastrophically poorly since Oprah’s following tends to consist of older women!\n\n\n\\\nHave An “In” — Prioritize influencers you can actually get in touch with: either via warm intro or because they have their business email readily available. Golden rule: avoid their agent at all costs! Agents care about one thing only, money upfront.\n\\\nIf you’re a startup founder, you likely don’t have the budget to be shoveling out loads of cash on influencer marketing campaigns. Instead, you could try contacting someone in the influencer’s orbit first: someone in their “entourage.”\n\\\nIf you can convince them of a quality product, they’ll likely be willing to warm intro you to the influencer at that point.\n\\\nIf you’re really struggling to find an “in” — You can reach out to small marketing agencies such as Homeplate or Courtside as these agencies are likely to have connections to influencers. Keep in mind, these agencies will likely require a fee for their services. But they might be affordable to you.\n\n\n\\\nDon’t discount your passion — It’s important to identify which creators you’d most like to work with because your passion for their brand will come off in the pitch.\n\\\n \n\\\nStep 2: The Pitch\nIt’s time to reach out and pitch influencers you’ve identified.\n\\\nInfluencer partnerships are relationship based. That is to say your reputation matters. Influencers only work with people they trust. Here are some items that can help give you credibility when you initially reach out:\n\\\n\nA strong portfolio of past products you’ve created that have good reviews.\n\\\n\nAn active community — even if it’s small — of existing & happy users.\n\\\n\nStrong concept art of the future product — the more personalized to the influencer the better.\n\\\n\nA mutual acquaintance that can speak to your talents.\n\\\n\n\nA strong “why” or mission to illuminate why you’re doing what you’re doing.\n\\\nFor instance, my initial text to Donovan read:\n\\\n\n  \nHey Donovan! I own a game studio called AppStop.io — we make sports games starring pro athletes. Our last moible game “QB Chase” starred Chase Winovich and is rated 4.9 stars on the iOS store. I’d love to build you a mobile game, completely free of charge. Curious if you have 30 minutes to discuss details next week?\n\\\nFull disclosure, I did have a warm intro to Donovan, but if I didn’t, I don’t believe I would’ve changed much about the initial text. I would’ve only included concept art in the initial message to grab attention, make the pitch more exciting, and make the pitch more personalized.\n\\\nIn our next meeting, I showed off a short slide deck highlighting my game studio, what I envisioned for Donovan’s game, how AppStop.io partners with philanthropies to donate money (this turned out to be critical), and concept art for how the game would look with Donovan in it.\n\\\nA few pro tips to keep in mind when entering the final pitch:\n\\\n\nKeep it Short — What is your product? What makes your product the next big thing? What is your “ask” for the influencer? Keep it lean.\n\\\n\n\nContent is King — (IMPORTANT): There’s a common misconception that influencers only care about money. In my experience, influencers do care about money but what they care even more about is content.\n\\\nIf you can convince the influencer that your product will inspire content that will thrill their community and that your company can actually create that content on the influencer’s behalf, then they’re very likely to want to do business with you — perhaps even for free.\n\\\nThis could be a giveaway, custom digital art, or a cool video or Tik Tok. In our case, we let Donovan know that we would create Instagram content on his behalf and that this Instagram content would perform great (more on this in step 3)\n\n\n\\\nDo You Need to Pay? — You don’t always need to pay the influencer an upfront guarantee. This is especially true if your product is remarkable, your intro is particularly warm, and the marketing activation is very easy for them to implement.\n\\\nYou do need to offer them something such as revenue share, content creation services, or philanthropic donations.\n\\\nSmaller influencers may also be fine with accepting an upfront guarantee as small as ~$500 simply so they can develop their own portfolio of successful marketing campaigns for when larger businesses reach out.\n\\\nHave Thick Skin — If you reach out to 100 influencers cold and even three respond, then that’s a huge success. Influencers are flooded with entrepreneurs such as yourself (now more than ever), and they can’t get to every pitch.\n\\\nHave patience, and don’t take rejection personally. Every influencer you work with gives you more credibility. The first deal is the hardest.\n\\\nAfter the pitch is over, be sure to sign a licensing agreement with the influencer(s) so that you have the ability to use their Name, Image, and Likeness (NIL) in app and on promotional content.\n\\\nEven though it’s a hassle, it’s important to sign these contracts so that each party is committed to following through on their end of the deal.\n\\\n \nChapter 3: Implementing the Influencer Marketing Campaign\nThe first thing to note is that the influencer’s fans are not the end all be all of your app’s users. Ideally speaking, you should think of influencers as a marketing catalyst that can increase two important stats:\n\\\n\nGet your app on the top charts of various AppStores — thereby increasing “organic **growth” (**i.e., users naturally finding you online)\n\\\n\n\nProvide a solid foundation of users that will naturally share the app with their friends. Often, this is called the “K-Factor.”\n\\\nThe right marketing strategy should always have your organic growth and K-Factor be the primary source of users. For instance, our game, Deep Pass Jam, grew 213% from users naturally finding us on the top iOS charts.\n\\\nThat means that all the marketing we did with the influencer accounted for less than half of our final total users! But, we still needed the influencer as a catalyst to get onto the top 100 charts to reap those benefits.\nThe next thing to keep in mind is content delivery. Sometimes the influencers will want to create the content for the marketing campaign. Often, they will want you to create the content and then they will approve the content with edits.\n\\\nIt is very critical to express who is responsible for creating what content and when you plan to have the influencer post it. If you don’t express this in plain language, it will not be posted, or worse; the content could be posted incorrectly — having catastrophic consequences.\n\\\nIn our case, we expressed to Donovan that AppStop.io would be creating the content. We had a trick up our sleeve. We knew semi-realistic video game content performs unbelievably well on social media.\n\\\nIt’s jarring and fun for the viewer to see the digital version of your favorite character inside a video game. This type of content increased Kim Kardashian, Connor McGregor, and Gordon Ramsay’s social media engagement.\n\\\nSo, we had our animators get to work. In the end, Donovan got to relax for a week while his Instagram engagement increased a tremendous 300% because of the content we created on his behalf:\nhttps://www.instagram.com/p/CZU0aFQJfI_/?embedable=true\n\\\nRegardless, a few tips and tricks with any content you plan to have the influencer post:\n\\\n\nInclude a Call-To-Action — Ensure there’s an easy off-ramp from the content to have consumers download your app\n\\\n\nProvide Value — The best social media content is content that can provide value to the viewer. Make the viewer laugh, give them valuable information, and show them something emotional. It’s important to study other apps’ high-performing content to see what worked for them and copy that format!\n\\\n\nCreate a Network Effect — Influencers often have strong ties to other influencers with followings. Make it easy for them to engage and re-share the content by having the art be high-quality, tying the product to a larger mission (possibly a philanthropic partnership), and highlighting ownership of the original influencer.\n\\\n\n\nBalance the Influencer’s Presence —While having the influencer star in promotional content and in-app can help drive traffic from fans who know the influencer, it can also be off-putting to those who aren’t familiar with the influencer. \n\\\nThat’s why it’s important for the influencer to have a “muted” presence. They shouldn’t be plastered on the front page of every piece of content, but they should be visible in some of the content.\n\\\nIn addition to posting content, it’s important to know the data behind what you’re posting. Have a plan on exactly how many downloads you hope to gain from the influencer’s promotion. Stats matter because they can help advise content strategy.\n\\\nHere are some of the most important statistics every startup founder should know about the AppStore:\n\\\n\n\nAccording to Tech Crunch, it requires roughly 8,000 downloads in a 24-hour period to get on the U.S. top 100 iOS free games list. 26,000 downloads to get into the top 10. Business apps are double those numbers. 16,000 for the top 100 and 52,000 for the top 10 of any business category. Of course, these numbers can vary from day to day.\n\\\nCertain app genres have different AppStore conversion rates. Know what your genre’s average conversion rate is. If your app’s conversion rate is below average that means that you are missing out on important organic growth and need to improve your AppStore’s promotional content. \n\\\nSometimes this process is called “AppStore Optimization” or “ASO.” The most important promotional content is the photo previews of your app. Ensure these are very high quality prior to launching an influencer campaign.\n\\\nIn conclusion, influencer marketing can be a powerful tool for bootstrapped startups looking to scale their apps. By partnering with influential individuals within their target market, startups can tap into their existing audience and gain valuable exposure for their apps. \n\\\nThis can help drive downloads and increase user engagement, ultimately helping the startup to grow and succeed.\n\\\nTo get started with influencer marketing, startups should identify potential influencers within their target market, offer them incentives to promote their app, and track the results to see if the strategy is effective.\n\\\nBy implementing influencer marketing as part of their growth strategy, bootstrapped startups can take their app to new heights.","dc:creator":"Max Albert","content":"Influencer marketing campaigns grew a staggering 26% in 2021 and the trend appears to be continuing in 2022. The process of having an influencer promote your product **—** —**— has become increasingly important. Smaller influencers are often very affordable or even “free” “big big bucks” are often often very big. Target influencers will follow up three times without a response before you give up on reaching that creator before giving up. Targeting influencers on YouTube or Instagram or Instagram.","contentSnippet":"Influencer marketing campaigns grew a staggering 26% in 2021 and the trend appears to be continuing in 2022. The process of having an influencer promote your product **—** —**— has become increasingly important. Smaller influencers are often very affordable or even “free” “big big bucks” are often often very big. Target influencers will follow up three times without a response before you give up on reaching that creator before giving up. Targeting influencers on YouTube or Instagram or Instagram.","guid":"https://hackernoon.com/how-a-solopreneur-used-influencer-marketing-to-reach-the-ios-top-100-list?source=rss","categories":["influencer-marketing","marketing","ios-development","bootstrap","marketing-for-engineers","influencers","mobile-apps","hackernoon-top-story","web-monetization","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja","hackernoon-es","hackernoon-hi","hackernoon-zh","hackernoon-vi","hackernoon-fr","hackernoon-pt","hackernoon-ja"],"isoDate":"2022-12-14T22:03:48.000Z","from":"https://hackernoon.com/feed","hashId":"dca721d1228b201d6b5804065aaf8b86"},{"creator":"Karl Maier","title":"Addressing Common Software Delivery (CI/CD) Pipeline Challenges","link":"https://medium.com/slalom-build/addressing-common-software-delivery-ci-cd-pipeline-challenges-9215f9a92b99?source=rss------devops-5","pubDate":"Wed, 14 Dec 2022 22:41:11 GMT","dc:creator":"Karl Maier","content":"<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/slalom-build/addressing-common-software-delivery-ci-cd-pipeline-challenges-9215f9a92b99?source=rss------devops-5\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*ZkkgkUT5L6p2DVac\" width=\"4032\"></a></p><p class=\"medium-feed-snippet\">How to avoid the most common pitfalls faced when implementing software delivery (CI/CD) pipelines at scale</p><p class=\"medium-feed-link\"><a href=\"https://medium.com/slalom-build/addressing-common-software-delivery-ci-cd-pipeline-challenges-9215f9a92b99?source=rss------devops-5\">Continue reading on Slalom Build »</a></p></div>","contentSnippet":"How to avoid the most common pitfalls faced when implementing software delivery (CI/CD) pipelines at scale\nContinue reading on Slalom Build »","guid":"https://medium.com/p/9215f9a92b99","categories":["ci-cd-pipeline","devops","cloud","delivery-software","platform-engineering"],"isoDate":"2022-12-14T22:41:11.000Z","from":"https://medium.com/feed/tag/devops","hashId":"62869b6eb5c43b66073b3a9faf23d6a4"}]